{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61b2138-cc84-4487-9c47-2d4ba2ff17bd",
   "metadata": {},
   "source": [
    "## Optiver Competition \n",
    "Team: Brandon, Jatindeep, Alex, Avi\n",
    "\n",
    "**Overview:** I created a Jupyter notebook from our last notebook where we can develop models here and test the MAE since it takes hours on Kaggle. After we develop some solid models, we can then submit them on kaggle. We will automatically start with the 50 features, as well as the targets. And go from there. Feel free to add visualization as it will help us better understand the models responses to our changes.\n",
    "\n",
    "Disregard Principal Component Analysis for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c93dd2-6192-40e6-a0a7-531f69ecd5e9",
   "metadata": {},
   "source": [
    "## New Features and Model Setup\n",
    "- This is the code I pulled from the other notebook mixed with all of our stuff. The goal is to beat our first model MAE of 6.41\n",
    "- I will first begin with just the new features\n",
    "- First up is feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21dfa191-fc8b-4e32-a73e-353917c1f785",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cbt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from warnings import simplefilter\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Filtering some warnings (we might wanna look at the performance one maybe)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "\n",
    "#Read data, calculate median, std_deviation of total bid + sizes, get target\n",
    "train = pd.read_csv('train.csv')\n",
    "median_sizes = train.groupby('stock_id')['bid_size'].median() + train.groupby('stock_id')['ask_size'].median()\n",
    "std_sizes = train.groupby('stock_id')['bid_size'].std() + train.groupby('stock_id')['ask_size'].std()\n",
    "train = train.dropna(subset=['target'])\n",
    "\n",
    "#The author's feature engineering. Could work well we could potentially improve and combine from last notebook if there are any differences\n",
    "def feat_eng(df):\n",
    "    \n",
    "    cols = [c for c in df.columns if c not in ['row_id', 'time_id']]\n",
    "    df = df[cols]\n",
    "    df['imbalance_ratio'] = df['imbalance_size'] / df['matched_size']\n",
    "    df['bid_ask_volume_diff'] = df['ask_size'] - df['bid_size']\n",
    "    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n",
    "    df['bid_plus_ask_sizes'] = df['bid_size'] + df['ask_size']\n",
    "    df['median_size'] = df['stock_id'].map(median_sizes.to_dict())\n",
    "    df['std_size'] = df['stock_id'].map(std_sizes.to_dict())\n",
    "    df['high_volume'] = np.where(df['bid_plus_ask_sizes'] > df['median_size'], 1, 0)\n",
    "        \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "\n",
    "    #Changed this part because it didn't handle zero cases\n",
    "    # This part should handle null values and avoid data loss\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f'{c[0]}_minus_{c[1]}'] = (df[f'{c[0]}'] - df[f'{c[1]}']).astype(np.float32)\n",
    "        denominator = df[f'{c[0]}'] + df[f'{c[1]}']\n",
    "        df[f'{c[0]}_{c[1]}_imb'] = np.where(denominator != 0, (df[f'{c[0]}'] - df[f'{c[1]}']) / denominator, 0).astype(np.float32)\n",
    "    \n",
    "    for c in combinations(prices, 3):\n",
    "        max_ = df[list(c)].max(axis=1)\n",
    "        min_ = df[list(c)].min(axis=1)\n",
    "        mid_ = df[list(c)].sum(axis=1) - min_ - max_\n",
    "        denominator = mid_ - min_\n",
    "        df[f'{c[0]}_{c[1]}_{c[2]}_imb2'] = np.where(denominator != 0, (max_ - mid_) / denominator, 0).astype(np.float32)\n",
    "    df.drop(columns=['date_id',], inplace=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    print('Features Finished Calculating')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a17d2d-ec53-465b-9bc1-0f136ec1099e",
   "metadata": {},
   "source": [
    "### Quick Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30af96ec-1a8a-4287-b473-a29682c5f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Finished Calculating\n"
     ]
    }
   ],
   "source": [
    "# Note the X, y columns\n",
    "X = feat_eng(train.drop(columns='target'))\n",
    "y = train['target'].values\n",
    "\n",
    "\n",
    "def inspect_columns(df):\n",
    "    \n",
    "    # Get this function from other's Jupyter\n",
    "    # A helper function that does a better job than df.info() and df.describe()\n",
    "    \n",
    "    result = pd.DataFrame({\n",
    "        'unique': df.nunique() == len(df),\n",
    "        'cardinality': df.nunique(),\n",
    "        'with_null': df.isna().any(),\n",
    "        'null_pct': round((df.isnull().sum() / len(df)) * 100, 2),\n",
    "        '1st_row': df.iloc[0],\n",
    "        'random_row': df.iloc[np.random.randint(low=0, high=len(df))],\n",
    "        'last_row': df.iloc[-1],\n",
    "        'dtype': df.dtypes\n",
    "    })\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e500e7-fa42-4b64-b751-dc7dd608029b",
   "metadata": {},
   "source": [
    "### Inspecting Current Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cba918-0ece-490b-8400-ecedf11f2510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>with_null</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>1st_row</th>\n",
       "      <th>random_row</th>\n",
       "      <th>last_row</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stock_id</th>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.090000e+02</td>\n",
       "      <td>1.990000e+02</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>5.400000e+02</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2971863</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.180603e+06</td>\n",
       "      <td>4.097017e+06</td>\n",
       "      <td>1.884286e+06</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28741</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.998120e-01</td>\n",
       "      <td>1.001790e+00</td>\n",
       "      <td>1.002129e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matched_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2948862</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.338028e+07</td>\n",
       "      <td>7.084771e+07</td>\n",
       "      <td>2.407368e+07</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price</th>\n",
       "      <td>False</td>\n",
       "      <td>95739</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000855e+00</td>\n",
       "      <td>1.000859e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price</th>\n",
       "      <td>False</td>\n",
       "      <td>84625</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001166e+00</td>\n",
       "      <td>1.001494e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28313</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.998120e-01</td>\n",
       "      <td>1.001790e+00</td>\n",
       "      <td>1.002129e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2591772</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.065150e+04</td>\n",
       "      <td>5.134053e+05</td>\n",
       "      <td>2.500814e+05</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>28266</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000026e+00</td>\n",
       "      <td>1.002102e+00</td>\n",
       "      <td>1.002447e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_size</th>\n",
       "      <td>False</td>\n",
       "      <td>2623253</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.493030e+03</td>\n",
       "      <td>5.692315e+05</td>\n",
       "      <td>3.001676e+05</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wap</th>\n",
       "      <td>False</td>\n",
       "      <td>31506</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.001938e+00</td>\n",
       "      <td>1.002274e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imbalance_ratio</th>\n",
       "      <td>False</td>\n",
       "      <td>2983874</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.377083e-01</td>\n",
       "      <td>5.782850e-02</td>\n",
       "      <td>7.827162e-02</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_ask_volume_diff</th>\n",
       "      <td>False</td>\n",
       "      <td>4636747</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.215847e+04</td>\n",
       "      <td>5.582627e+04</td>\n",
       "      <td>5.008612e+04</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>69087</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.999190e-01</td>\n",
       "      <td>1.001946e+00</td>\n",
       "      <td>1.002288e+00</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_plus_ask_sizes</th>\n",
       "      <td>False</td>\n",
       "      <td>4497517</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.914453e+04</td>\n",
       "      <td>1.082637e+06</td>\n",
       "      <td>5.502490e+05</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_size</th>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.273916e+04</td>\n",
       "      <td>3.445545e+05</td>\n",
       "      <td>1.141271e+05</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_size</th>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.329869e+05</td>\n",
       "      <td>3.306171e+05</td>\n",
       "      <td>1.942101e+05</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_volume</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>int32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_minus_far_price</th>\n",
       "      <td>False</td>\n",
       "      <td>120697</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.350000e-04</td>\n",
       "      <td>1.270000e-03</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_far_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1179602</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.668825e-04</td>\n",
       "      <td>6.340527e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_minus_near_price</th>\n",
       "      <td>False</td>\n",
       "      <td>96511</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.240000e-04</td>\n",
       "      <td>6.350000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_near_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1258289</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.115395e-04</td>\n",
       "      <td>3.169259e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_minus_ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>7614</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.140000e-04</td>\n",
       "      <td>-3.120000e-04</td>\n",
       "      <td>-3.180000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_ask_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2204404</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.070087e-04</td>\n",
       "      <td>-1.556970e-04</td>\n",
       "      <td>-1.586370e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_minus_bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>7799</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_bid_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2178194</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_minus_wap</th>\n",
       "      <td>False</td>\n",
       "      <td>9980</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.880000e-04</td>\n",
       "      <td>-1.480000e-04</td>\n",
       "      <td>-1.450000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_wap_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>3487741</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.400884e-05</td>\n",
       "      <td>-7.386232e-05</td>\n",
       "      <td>-7.234074e-05</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_minus_near_price</th>\n",
       "      <td>False</td>\n",
       "      <td>82914</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.110000e-04</td>\n",
       "      <td>-6.350000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_near_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>827306</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.553430e-04</td>\n",
       "      <td>-3.171269e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_minus_ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>119175</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.247000e-03</td>\n",
       "      <td>-1.588000e-03</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_ask_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1483056</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.225795e-04</td>\n",
       "      <td>-7.926897e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_minus_bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>119221</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.350000e-04</td>\n",
       "      <td>-1.270000e-03</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_bid_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1491191</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.668825e-04</td>\n",
       "      <td>-6.340527e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_minus_wap</th>\n",
       "      <td>False</td>\n",
       "      <td>130599</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.083000e-03</td>\n",
       "      <td>-1.415000e-03</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_wap_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2255489</td>\n",
       "      <td>True</td>\n",
       "      <td>55.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.407449e-04</td>\n",
       "      <td>-7.063934e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_minus_ask_price</th>\n",
       "      <td>False</td>\n",
       "      <td>95905</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.360000e-04</td>\n",
       "      <td>-9.530000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_ask_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1587645</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.672365e-04</td>\n",
       "      <td>-4.755629e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_minus_bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>95942</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.240000e-04</td>\n",
       "      <td>-6.350000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_bid_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>1595299</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.115395e-04</td>\n",
       "      <td>-3.169259e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_minus_wap</th>\n",
       "      <td>False</td>\n",
       "      <td>102231</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.720000e-04</td>\n",
       "      <td>-7.800000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_wap_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2278153</td>\n",
       "      <td>True</td>\n",
       "      <td>54.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.854019e-04</td>\n",
       "      <td>-3.892666e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price_minus_bid_price</th>\n",
       "      <td>False</td>\n",
       "      <td>6613</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.140000e-04</td>\n",
       "      <td>3.120000e-04</td>\n",
       "      <td>3.180000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price_bid_price_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2603178</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.070087e-04</td>\n",
       "      <td>1.556970e-04</td>\n",
       "      <td>1.586370e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price_minus_wap</th>\n",
       "      <td>False</td>\n",
       "      <td>6357</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.600000e-05</td>\n",
       "      <td>1.640000e-04</td>\n",
       "      <td>1.730000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price_wap_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2954129</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.299983e-05</td>\n",
       "      <td>8.183470e-05</td>\n",
       "      <td>8.629630e-05</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price_minus_wap</th>\n",
       "      <td>False</td>\n",
       "      <td>6097</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.880000e-04</td>\n",
       "      <td>-1.480000e-04</td>\n",
       "      <td>-1.450000e-04</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bid_price_wap_imb</th>\n",
       "      <td>False</td>\n",
       "      <td>2924570</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-9.400884e-05</td>\n",
       "      <td>-7.386232e-05</td>\n",
       "      <td>-7.234074e-05</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_far_price_near_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>948151</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.006431e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_far_price_ask_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>832148</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000214e+00</td>\n",
       "      <td>3.336898e-01</td>\n",
       "      <td>2.503937e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_far_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>804950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_far_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1167091</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000188e+00</td>\n",
       "      <td>1.582888e-01</td>\n",
       "      <td>1.141732e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_near_price_ask_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>729266</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000214e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.007874e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_near_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>705376</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_near_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1000214</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000188e+00</td>\n",
       "      <td>2.371795e-01</td>\n",
       "      <td>2.283465e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_ask_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>401933</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.927541e+12</td>\n",
       "      <td>7.025615e+11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_ask_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>445764</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.382979e-01</td>\n",
       "      <td>1.108108e+00</td>\n",
       "      <td>1.193103e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_price_bid_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>448959</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.693354e+12</td>\n",
       "      <td>-6.665328e+11</td>\n",
       "      <td>-6.530219e+11</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_near_price_ask_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>939856</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>3.009646e+00</td>\n",
       "      <td>1.500787e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_near_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>940370</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.006431e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_near_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1213130</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.482315e+00</td>\n",
       "      <td>1.228346e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_ask_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1020581</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000214e+00</td>\n",
       "      <td>3.336898e-01</td>\n",
       "      <td>2.503937e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_ask_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1268379</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000026e+00</td>\n",
       "      <td>1.514312e-01</td>\n",
       "      <td>1.222615e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>far_price_bid_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1263378</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000188e+00</td>\n",
       "      <td>1.582888e-01</td>\n",
       "      <td>1.141732e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_ask_price_bid_price_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>908963</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000214e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.007874e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_ask_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1099739</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000026e+00</td>\n",
       "      <td>2.124352e-01</td>\n",
       "      <td>2.217949e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near_price_bid_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>1096176</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.000188e+00</td>\n",
       "      <td>2.371795e-01</td>\n",
       "      <td>2.283465e-01</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask_price_bid_price_wap_imb2</th>\n",
       "      <td>False</td>\n",
       "      <td>574434</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.382979e-01</td>\n",
       "      <td>1.108108e+00</td>\n",
       "      <td>1.193103e+00</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "inspected_features = inspect_columns(X)\n",
    "\n",
    "html = inspected_features.to_html(classes='table table-striped table-bordered')\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e99df-1d6d-4fdc-980e-bf8c43881c15",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "- I reduced the parameters just so i could run it in a timely fashion to study the outputs. I will come back to this later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b3bfd-2c3c-4113-b009-8a434e2b4625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training of Models\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.074987\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000029 seconds, init for row-wise cost 0.268737 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.369525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16970\n",
      "[LightGBM] [Info] Number of data points in the train set: 3142734, number of used features: 70\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 437 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 435 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 438 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 437 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 436 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 425 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 431 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 435 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 439 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 418 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 438 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 432 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 438 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 420 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 394 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 407 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 435 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 393 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 395 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 428 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 392 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 416 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 395 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 414 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 430 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 425 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 401 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 417 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 430 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 398 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 412 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 393 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 432 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 384 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 420 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 437 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 374 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 404 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 404 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 380 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 423 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 426 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 417 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 379 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 390 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 409 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 411 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 382 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 363 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 415 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 399 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 393 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 396 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 368 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 394 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 390 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 407 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 370 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 416 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 415 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 399 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 407 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 391 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 366 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 387 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 369 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 404 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 347 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 396 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 364 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 348 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 370 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 344 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 305 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 383 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 342 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 384 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 338 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 365 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 325 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 372 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 341 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 377 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 351 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 391 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 378 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 348 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 322 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 344 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 376 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 321 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 348 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 373 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 329 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 307 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 297 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 349 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 372 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 381 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 353 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 263 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 260 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 350 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 278 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 238 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 347 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 324 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 364 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 310 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 276 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 327 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 342 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 281 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 240 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 271 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 242 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 217 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 311 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 341 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 314 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 329 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 338 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 261 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 337 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 318 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 315 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 339 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 307 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 294 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 212 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 316 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 273 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 399 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 282 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 416 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 213 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 314 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 308 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 351 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 340 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 333 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 284 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 236 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 364 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 287 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 297 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 247 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 265 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 275 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 290 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 290 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 296 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 180 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 255 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 239 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 279 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 350 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 319 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 329 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 296 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 334 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 432 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 299 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 300 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 323 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 301 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 264 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 275 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 299 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 180 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 218 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 267 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 307 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 244 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 228 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 301 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 233 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 294 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 243 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 315 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 287 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 426 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 228 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 317 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 210 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 271 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 406 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 255 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 316 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 390 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 277 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 245 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 233 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 332 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 296 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 235 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 259 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 216 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 279 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 298 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 375 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 283 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 263 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 362 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 252 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 199 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 237 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 214 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 318 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 194 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 332 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 262 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 296 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 330 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 295 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 322 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 236 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 305 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 292 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 294 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 226 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 359 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 371 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 289 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 197 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 250 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 239 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 365 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 334 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 292 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 326 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 203 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 245 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 227 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 274 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 327 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 232 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 232 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 126 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 186 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 380 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 272 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 310 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 195 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 197 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 255 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 210 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 327 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 220 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 385 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 173 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 314 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 302 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 298 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 288 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 200 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 181 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 393 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 263 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 109 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 106 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 336 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 354 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 240 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 351 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 262 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 270 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 390 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 320 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 197 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 214 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 342 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 304 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 270 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 249 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 254 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 242 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 227 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 304 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 344 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 344 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 276 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 329 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 189 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 311 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 342 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 238 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 251 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 242 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 345 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 230 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 315 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 309 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 266 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 245 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 197 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 330 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 190 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 230 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 304 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 306 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 236 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 264 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 243 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 289 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 275 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 401 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 252 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 310 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 255 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 248 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 289 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 268 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 247 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 273 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 273 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 226 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 200 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 284 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 255 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 168 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 314 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 367 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 215 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 233 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 271 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 260 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 240 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 332 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 299 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 298 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 278 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 353 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 340 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 249 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 260 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 188 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 205 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 212 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 184 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 261 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 346 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 213 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 378 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 300 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 200 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 254 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 207 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 275 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 220 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 208 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 249 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 251 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 226 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 229 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 254 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 284 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 342 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 330 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 316 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 343 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 298 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 178 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 251 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 241 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 294 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 254 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 206 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 384 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 256 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 233 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 312 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 240 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 181 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 226 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 194 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 179 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 254 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 316 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 300 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 207 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 419 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 217 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 281 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 308 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 216 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 222 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 242 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 378 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 242 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 314 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 353 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 257 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 234 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 215 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 261 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 349 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 304 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 221 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 204 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 240 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 231 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 322 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 213 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 368 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 210 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 244 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 285 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 169 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 191 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 181 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 329 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 236 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 207 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 203 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 276 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 225 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 304 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 230 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 175 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 297 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 403 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 268 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 151 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 181 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 197 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 259 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 262 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 289 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 280 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 306 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 305 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 289 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 381 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 321 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 339 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 317 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 281 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 306 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 263 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 186 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 239 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 161 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 270 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 243 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 324 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 277 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 204 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 301 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 154 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 202 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 398 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 183 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 293 and depth = 9\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[599]\tvalid_0's l1: 6.23383\n",
      "Evaluated only: l1\n",
      "[0]\tvalidation_0-mae:6.35560\n",
      "[1]\tvalidation_0-mae:6.32732\n",
      "[2]\tvalidation_0-mae:6.31094\n",
      "[3]\tvalidation_0-mae:6.30019\n",
      "[4]\tvalidation_0-mae:6.29434\n",
      "[5]\tvalidation_0-mae:6.28993\n",
      "[6]\tvalidation_0-mae:6.28705\n",
      "[7]\tvalidation_0-mae:6.28483\n",
      "[8]\tvalidation_0-mae:6.28359\n",
      "[9]\tvalidation_0-mae:6.28153\n",
      "[10]\tvalidation_0-mae:6.27971\n",
      "[11]\tvalidation_0-mae:6.27807\n",
      "[12]\tvalidation_0-mae:6.27709\n",
      "[13]\tvalidation_0-mae:6.27622\n",
      "[14]\tvalidation_0-mae:6.27466\n",
      "[15]\tvalidation_0-mae:6.27408\n",
      "[16]\tvalidation_0-mae:6.27230\n",
      "[17]\tvalidation_0-mae:6.27143\n",
      "[18]\tvalidation_0-mae:6.27066\n",
      "[19]\tvalidation_0-mae:6.27029\n",
      "[20]\tvalidation_0-mae:6.26867\n",
      "[21]\tvalidation_0-mae:6.26785\n",
      "[22]\tvalidation_0-mae:6.26746\n",
      "[23]\tvalidation_0-mae:6.26668\n",
      "[24]\tvalidation_0-mae:6.26496\n",
      "[25]\tvalidation_0-mae:6.26455\n",
      "[26]\tvalidation_0-mae:6.26393\n",
      "[27]\tvalidation_0-mae:6.26387\n",
      "[28]\tvalidation_0-mae:6.26349\n",
      "[29]\tvalidation_0-mae:6.26288\n",
      "[30]\tvalidation_0-mae:6.26235\n",
      "[31]\tvalidation_0-mae:6.26211\n",
      "[32]\tvalidation_0-mae:6.26148\n",
      "[33]\tvalidation_0-mae:6.26119\n",
      "[34]\tvalidation_0-mae:6.26080\n",
      "[35]\tvalidation_0-mae:6.26054\n",
      "[36]\tvalidation_0-mae:6.26041\n",
      "[37]\tvalidation_0-mae:6.26001\n",
      "[38]\tvalidation_0-mae:6.25951\n",
      "[39]\tvalidation_0-mae:6.25914\n",
      "[40]\tvalidation_0-mae:6.25825\n",
      "[41]\tvalidation_0-mae:6.25822\n",
      "[42]\tvalidation_0-mae:6.25811\n",
      "[43]\tvalidation_0-mae:6.25781\n",
      "[44]\tvalidation_0-mae:6.25770\n",
      "[45]\tvalidation_0-mae:6.25730\n",
      "[46]\tvalidation_0-mae:6.25691\n",
      "[47]\tvalidation_0-mae:6.25669\n",
      "[48]\tvalidation_0-mae:6.25634\n",
      "[49]\tvalidation_0-mae:6.25636\n",
      "[50]\tvalidation_0-mae:6.25626\n",
      "[51]\tvalidation_0-mae:6.25557\n",
      "[52]\tvalidation_0-mae:6.25489\n",
      "[53]\tvalidation_0-mae:6.25412\n",
      "[54]\tvalidation_0-mae:6.25348\n",
      "[55]\tvalidation_0-mae:6.25334\n",
      "[56]\tvalidation_0-mae:6.25304\n",
      "[57]\tvalidation_0-mae:6.25275\n",
      "[58]\tvalidation_0-mae:6.25261\n",
      "[59]\tvalidation_0-mae:6.25234\n",
      "[60]\tvalidation_0-mae:6.25194\n",
      "[61]\tvalidation_0-mae:6.25177\n",
      "[62]\tvalidation_0-mae:6.25147\n",
      "[63]\tvalidation_0-mae:6.25136\n",
      "[64]\tvalidation_0-mae:6.25113\n",
      "[65]\tvalidation_0-mae:6.25105\n",
      "[66]\tvalidation_0-mae:6.25082\n",
      "[67]\tvalidation_0-mae:6.25004\n",
      "[68]\tvalidation_0-mae:6.24989\n",
      "[69]\tvalidation_0-mae:6.25005\n",
      "[70]\tvalidation_0-mae:6.25008\n",
      "[71]\tvalidation_0-mae:6.24945\n",
      "[72]\tvalidation_0-mae:6.24905\n",
      "[73]\tvalidation_0-mae:6.24883\n",
      "[74]\tvalidation_0-mae:6.24866\n",
      "[75]\tvalidation_0-mae:6.24841\n",
      "[76]\tvalidation_0-mae:6.24822\n",
      "[77]\tvalidation_0-mae:6.24742\n",
      "[78]\tvalidation_0-mae:6.24724\n",
      "[79]\tvalidation_0-mae:6.24704\n",
      "[80]\tvalidation_0-mae:6.24678\n",
      "[81]\tvalidation_0-mae:6.24662\n",
      "[82]\tvalidation_0-mae:6.24638\n",
      "[83]\tvalidation_0-mae:6.24624\n",
      "[84]\tvalidation_0-mae:6.24570\n",
      "[85]\tvalidation_0-mae:6.24551\n",
      "[86]\tvalidation_0-mae:6.24533\n",
      "[87]\tvalidation_0-mae:6.24513\n",
      "[88]\tvalidation_0-mae:6.24488\n",
      "[89]\tvalidation_0-mae:6.24480\n",
      "[90]\tvalidation_0-mae:6.24420\n",
      "[91]\tvalidation_0-mae:6.24333\n",
      "[92]\tvalidation_0-mae:6.24294\n",
      "[93]\tvalidation_0-mae:6.24266\n",
      "[94]\tvalidation_0-mae:6.24235\n",
      "[95]\tvalidation_0-mae:6.24206\n",
      "[96]\tvalidation_0-mae:6.24183\n",
      "[97]\tvalidation_0-mae:6.24160\n",
      "[98]\tvalidation_0-mae:6.24164\n",
      "[99]\tvalidation_0-mae:6.24148\n",
      "[100]\tvalidation_0-mae:6.24138\n",
      "[101]\tvalidation_0-mae:6.24132\n",
      "[102]\tvalidation_0-mae:6.24133\n",
      "[103]\tvalidation_0-mae:6.24113\n",
      "[104]\tvalidation_0-mae:6.24108\n",
      "[105]\tvalidation_0-mae:6.24084\n",
      "[106]\tvalidation_0-mae:6.24077\n",
      "[107]\tvalidation_0-mae:6.24055\n",
      "[108]\tvalidation_0-mae:6.24048\n",
      "[109]\tvalidation_0-mae:6.24060\n",
      "[110]\tvalidation_0-mae:6.24046\n",
      "[111]\tvalidation_0-mae:6.24035\n",
      "[112]\tvalidation_0-mae:6.24046\n",
      "[113]\tvalidation_0-mae:6.24025\n",
      "[114]\tvalidation_0-mae:6.24021\n",
      "[115]\tvalidation_0-mae:6.24012\n",
      "[116]\tvalidation_0-mae:6.23975\n",
      "[117]\tvalidation_0-mae:6.23948\n",
      "[118]\tvalidation_0-mae:6.23925\n",
      "[119]\tvalidation_0-mae:6.23919\n",
      "[120]\tvalidation_0-mae:6.23918\n",
      "[121]\tvalidation_0-mae:6.23912\n",
      "[122]\tvalidation_0-mae:6.23904\n",
      "[123]\tvalidation_0-mae:6.23895\n",
      "[124]\tvalidation_0-mae:6.23883\n",
      "[125]\tvalidation_0-mae:6.23883\n",
      "[126]\tvalidation_0-mae:6.23868\n",
      "[127]\tvalidation_0-mae:6.23867\n",
      "[128]\tvalidation_0-mae:6.23820\n",
      "[129]\tvalidation_0-mae:6.23804\n",
      "[130]\tvalidation_0-mae:6.23796\n",
      "[131]\tvalidation_0-mae:6.23781\n",
      "[132]\tvalidation_0-mae:6.23766\n",
      "[133]\tvalidation_0-mae:6.23764\n",
      "[134]\tvalidation_0-mae:6.23749\n",
      "[135]\tvalidation_0-mae:6.23754\n",
      "[136]\tvalidation_0-mae:6.23763\n",
      "[137]\tvalidation_0-mae:6.23752\n",
      "[138]\tvalidation_0-mae:6.23746\n",
      "[139]\tvalidation_0-mae:6.23735\n",
      "[140]\tvalidation_0-mae:6.23718\n",
      "[141]\tvalidation_0-mae:6.23716\n",
      "[142]\tvalidation_0-mae:6.23709\n",
      "[143]\tvalidation_0-mae:6.23711\n",
      "[144]\tvalidation_0-mae:6.23701\n",
      "[145]\tvalidation_0-mae:6.23679\n",
      "[146]\tvalidation_0-mae:6.23686\n",
      "[147]\tvalidation_0-mae:6.23685\n",
      "[148]\tvalidation_0-mae:6.23660\n",
      "[149]\tvalidation_0-mae:6.23654\n",
      "[150]\tvalidation_0-mae:6.23644\n",
      "[151]\tvalidation_0-mae:6.23647\n",
      "[152]\tvalidation_0-mae:6.23645\n",
      "[153]\tvalidation_0-mae:6.23633\n",
      "[154]\tvalidation_0-mae:6.23644\n",
      "[155]\tvalidation_0-mae:6.23626\n",
      "[156]\tvalidation_0-mae:6.23607\n",
      "[157]\tvalidation_0-mae:6.23603\n",
      "[158]\tvalidation_0-mae:6.23604\n",
      "[159]\tvalidation_0-mae:6.23612\n",
      "[160]\tvalidation_0-mae:6.23602\n",
      "[161]\tvalidation_0-mae:6.23587\n",
      "[162]\tvalidation_0-mae:6.23566\n",
      "[163]\tvalidation_0-mae:6.23559\n",
      "[164]\tvalidation_0-mae:6.23555\n",
      "[165]\tvalidation_0-mae:6.23551\n",
      "[166]\tvalidation_0-mae:6.23548\n",
      "[167]\tvalidation_0-mae:6.23520\n",
      "[168]\tvalidation_0-mae:6.23528\n",
      "[169]\tvalidation_0-mae:6.23519\n",
      "[170]\tvalidation_0-mae:6.23511\n",
      "[171]\tvalidation_0-mae:6.23463\n",
      "[172]\tvalidation_0-mae:6.23442\n",
      "[173]\tvalidation_0-mae:6.23436\n",
      "[174]\tvalidation_0-mae:6.23440\n",
      "[175]\tvalidation_0-mae:6.23438\n",
      "[176]\tvalidation_0-mae:6.23402\n",
      "[177]\tvalidation_0-mae:6.23403\n",
      "[178]\tvalidation_0-mae:6.23390\n",
      "[179]\tvalidation_0-mae:6.23399\n",
      "[180]\tvalidation_0-mae:6.23408\n",
      "[181]\tvalidation_0-mae:6.23407\n",
      "[182]\tvalidation_0-mae:6.23395\n",
      "[183]\tvalidation_0-mae:6.23376\n",
      "[184]\tvalidation_0-mae:6.23365\n",
      "[185]\tvalidation_0-mae:6.23358\n",
      "[186]\tvalidation_0-mae:6.23348\n",
      "[187]\tvalidation_0-mae:6.23337\n",
      "[188]\tvalidation_0-mae:6.23334\n",
      "[189]\tvalidation_0-mae:6.23335\n",
      "[190]\tvalidation_0-mae:6.23339\n",
      "[191]\tvalidation_0-mae:6.23350\n",
      "0:\tlearn: 6.4040128\ttest: 6.4018375\tbest: 6.4018375 (0)\ttotal: 920ms\tremaining: 15m 19s\n",
      "1:\tlearn: 6.3995518\ttest: 6.3973132\tbest: 6.3973132 (1)\ttotal: 1.68s\tremaining: 14m\n",
      "2:\tlearn: 6.3953347\ttest: 6.3930465\tbest: 6.3930465 (2)\ttotal: 2.44s\tremaining: 13m 30s\n",
      "3:\tlearn: 6.3909601\ttest: 6.3886017\tbest: 6.3886017 (3)\ttotal: 3.18s\tremaining: 13m 12s\n",
      "4:\tlearn: 6.3868846\ttest: 6.3843933\tbest: 6.3843933 (4)\ttotal: 3.94s\tremaining: 13m 5s\n",
      "5:\tlearn: 6.3834588\ttest: 6.3809815\tbest: 6.3809815 (5)\ttotal: 4.7s\tremaining: 12m 59s\n",
      "6:\tlearn: 6.3796747\ttest: 6.3770990\tbest: 6.3770990 (6)\ttotal: 5.47s\tremaining: 12m 56s\n",
      "7:\tlearn: 6.3762377\ttest: 6.3736528\tbest: 6.3736528 (7)\ttotal: 6.2s\tremaining: 12m 49s\n",
      "8:\tlearn: 6.3730546\ttest: 6.3704444\tbest: 6.3704444 (8)\ttotal: 6.94s\tremaining: 12m 44s\n",
      "9:\tlearn: 6.3700372\ttest: 6.3673804\tbest: 6.3673804 (9)\ttotal: 7.67s\tremaining: 12m 39s\n",
      "10:\tlearn: 6.3670327\ttest: 6.3642911\tbest: 6.3642911 (10)\ttotal: 8.38s\tremaining: 12m 33s\n",
      "11:\tlearn: 6.3644313\ttest: 6.3617060\tbest: 6.3617060 (11)\ttotal: 9.13s\tremaining: 12m 31s\n",
      "12:\tlearn: 6.3617926\ttest: 6.3590555\tbest: 6.3590555 (12)\ttotal: 9.81s\tremaining: 12m 24s\n",
      "13:\tlearn: 6.3592192\ttest: 6.3564426\tbest: 6.3564426 (13)\ttotal: 10.5s\tremaining: 12m 22s\n",
      "14:\tlearn: 6.3567516\ttest: 6.3539197\tbest: 6.3539197 (14)\ttotal: 11.2s\tremaining: 12m 14s\n",
      "15:\tlearn: 6.3543238\ttest: 6.3514794\tbest: 6.3514794 (15)\ttotal: 11.9s\tremaining: 12m 10s\n",
      "16:\tlearn: 6.3520737\ttest: 6.3491968\tbest: 6.3491968 (16)\ttotal: 12.7s\tremaining: 12m 11s\n",
      "17:\tlearn: 6.3500912\ttest: 6.3472232\tbest: 6.3472232 (17)\ttotal: 13.4s\tremaining: 12m 9s\n",
      "18:\tlearn: 6.3480333\ttest: 6.3450711\tbest: 6.3450711 (18)\ttotal: 14.1s\tremaining: 12m 7s\n",
      "19:\tlearn: 6.3462371\ttest: 6.3433324\tbest: 6.3433324 (19)\ttotal: 14.8s\tremaining: 12m 7s\n",
      "20:\tlearn: 6.3444091\ttest: 6.3415254\tbest: 6.3415254 (20)\ttotal: 15.5s\tremaining: 12m 2s\n",
      "21:\tlearn: 6.3426726\ttest: 6.3397717\tbest: 6.3397717 (21)\ttotal: 16.2s\tremaining: 12m 1s\n",
      "22:\tlearn: 6.3409827\ttest: 6.3380303\tbest: 6.3380303 (22)\ttotal: 16.9s\tremaining: 11m 59s\n",
      "23:\tlearn: 6.3393482\ttest: 6.3363612\tbest: 6.3363612 (23)\ttotal: 17.7s\tremaining: 11m 59s\n",
      "24:\tlearn: 6.3376804\ttest: 6.3346889\tbest: 6.3346889 (24)\ttotal: 18.4s\tremaining: 11m 56s\n",
      "25:\tlearn: 6.3362773\ttest: 6.3332276\tbest: 6.3332276 (25)\ttotal: 19.1s\tremaining: 11m 54s\n",
      "26:\tlearn: 6.3349127\ttest: 6.3318827\tbest: 6.3318827 (26)\ttotal: 19.8s\tremaining: 11m 52s\n",
      "27:\tlearn: 6.3336451\ttest: 6.3306444\tbest: 6.3306444 (27)\ttotal: 20.5s\tremaining: 11m 53s\n",
      "28:\tlearn: 6.3322886\ttest: 6.3292954\tbest: 6.3292954 (28)\ttotal: 21.2s\tremaining: 11m 50s\n",
      "29:\tlearn: 6.3309386\ttest: 6.3279145\tbest: 6.3279145 (29)\ttotal: 21.9s\tremaining: 11m 49s\n",
      "30:\tlearn: 6.3298296\ttest: 6.3268311\tbest: 6.3268311 (30)\ttotal: 22.7s\tremaining: 11m 48s\n",
      "31:\tlearn: 6.3287518\ttest: 6.3257940\tbest: 6.3257940 (31)\ttotal: 23.4s\tremaining: 11m 47s\n",
      "32:\tlearn: 6.3276757\ttest: 6.3246718\tbest: 6.3246718 (32)\ttotal: 24.1s\tremaining: 11m 45s\n",
      "33:\tlearn: 6.3266623\ttest: 6.3236447\tbest: 6.3236447 (33)\ttotal: 24.8s\tremaining: 11m 43s\n",
      "34:\tlearn: 6.3256753\ttest: 6.3226690\tbest: 6.3226690 (34)\ttotal: 25.5s\tremaining: 11m 42s\n",
      "35:\tlearn: 6.3247464\ttest: 6.3217028\tbest: 6.3217028 (35)\ttotal: 26.2s\tremaining: 11m 42s\n",
      "36:\tlearn: 6.3239785\ttest: 6.3209177\tbest: 6.3209177 (36)\ttotal: 26.9s\tremaining: 11m 40s\n",
      "37:\tlearn: 6.3230822\ttest: 6.3199751\tbest: 6.3199751 (37)\ttotal: 27.6s\tremaining: 11m 38s\n",
      "38:\tlearn: 6.3222673\ttest: 6.3191242\tbest: 6.3191242 (38)\ttotal: 28.3s\tremaining: 11m 36s\n",
      "39:\tlearn: 6.3214809\ttest: 6.3182523\tbest: 6.3182523 (39)\ttotal: 29s\tremaining: 11m 35s\n",
      "40:\tlearn: 6.3206980\ttest: 6.3174607\tbest: 6.3174607 (40)\ttotal: 29.7s\tremaining: 11m 34s\n",
      "41:\tlearn: 6.3199788\ttest: 6.3167547\tbest: 6.3167547 (41)\ttotal: 30.4s\tremaining: 11m 33s\n",
      "42:\tlearn: 6.3191867\ttest: 6.3159134\tbest: 6.3159134 (42)\ttotal: 31s\tremaining: 11m 30s\n",
      "43:\tlearn: 6.3185226\ttest: 6.3151905\tbest: 6.3151905 (43)\ttotal: 31.8s\tremaining: 11m 29s\n",
      "44:\tlearn: 6.3178506\ttest: 6.3144855\tbest: 6.3144855 (44)\ttotal: 32.5s\tremaining: 11m 28s\n",
      "45:\tlearn: 6.3171691\ttest: 6.3138000\tbest: 6.3138000 (45)\ttotal: 33.2s\tremaining: 11m 27s\n",
      "46:\tlearn: 6.3164657\ttest: 6.3130814\tbest: 6.3130814 (46)\ttotal: 33.8s\tremaining: 11m 26s\n",
      "47:\tlearn: 6.3157902\ttest: 6.3123488\tbest: 6.3123488 (47)\ttotal: 34.5s\tremaining: 11m 23s\n",
      "48:\tlearn: 6.3152330\ttest: 6.3118282\tbest: 6.3118282 (48)\ttotal: 35.2s\tremaining: 11m 22s\n",
      "49:\tlearn: 6.3146622\ttest: 6.3112836\tbest: 6.3112836 (49)\ttotal: 35.9s\tremaining: 11m 21s\n",
      "50:\tlearn: 6.3141217\ttest: 6.3107014\tbest: 6.3107014 (50)\ttotal: 36.6s\tremaining: 11m 20s\n",
      "51:\tlearn: 6.3135785\ttest: 6.3101560\tbest: 6.3101560 (51)\ttotal: 37.2s\tremaining: 11m 19s\n",
      "52:\tlearn: 6.3130243\ttest: 6.3095746\tbest: 6.3095746 (52)\ttotal: 37.9s\tremaining: 11m 16s\n",
      "53:\tlearn: 6.3124674\ttest: 6.3090023\tbest: 6.3090023 (53)\ttotal: 38.5s\tremaining: 11m 15s\n",
      "54:\tlearn: 6.3120719\ttest: 6.3086091\tbest: 6.3086091 (54)\ttotal: 39.2s\tremaining: 11m 13s\n",
      "55:\tlearn: 6.3116243\ttest: 6.3081406\tbest: 6.3081406 (55)\ttotal: 39.8s\tremaining: 11m 11s\n",
      "56:\tlearn: 6.3111689\ttest: 6.3076598\tbest: 6.3076598 (56)\ttotal: 40.5s\tremaining: 11m 10s\n",
      "57:\tlearn: 6.3107083\ttest: 6.3071564\tbest: 6.3071564 (57)\ttotal: 41.2s\tremaining: 11m 9s\n",
      "58:\tlearn: 6.3102311\ttest: 6.3066530\tbest: 6.3066530 (58)\ttotal: 41.9s\tremaining: 11m 7s\n",
      "59:\tlearn: 6.3098392\ttest: 6.3062426\tbest: 6.3062426 (59)\ttotal: 42.5s\tremaining: 11m 5s\n",
      "60:\tlearn: 6.3094435\ttest: 6.3058490\tbest: 6.3058490 (60)\ttotal: 43.2s\tremaining: 11m 4s\n",
      "61:\tlearn: 6.3091391\ttest: 6.3055554\tbest: 6.3055554 (61)\ttotal: 43.8s\tremaining: 11m 2s\n",
      "62:\tlearn: 6.3087756\ttest: 6.3052288\tbest: 6.3052288 (62)\ttotal: 44.5s\tremaining: 11m 1s\n",
      "63:\tlearn: 6.3083765\ttest: 6.3048307\tbest: 6.3048307 (63)\ttotal: 45.1s\tremaining: 11m\n",
      "64:\tlearn: 6.3080250\ttest: 6.3044175\tbest: 6.3044175 (64)\ttotal: 45.8s\tremaining: 10m 58s\n",
      "65:\tlearn: 6.3076848\ttest: 6.3040535\tbest: 6.3040535 (65)\ttotal: 46.5s\tremaining: 10m 57s\n",
      "66:\tlearn: 6.3073845\ttest: 6.3037689\tbest: 6.3037689 (66)\ttotal: 47.1s\tremaining: 10m 55s\n",
      "67:\tlearn: 6.3071189\ttest: 6.3034680\tbest: 6.3034680 (67)\ttotal: 47.8s\tremaining: 10m 55s\n",
      "68:\tlearn: 6.3067881\ttest: 6.3031276\tbest: 6.3031276 (68)\ttotal: 48.5s\tremaining: 10m 54s\n",
      "69:\tlearn: 6.3064302\ttest: 6.3027754\tbest: 6.3027754 (69)\ttotal: 49.1s\tremaining: 10m 52s\n",
      "70:\tlearn: 6.3061598\ttest: 6.3024904\tbest: 6.3024904 (70)\ttotal: 49.7s\tremaining: 10m 50s\n",
      "71:\tlearn: 6.3059078\ttest: 6.3022502\tbest: 6.3022502 (71)\ttotal: 50.3s\tremaining: 10m 48s\n",
      "72:\tlearn: 6.3055239\ttest: 6.3019005\tbest: 6.3019005 (72)\ttotal: 51.1s\tremaining: 10m 48s\n",
      "73:\tlearn: 6.3052518\ttest: 6.3016105\tbest: 6.3016105 (73)\ttotal: 51.7s\tremaining: 10m 47s\n",
      "74:\tlearn: 6.3049711\ttest: 6.3013302\tbest: 6.3013302 (74)\ttotal: 52.4s\tremaining: 10m 45s\n",
      "75:\tlearn: 6.3047597\ttest: 6.3011290\tbest: 6.3011290 (75)\ttotal: 53s\tremaining: 10m 44s\n",
      "76:\tlearn: 6.3044654\ttest: 6.3008353\tbest: 6.3008353 (76)\ttotal: 53.7s\tremaining: 10m 43s\n",
      "77:\tlearn: 6.3042671\ttest: 6.3006461\tbest: 6.3006461 (77)\ttotal: 54.4s\tremaining: 10m 42s\n",
      "78:\tlearn: 6.3039468\ttest: 6.3003701\tbest: 6.3003701 (78)\ttotal: 55s\tremaining: 10m 41s\n",
      "79:\tlearn: 6.3037094\ttest: 6.3001220\tbest: 6.3001220 (79)\ttotal: 55.7s\tremaining: 10m 40s\n",
      "80:\tlearn: 6.3034482\ttest: 6.2998444\tbest: 6.2998444 (80)\ttotal: 56.3s\tremaining: 10m 38s\n",
      "81:\tlearn: 6.3031977\ttest: 6.2996308\tbest: 6.2996308 (81)\ttotal: 57s\tremaining: 10m 37s\n",
      "82:\tlearn: 6.3029204\ttest: 6.2993627\tbest: 6.2993627 (82)\ttotal: 57.6s\tremaining: 10m 36s\n",
      "83:\tlearn: 6.3025446\ttest: 6.2989828\tbest: 6.2989828 (83)\ttotal: 58.3s\tremaining: 10m 35s\n",
      "84:\tlearn: 6.3022946\ttest: 6.2987563\tbest: 6.2987563 (84)\ttotal: 58.9s\tremaining: 10m 33s\n",
      "85:\tlearn: 6.3020756\ttest: 6.2984832\tbest: 6.2984832 (85)\ttotal: 59.5s\tremaining: 10m 32s\n",
      "86:\tlearn: 6.3017533\ttest: 6.2981481\tbest: 6.2981481 (86)\ttotal: 1m\tremaining: 10m 31s\n",
      "87:\tlearn: 6.3015341\ttest: 6.2979369\tbest: 6.2979369 (87)\ttotal: 1m\tremaining: 10m 31s\n",
      "88:\tlearn: 6.3013438\ttest: 6.2977563\tbest: 6.2977563 (88)\ttotal: 1m 1s\tremaining: 10m 29s\n",
      "89:\tlearn: 6.3010429\ttest: 6.2974130\tbest: 6.2974130 (89)\ttotal: 1m 2s\tremaining: 10m 28s\n",
      "90:\tlearn: 6.3008558\ttest: 6.2972528\tbest: 6.2972528 (90)\ttotal: 1m 2s\tremaining: 10m 27s\n",
      "91:\tlearn: 6.3006829\ttest: 6.2971199\tbest: 6.2971199 (91)\ttotal: 1m 3s\tremaining: 10m 26s\n",
      "92:\tlearn: 6.3004685\ttest: 6.2968806\tbest: 6.2968806 (92)\ttotal: 1m 4s\tremaining: 10m 25s\n",
      "93:\tlearn: 6.3002207\ttest: 6.2966673\tbest: 6.2966673 (93)\ttotal: 1m 4s\tremaining: 10m 23s\n",
      "94:\tlearn: 6.2999486\ttest: 6.2964199\tbest: 6.2964199 (94)\ttotal: 1m 5s\tremaining: 10m 22s\n",
      "95:\tlearn: 6.2997560\ttest: 6.2962418\tbest: 6.2962418 (95)\ttotal: 1m 5s\tremaining: 10m 21s\n",
      "96:\tlearn: 6.2995052\ttest: 6.2959956\tbest: 6.2959956 (96)\ttotal: 1m 6s\tremaining: 10m 20s\n",
      "97:\tlearn: 6.2993254\ttest: 6.2958322\tbest: 6.2958322 (97)\ttotal: 1m 7s\tremaining: 10m 19s\n",
      "98:\tlearn: 6.2991453\ttest: 6.2956922\tbest: 6.2956922 (98)\ttotal: 1m 7s\tremaining: 10m 18s\n",
      "99:\tlearn: 6.2989019\ttest: 6.2954278\tbest: 6.2954278 (99)\ttotal: 1m 8s\tremaining: 10m 16s\n",
      "100:\tlearn: 6.2986171\ttest: 6.2951218\tbest: 6.2951218 (100)\ttotal: 1m 9s\tremaining: 10m 16s\n",
      "101:\tlearn: 6.2984234\ttest: 6.2949698\tbest: 6.2949698 (101)\ttotal: 1m 9s\tremaining: 10m 15s\n",
      "102:\tlearn: 6.2981845\ttest: 6.2947190\tbest: 6.2947190 (102)\ttotal: 1m 10s\tremaining: 10m 15s\n",
      "103:\tlearn: 6.2979743\ttest: 6.2945443\tbest: 6.2945443 (103)\ttotal: 1m 11s\tremaining: 10m 14s\n",
      "104:\tlearn: 6.2977842\ttest: 6.2943529\tbest: 6.2943529 (104)\ttotal: 1m 12s\tremaining: 10m 13s\n",
      "105:\tlearn: 6.2975832\ttest: 6.2941382\tbest: 6.2941382 (105)\ttotal: 1m 12s\tremaining: 10m 13s\n",
      "106:\tlearn: 6.2973330\ttest: 6.2939007\tbest: 6.2939007 (106)\ttotal: 1m 13s\tremaining: 10m 13s\n",
      "107:\tlearn: 6.2971321\ttest: 6.2937494\tbest: 6.2937494 (107)\ttotal: 1m 14s\tremaining: 10m 12s\n",
      "108:\tlearn: 6.2969480\ttest: 6.2935425\tbest: 6.2935425 (108)\ttotal: 1m 14s\tremaining: 10m 11s\n",
      "109:\tlearn: 6.2968220\ttest: 6.2934586\tbest: 6.2934586 (109)\ttotal: 1m 15s\tremaining: 10m 10s\n",
      "110:\tlearn: 6.2965440\ttest: 6.2931981\tbest: 6.2931981 (110)\ttotal: 1m 16s\tremaining: 10m 10s\n",
      "111:\tlearn: 6.2963000\ttest: 6.2929749\tbest: 6.2929749 (111)\ttotal: 1m 16s\tremaining: 10m 8s\n",
      "112:\tlearn: 6.2961345\ttest: 6.2928166\tbest: 6.2928166 (112)\ttotal: 1m 17s\tremaining: 10m 7s\n",
      "113:\tlearn: 6.2959551\ttest: 6.2926636\tbest: 6.2926636 (113)\ttotal: 1m 18s\tremaining: 10m 6s\n",
      "114:\tlearn: 6.2956937\ttest: 6.2924250\tbest: 6.2924250 (114)\ttotal: 1m 18s\tremaining: 10m 6s\n",
      "115:\tlearn: 6.2954814\ttest: 6.2922001\tbest: 6.2922001 (115)\ttotal: 1m 19s\tremaining: 10m 5s\n",
      "116:\tlearn: 6.2952648\ttest: 6.2919855\tbest: 6.2919855 (116)\ttotal: 1m 20s\tremaining: 10m 4s\n",
      "117:\tlearn: 6.2950872\ttest: 6.2918179\tbest: 6.2918179 (117)\ttotal: 1m 20s\tremaining: 10m 3s\n",
      "118:\tlearn: 6.2949079\ttest: 6.2916629\tbest: 6.2916629 (118)\ttotal: 1m 21s\tremaining: 10m 2s\n",
      "119:\tlearn: 6.2946685\ttest: 6.2914578\tbest: 6.2914578 (119)\ttotal: 1m 22s\tremaining: 10m 1s\n",
      "120:\tlearn: 6.2945205\ttest: 6.2913173\tbest: 6.2913173 (120)\ttotal: 1m 22s\tremaining: 10m 1s\n",
      "121:\tlearn: 6.2943432\ttest: 6.2911544\tbest: 6.2911544 (121)\ttotal: 1m 23s\tremaining: 10m\n",
      "122:\tlearn: 6.2941904\ttest: 6.2910474\tbest: 6.2910474 (122)\ttotal: 1m 24s\tremaining: 9m 59s\n",
      "123:\tlearn: 6.2940538\ttest: 6.2909230\tbest: 6.2909230 (123)\ttotal: 1m 24s\tremaining: 9m 59s\n",
      "124:\tlearn: 6.2938620\ttest: 6.2907622\tbest: 6.2907622 (124)\ttotal: 1m 25s\tremaining: 9m 58s\n",
      "125:\tlearn: 6.2936969\ttest: 6.2906075\tbest: 6.2906075 (125)\ttotal: 1m 26s\tremaining: 9m 57s\n",
      "126:\tlearn: 6.2934637\ttest: 6.2903827\tbest: 6.2903827 (126)\ttotal: 1m 26s\tremaining: 9m 56s\n",
      "127:\tlearn: 6.2933441\ttest: 6.2902703\tbest: 6.2902703 (127)\ttotal: 1m 27s\tremaining: 9m 55s\n",
      "128:\tlearn: 6.2932317\ttest: 6.2901922\tbest: 6.2901922 (128)\ttotal: 1m 28s\tremaining: 9m 55s\n",
      "129:\tlearn: 6.2931358\ttest: 6.2900829\tbest: 6.2900829 (129)\ttotal: 1m 28s\tremaining: 9m 54s\n",
      "130:\tlearn: 6.2930369\ttest: 6.2899797\tbest: 6.2899797 (130)\ttotal: 1m 29s\tremaining: 9m 53s\n",
      "131:\tlearn: 6.2928747\ttest: 6.2897900\tbest: 6.2897900 (131)\ttotal: 1m 30s\tremaining: 9m 52s\n",
      "132:\tlearn: 6.2927197\ttest: 6.2896856\tbest: 6.2896856 (132)\ttotal: 1m 30s\tremaining: 9m 52s\n",
      "133:\tlearn: 6.2925129\ttest: 6.2894775\tbest: 6.2894775 (133)\ttotal: 1m 31s\tremaining: 9m 51s\n",
      "134:\tlearn: 6.2923263\ttest: 6.2892800\tbest: 6.2892800 (134)\ttotal: 1m 32s\tremaining: 9m 50s\n",
      "135:\tlearn: 6.2921744\ttest: 6.2891317\tbest: 6.2891317 (135)\ttotal: 1m 32s\tremaining: 9m 49s\n",
      "136:\tlearn: 6.2920368\ttest: 6.2889989\tbest: 6.2889989 (136)\ttotal: 1m 33s\tremaining: 9m 48s\n",
      "137:\tlearn: 6.2919084\ttest: 6.2888753\tbest: 6.2888753 (137)\ttotal: 1m 34s\tremaining: 9m 47s\n",
      "138:\tlearn: 6.2917567\ttest: 6.2887134\tbest: 6.2887134 (138)\ttotal: 1m 34s\tremaining: 9m 46s\n",
      "139:\tlearn: 6.2916652\ttest: 6.2886429\tbest: 6.2886429 (139)\ttotal: 1m 35s\tremaining: 9m 45s\n",
      "140:\tlearn: 6.2915720\ttest: 6.2885511\tbest: 6.2885511 (140)\ttotal: 1m 35s\tremaining: 9m 44s\n",
      "141:\tlearn: 6.2914003\ttest: 6.2883817\tbest: 6.2883817 (141)\ttotal: 1m 36s\tremaining: 9m 43s\n",
      "142:\tlearn: 6.2912359\ttest: 6.2882295\tbest: 6.2882295 (142)\ttotal: 1m 37s\tremaining: 9m 42s\n",
      "143:\tlearn: 6.2910350\ttest: 6.2880148\tbest: 6.2880148 (143)\ttotal: 1m 37s\tremaining: 9m 41s\n",
      "144:\tlearn: 6.2908430\ttest: 6.2878301\tbest: 6.2878301 (144)\ttotal: 1m 38s\tremaining: 9m 41s\n",
      "145:\tlearn: 6.2906679\ttest: 6.2877021\tbest: 6.2877021 (145)\ttotal: 1m 39s\tremaining: 9m 40s\n",
      "146:\tlearn: 6.2905630\ttest: 6.2876366\tbest: 6.2876366 (146)\ttotal: 1m 39s\tremaining: 9m 39s\n",
      "147:\tlearn: 6.2904663\ttest: 6.2875613\tbest: 6.2875613 (147)\ttotal: 1m 40s\tremaining: 9m 39s\n",
      "148:\tlearn: 6.2903215\ttest: 6.2874288\tbest: 6.2874288 (148)\ttotal: 1m 41s\tremaining: 9m 38s\n",
      "149:\tlearn: 6.2901668\ttest: 6.2872903\tbest: 6.2872903 (149)\ttotal: 1m 42s\tremaining: 9m 38s\n",
      "150:\tlearn: 6.2899905\ttest: 6.2871021\tbest: 6.2871021 (150)\ttotal: 1m 42s\tremaining: 9m 38s\n",
      "151:\tlearn: 6.2898985\ttest: 6.2870077\tbest: 6.2870077 (151)\ttotal: 1m 43s\tremaining: 9m 37s\n",
      "152:\tlearn: 6.2897703\ttest: 6.2869233\tbest: 6.2869233 (152)\ttotal: 1m 44s\tremaining: 9m 36s\n",
      "153:\tlearn: 6.2896336\ttest: 6.2868241\tbest: 6.2868241 (153)\ttotal: 1m 44s\tremaining: 9m 35s\n",
      "154:\tlearn: 6.2895208\ttest: 6.2867381\tbest: 6.2867381 (154)\ttotal: 1m 45s\tremaining: 9m 34s\n",
      "155:\tlearn: 6.2893246\ttest: 6.2865560\tbest: 6.2865560 (155)\ttotal: 1m 46s\tremaining: 9m 34s\n",
      "156:\tlearn: 6.2892121\ttest: 6.2864968\tbest: 6.2864968 (156)\ttotal: 1m 46s\tremaining: 9m 33s\n",
      "157:\tlearn: 6.2890639\ttest: 6.2863280\tbest: 6.2863280 (157)\ttotal: 1m 47s\tremaining: 9m 32s\n",
      "158:\tlearn: 6.2889235\ttest: 6.2861938\tbest: 6.2861938 (158)\ttotal: 1m 48s\tremaining: 9m 31s\n",
      "159:\tlearn: 6.2888230\ttest: 6.2861216\tbest: 6.2861216 (159)\ttotal: 1m 48s\tremaining: 9m 30s\n",
      "160:\tlearn: 6.2886721\ttest: 6.2859848\tbest: 6.2859848 (160)\ttotal: 1m 49s\tremaining: 9m 29s\n",
      "161:\tlearn: 6.2886274\ttest: 6.2859342\tbest: 6.2859342 (161)\ttotal: 1m 49s\tremaining: 9m 28s\n",
      "162:\tlearn: 6.2885192\ttest: 6.2858340\tbest: 6.2858340 (162)\ttotal: 1m 50s\tremaining: 9m 28s\n",
      "163:\tlearn: 6.2883542\ttest: 6.2857088\tbest: 6.2857088 (163)\ttotal: 1m 51s\tremaining: 9m 27s\n",
      "164:\tlearn: 6.2882765\ttest: 6.2856646\tbest: 6.2856646 (164)\ttotal: 1m 51s\tremaining: 9m 26s\n",
      "165:\tlearn: 6.2881552\ttest: 6.2855551\tbest: 6.2855551 (165)\ttotal: 1m 52s\tremaining: 9m 25s\n",
      "166:\tlearn: 6.2880674\ttest: 6.2854693\tbest: 6.2854693 (166)\ttotal: 1m 53s\tremaining: 9m 25s\n",
      "167:\tlearn: 6.2878990\ttest: 6.2853133\tbest: 6.2853133 (167)\ttotal: 1m 53s\tremaining: 9m 24s\n",
      "168:\tlearn: 6.2877848\ttest: 6.2851891\tbest: 6.2851891 (168)\ttotal: 1m 54s\tremaining: 9m 23s\n",
      "169:\tlearn: 6.2876837\ttest: 6.2850948\tbest: 6.2850948 (169)\ttotal: 1m 55s\tremaining: 9m 23s\n",
      "170:\tlearn: 6.2875105\ttest: 6.2849459\tbest: 6.2849459 (170)\ttotal: 1m 55s\tremaining: 9m 22s\n",
      "171:\tlearn: 6.2873619\ttest: 6.2848106\tbest: 6.2848106 (171)\ttotal: 1m 56s\tremaining: 9m 21s\n",
      "172:\tlearn: 6.2871902\ttest: 6.2846327\tbest: 6.2846327 (172)\ttotal: 1m 57s\tremaining: 9m 20s\n",
      "173:\tlearn: 6.2870820\ttest: 6.2845049\tbest: 6.2845049 (173)\ttotal: 1m 57s\tremaining: 9m 19s\n",
      "174:\tlearn: 6.2869630\ttest: 6.2844296\tbest: 6.2844296 (174)\ttotal: 1m 58s\tremaining: 9m 19s\n",
      "175:\tlearn: 6.2868605\ttest: 6.2843476\tbest: 6.2843476 (175)\ttotal: 1m 59s\tremaining: 9m 18s\n",
      "176:\tlearn: 6.2867702\ttest: 6.2842597\tbest: 6.2842597 (176)\ttotal: 2m\tremaining: 9m 18s\n",
      "177:\tlearn: 6.2867186\ttest: 6.2842128\tbest: 6.2842128 (177)\ttotal: 2m\tremaining: 9m 17s\n",
      "178:\tlearn: 6.2866109\ttest: 6.2841221\tbest: 6.2841221 (178)\ttotal: 2m 1s\tremaining: 9m 16s\n",
      "179:\tlearn: 6.2864980\ttest: 6.2840061\tbest: 6.2840061 (179)\ttotal: 2m 1s\tremaining: 9m 15s\n",
      "180:\tlearn: 6.2864180\ttest: 6.2839560\tbest: 6.2839560 (180)\ttotal: 2m 2s\tremaining: 9m 14s\n",
      "181:\tlearn: 6.2861947\ttest: 6.2837130\tbest: 6.2837130 (181)\ttotal: 2m 3s\tremaining: 9m 14s\n",
      "182:\tlearn: 6.2861046\ttest: 6.2836503\tbest: 6.2836503 (182)\ttotal: 2m 4s\tremaining: 9m 13s\n",
      "183:\tlearn: 6.2860231\ttest: 6.2835759\tbest: 6.2835759 (183)\ttotal: 2m 4s\tremaining: 9m 12s\n",
      "184:\tlearn: 6.2859029\ttest: 6.2834693\tbest: 6.2834693 (184)\ttotal: 2m 5s\tremaining: 9m 11s\n",
      "185:\tlearn: 6.2857574\ttest: 6.2833034\tbest: 6.2833034 (185)\ttotal: 2m 5s\tremaining: 9m 11s\n",
      "186:\tlearn: 6.2856615\ttest: 6.2832477\tbest: 6.2832477 (186)\ttotal: 2m 6s\tremaining: 9m 10s\n",
      "187:\tlearn: 6.2855617\ttest: 6.2831433\tbest: 6.2831433 (187)\ttotal: 2m 7s\tremaining: 9m 9s\n",
      "188:\tlearn: 6.2854159\ttest: 6.2829980\tbest: 6.2829980 (188)\ttotal: 2m 7s\tremaining: 9m 8s\n",
      "189:\tlearn: 6.2853164\ttest: 6.2829108\tbest: 6.2829108 (189)\ttotal: 2m 8s\tremaining: 9m 8s\n",
      "190:\tlearn: 6.2852165\ttest: 6.2828420\tbest: 6.2828420 (190)\ttotal: 2m 9s\tremaining: 9m 7s\n",
      "191:\tlearn: 6.2851342\ttest: 6.2827952\tbest: 6.2827952 (191)\ttotal: 2m 9s\tremaining: 9m 6s\n",
      "192:\tlearn: 6.2850290\ttest: 6.2826917\tbest: 6.2826917 (192)\ttotal: 2m 10s\tremaining: 9m 5s\n",
      "193:\tlearn: 6.2849433\ttest: 6.2826197\tbest: 6.2826197 (193)\ttotal: 2m 11s\tremaining: 9m 4s\n",
      "194:\tlearn: 6.2848637\ttest: 6.2825440\tbest: 6.2825440 (194)\ttotal: 2m 11s\tremaining: 9m 4s\n",
      "195:\tlearn: 6.2847826\ttest: 6.2824618\tbest: 6.2824618 (195)\ttotal: 2m 12s\tremaining: 9m 3s\n",
      "196:\tlearn: 6.2847193\ttest: 6.2824282\tbest: 6.2824282 (196)\ttotal: 2m 13s\tremaining: 9m 2s\n",
      "197:\tlearn: 6.2845920\ttest: 6.2823348\tbest: 6.2823348 (197)\ttotal: 2m 13s\tremaining: 9m 2s\n",
      "198:\tlearn: 6.2845353\ttest: 6.2822869\tbest: 6.2822869 (198)\ttotal: 2m 14s\tremaining: 9m 1s\n",
      "199:\tlearn: 6.2844713\ttest: 6.2822278\tbest: 6.2822278 (199)\ttotal: 2m 15s\tremaining: 9m\n",
      "200:\tlearn: 6.2843786\ttest: 6.2821268\tbest: 6.2821268 (200)\ttotal: 2m 15s\tremaining: 8m 59s\n",
      "201:\tlearn: 6.2843238\ttest: 6.2820806\tbest: 6.2820806 (201)\ttotal: 2m 16s\tremaining: 8m 58s\n",
      "202:\tlearn: 6.2841786\ttest: 6.2819427\tbest: 6.2819427 (202)\ttotal: 2m 17s\tremaining: 8m 58s\n",
      "203:\tlearn: 6.2840611\ttest: 6.2818238\tbest: 6.2818238 (203)\ttotal: 2m 17s\tremaining: 8m 57s\n",
      "204:\tlearn: 6.2839461\ttest: 6.2817004\tbest: 6.2817004 (204)\ttotal: 2m 18s\tremaining: 8m 56s\n",
      "205:\tlearn: 6.2838642\ttest: 6.2816208\tbest: 6.2816208 (205)\ttotal: 2m 19s\tremaining: 8m 56s\n",
      "206:\tlearn: 6.2837779\ttest: 6.2815539\tbest: 6.2815539 (206)\ttotal: 2m 19s\tremaining: 8m 55s\n",
      "207:\tlearn: 6.2836713\ttest: 6.2814633\tbest: 6.2814633 (207)\ttotal: 2m 20s\tremaining: 8m 54s\n",
      "208:\tlearn: 6.2836220\ttest: 6.2814080\tbest: 6.2814080 (208)\ttotal: 2m 21s\tremaining: 8m 54s\n",
      "209:\tlearn: 6.2834993\ttest: 6.2812792\tbest: 6.2812792 (209)\ttotal: 2m 21s\tremaining: 8m 53s\n",
      "210:\tlearn: 6.2833796\ttest: 6.2811623\tbest: 6.2811623 (210)\ttotal: 2m 22s\tremaining: 8m 52s\n",
      "211:\tlearn: 6.2832654\ttest: 6.2810482\tbest: 6.2810482 (211)\ttotal: 2m 23s\tremaining: 8m 51s\n",
      "212:\tlearn: 6.2832266\ttest: 6.2810171\tbest: 6.2810171 (212)\ttotal: 2m 23s\tremaining: 8m 51s\n",
      "213:\tlearn: 6.2831460\ttest: 6.2809366\tbest: 6.2809366 (213)\ttotal: 2m 24s\tremaining: 8m 50s\n",
      "214:\tlearn: 6.2830790\ttest: 6.2809051\tbest: 6.2809051 (214)\ttotal: 2m 25s\tremaining: 8m 49s\n",
      "215:\tlearn: 6.2829779\ttest: 6.2808136\tbest: 6.2808136 (215)\ttotal: 2m 25s\tremaining: 8m 48s\n",
      "216:\tlearn: 6.2828613\ttest: 6.2807240\tbest: 6.2807240 (216)\ttotal: 2m 26s\tremaining: 8m 48s\n",
      "217:\tlearn: 6.2828011\ttest: 6.2806628\tbest: 6.2806628 (217)\ttotal: 2m 27s\tremaining: 8m 47s\n",
      "218:\tlearn: 6.2827415\ttest: 6.2806084\tbest: 6.2806084 (218)\ttotal: 2m 27s\tremaining: 8m 47s\n",
      "219:\tlearn: 6.2825529\ttest: 6.2804179\tbest: 6.2804179 (219)\ttotal: 2m 28s\tremaining: 8m 46s\n",
      "220:\tlearn: 6.2824834\ttest: 6.2803464\tbest: 6.2803464 (220)\ttotal: 2m 29s\tremaining: 8m 45s\n",
      "221:\tlearn: 6.2824045\ttest: 6.2802756\tbest: 6.2802756 (221)\ttotal: 2m 29s\tremaining: 8m 44s\n",
      "222:\tlearn: 6.2823213\ttest: 6.2802065\tbest: 6.2802065 (222)\ttotal: 2m 30s\tremaining: 8m 44s\n",
      "223:\tlearn: 6.2822861\ttest: 6.2801898\tbest: 6.2801898 (223)\ttotal: 2m 31s\tremaining: 8m 43s\n",
      "224:\tlearn: 6.2821574\ttest: 6.2800681\tbest: 6.2800681 (224)\ttotal: 2m 31s\tremaining: 8m 42s\n",
      "225:\tlearn: 6.2820207\ttest: 6.2799241\tbest: 6.2799241 (225)\ttotal: 2m 32s\tremaining: 8m 42s\n",
      "226:\tlearn: 6.2819405\ttest: 6.2798370\tbest: 6.2798370 (226)\ttotal: 2m 33s\tremaining: 8m 41s\n",
      "227:\tlearn: 6.2818889\ttest: 6.2797966\tbest: 6.2797966 (227)\ttotal: 2m 33s\tremaining: 8m 41s\n",
      "228:\tlearn: 6.2818370\ttest: 6.2797692\tbest: 6.2797692 (228)\ttotal: 2m 34s\tremaining: 8m 40s\n",
      "229:\tlearn: 6.2817493\ttest: 6.2797001\tbest: 6.2797001 (229)\ttotal: 2m 35s\tremaining: 8m 39s\n",
      "230:\tlearn: 6.2816403\ttest: 6.2796047\tbest: 6.2796047 (230)\ttotal: 2m 35s\tremaining: 8m 39s\n",
      "231:\tlearn: 6.2815979\ttest: 6.2795621\tbest: 6.2795621 (231)\ttotal: 2m 36s\tremaining: 8m 38s\n",
      "232:\tlearn: 6.2815123\ttest: 6.2794667\tbest: 6.2794667 (232)\ttotal: 2m 37s\tremaining: 8m 37s\n",
      "233:\tlearn: 6.2814567\ttest: 6.2794199\tbest: 6.2794199 (233)\ttotal: 2m 37s\tremaining: 8m 36s\n",
      "234:\tlearn: 6.2813486\ttest: 6.2793117\tbest: 6.2793117 (234)\ttotal: 2m 38s\tremaining: 8m 36s\n",
      "235:\tlearn: 6.2812939\ttest: 6.2792569\tbest: 6.2792569 (235)\ttotal: 2m 39s\tremaining: 8m 35s\n",
      "236:\tlearn: 6.2812216\ttest: 6.2792099\tbest: 6.2792099 (236)\ttotal: 2m 39s\tremaining: 8m 34s\n",
      "237:\tlearn: 6.2811561\ttest: 6.2791223\tbest: 6.2791223 (237)\ttotal: 2m 40s\tremaining: 8m 33s\n",
      "238:\tlearn: 6.2810725\ttest: 6.2790509\tbest: 6.2790509 (238)\ttotal: 2m 41s\tremaining: 8m 32s\n",
      "239:\tlearn: 6.2810052\ttest: 6.2789807\tbest: 6.2789807 (239)\ttotal: 2m 41s\tremaining: 8m 32s\n",
      "240:\tlearn: 6.2809330\ttest: 6.2789057\tbest: 6.2789057 (240)\ttotal: 2m 42s\tremaining: 8m 31s\n",
      "241:\tlearn: 6.2808355\ttest: 6.2788265\tbest: 6.2788265 (241)\ttotal: 2m 43s\tremaining: 8m 30s\n",
      "242:\tlearn: 6.2807610\ttest: 6.2787449\tbest: 6.2787449 (242)\ttotal: 2m 43s\tremaining: 8m 29s\n",
      "243:\tlearn: 6.2806739\ttest: 6.2786514\tbest: 6.2786514 (243)\ttotal: 2m 44s\tremaining: 8m 29s\n",
      "244:\tlearn: 6.2806159\ttest: 6.2786132\tbest: 6.2786132 (244)\ttotal: 2m 45s\tremaining: 8m 28s\n",
      "245:\tlearn: 6.2805628\ttest: 6.2785523\tbest: 6.2785523 (245)\ttotal: 2m 45s\tremaining: 8m 27s\n",
      "246:\tlearn: 6.2804805\ttest: 6.2784835\tbest: 6.2784835 (246)\ttotal: 2m 46s\tremaining: 8m 27s\n",
      "247:\tlearn: 6.2803995\ttest: 6.2784181\tbest: 6.2784181 (247)\ttotal: 2m 47s\tremaining: 8m 26s\n",
      "248:\tlearn: 6.2803575\ttest: 6.2783957\tbest: 6.2783957 (248)\ttotal: 2m 47s\tremaining: 8m 25s\n",
      "249:\tlearn: 6.2802710\ttest: 6.2783317\tbest: 6.2783317 (249)\ttotal: 2m 48s\tremaining: 8m 24s\n",
      "250:\tlearn: 6.2802223\ttest: 6.2782887\tbest: 6.2782887 (250)\ttotal: 2m 48s\tremaining: 8m 23s\n",
      "251:\tlearn: 6.2801518\ttest: 6.2782191\tbest: 6.2782191 (251)\ttotal: 2m 49s\tremaining: 8m 23s\n",
      "252:\tlearn: 6.2801132\ttest: 6.2781931\tbest: 6.2781931 (252)\ttotal: 2m 50s\tremaining: 8m 22s\n",
      "253:\tlearn: 6.2800409\ttest: 6.2781169\tbest: 6.2781169 (253)\ttotal: 2m 50s\tremaining: 8m 22s\n",
      "254:\tlearn: 6.2799222\ttest: 6.2780014\tbest: 6.2780014 (254)\ttotal: 2m 51s\tremaining: 8m 21s\n",
      "255:\tlearn: 6.2798418\ttest: 6.2779509\tbest: 6.2779509 (255)\ttotal: 2m 52s\tremaining: 8m 20s\n",
      "256:\tlearn: 6.2797655\ttest: 6.2778981\tbest: 6.2778981 (256)\ttotal: 2m 52s\tremaining: 8m 20s\n",
      "257:\tlearn: 6.2796713\ttest: 6.2778082\tbest: 6.2778082 (257)\ttotal: 2m 53s\tremaining: 8m 19s\n",
      "258:\tlearn: 6.2796340\ttest: 6.2777574\tbest: 6.2777574 (258)\ttotal: 2m 54s\tremaining: 8m 18s\n",
      "259:\tlearn: 6.2795887\ttest: 6.2777139\tbest: 6.2777139 (259)\ttotal: 2m 55s\tremaining: 8m 18s\n",
      "260:\tlearn: 6.2795371\ttest: 6.2776805\tbest: 6.2776805 (260)\ttotal: 2m 55s\tremaining: 8m 17s\n",
      "261:\tlearn: 6.2794912\ttest: 6.2776471\tbest: 6.2776471 (261)\ttotal: 2m 56s\tremaining: 8m 16s\n",
      "262:\tlearn: 6.2793723\ttest: 6.2775156\tbest: 6.2775156 (262)\ttotal: 2m 57s\tremaining: 8m 16s\n",
      "263:\tlearn: 6.2793120\ttest: 6.2774524\tbest: 6.2774524 (263)\ttotal: 2m 57s\tremaining: 8m 15s\n",
      "264:\tlearn: 6.2791750\ttest: 6.2772977\tbest: 6.2772977 (264)\ttotal: 2m 58s\tremaining: 8m 14s\n",
      "265:\tlearn: 6.2791154\ttest: 6.2772646\tbest: 6.2772646 (265)\ttotal: 2m 59s\tremaining: 8m 13s\n",
      "266:\tlearn: 6.2790877\ttest: 6.2772386\tbest: 6.2772386 (266)\ttotal: 2m 59s\tremaining: 8m 13s\n",
      "267:\tlearn: 6.2790196\ttest: 6.2771879\tbest: 6.2771879 (267)\ttotal: 3m\tremaining: 8m 12s\n",
      "268:\tlearn: 6.2789763\ttest: 6.2771361\tbest: 6.2771361 (268)\ttotal: 3m 1s\tremaining: 8m 11s\n",
      "269:\tlearn: 6.2789161\ttest: 6.2770899\tbest: 6.2770899 (269)\ttotal: 3m 1s\tremaining: 8m 11s\n",
      "270:\tlearn: 6.2788655\ttest: 6.2770421\tbest: 6.2770421 (270)\ttotal: 3m 2s\tremaining: 8m 10s\n",
      "271:\tlearn: 6.2787939\ttest: 6.2769973\tbest: 6.2769973 (271)\ttotal: 3m 2s\tremaining: 8m 9s\n",
      "272:\tlearn: 6.2787334\ttest: 6.2769523\tbest: 6.2769523 (272)\ttotal: 3m 3s\tremaining: 8m 9s\n",
      "273:\tlearn: 6.2786346\ttest: 6.2768781\tbest: 6.2768781 (273)\ttotal: 3m 4s\tremaining: 8m 8s\n",
      "274:\tlearn: 6.2785231\ttest: 6.2767661\tbest: 6.2767661 (274)\ttotal: 3m 5s\tremaining: 8m 7s\n",
      "275:\tlearn: 6.2784743\ttest: 6.2767039\tbest: 6.2767039 (275)\ttotal: 3m 5s\tremaining: 8m 7s\n",
      "276:\tlearn: 6.2783858\ttest: 6.2766288\tbest: 6.2766288 (276)\ttotal: 3m 6s\tremaining: 8m 6s\n",
      "277:\tlearn: 6.2783195\ttest: 6.2765855\tbest: 6.2765855 (277)\ttotal: 3m 6s\tremaining: 8m 5s\n",
      "278:\tlearn: 6.2781730\ttest: 6.2764062\tbest: 6.2764062 (278)\ttotal: 3m 7s\tremaining: 8m 5s\n",
      "279:\tlearn: 6.2781314\ttest: 6.2763814\tbest: 6.2763814 (279)\ttotal: 3m 8s\tremaining: 8m 4s\n",
      "280:\tlearn: 6.2780056\ttest: 6.2762409\tbest: 6.2762409 (280)\ttotal: 3m 9s\tremaining: 8m 3s\n",
      "281:\tlearn: 6.2779576\ttest: 6.2762071\tbest: 6.2762071 (281)\ttotal: 3m 9s\tremaining: 8m 3s\n",
      "282:\tlearn: 6.2779125\ttest: 6.2761964\tbest: 6.2761964 (282)\ttotal: 3m 10s\tremaining: 8m 2s\n",
      "283:\tlearn: 6.2778302\ttest: 6.2761056\tbest: 6.2761056 (283)\ttotal: 3m 11s\tremaining: 8m 2s\n",
      "284:\tlearn: 6.2778046\ttest: 6.2760777\tbest: 6.2760777 (284)\ttotal: 3m 11s\tremaining: 8m 1s\n",
      "285:\tlearn: 6.2777476\ttest: 6.2760355\tbest: 6.2760355 (285)\ttotal: 3m 12s\tremaining: 8m\n",
      "286:\tlearn: 6.2776617\ttest: 6.2759640\tbest: 6.2759640 (286)\ttotal: 3m 13s\tremaining: 7m 59s\n",
      "287:\tlearn: 6.2776168\ttest: 6.2759362\tbest: 6.2759362 (287)\ttotal: 3m 13s\tremaining: 7m 58s\n",
      "288:\tlearn: 6.2775637\ttest: 6.2758736\tbest: 6.2758736 (288)\ttotal: 3m 14s\tremaining: 7m 58s\n",
      "289:\tlearn: 6.2774996\ttest: 6.2758277\tbest: 6.2758277 (289)\ttotal: 3m 15s\tremaining: 7m 57s\n",
      "290:\tlearn: 6.2774361\ttest: 6.2757792\tbest: 6.2757792 (290)\ttotal: 3m 15s\tremaining: 7m 56s\n",
      "291:\tlearn: 6.2772755\ttest: 6.2756214\tbest: 6.2756214 (291)\ttotal: 3m 16s\tremaining: 7m 56s\n",
      "292:\tlearn: 6.2772210\ttest: 6.2755688\tbest: 6.2755688 (292)\ttotal: 3m 17s\tremaining: 7m 55s\n",
      "293:\tlearn: 6.2771492\ttest: 6.2755137\tbest: 6.2755137 (293)\ttotal: 3m 17s\tremaining: 7m 54s\n",
      "294:\tlearn: 6.2770926\ttest: 6.2754613\tbest: 6.2754613 (294)\ttotal: 3m 18s\tremaining: 7m 53s\n",
      "295:\tlearn: 6.2770664\ttest: 6.2754448\tbest: 6.2754448 (295)\ttotal: 3m 18s\tremaining: 7m 53s\n",
      "296:\tlearn: 6.2769881\ttest: 6.2753665\tbest: 6.2753665 (296)\ttotal: 3m 19s\tremaining: 7m 52s\n",
      "297:\tlearn: 6.2769417\ttest: 6.2753089\tbest: 6.2753089 (297)\ttotal: 3m 20s\tremaining: 7m 51s\n",
      "298:\tlearn: 6.2768085\ttest: 6.2751615\tbest: 6.2751615 (298)\ttotal: 3m 20s\tremaining: 7m 51s\n",
      "299:\tlearn: 6.2767604\ttest: 6.2751380\tbest: 6.2751380 (299)\ttotal: 3m 21s\tremaining: 7m 50s\n",
      "300:\tlearn: 6.2767131\ttest: 6.2751067\tbest: 6.2751067 (300)\ttotal: 3m 22s\tremaining: 7m 49s\n",
      "301:\tlearn: 6.2766648\ttest: 6.2750818\tbest: 6.2750818 (301)\ttotal: 3m 22s\tremaining: 7m 48s\n",
      "302:\tlearn: 6.2766301\ttest: 6.2750356\tbest: 6.2750356 (302)\ttotal: 3m 23s\tremaining: 7m 48s\n",
      "303:\tlearn: 6.2765459\ttest: 6.2749561\tbest: 6.2749561 (303)\ttotal: 3m 24s\tremaining: 7m 47s\n",
      "304:\tlearn: 6.2764988\ttest: 6.2749211\tbest: 6.2749211 (304)\ttotal: 3m 24s\tremaining: 7m 46s\n",
      "305:\tlearn: 6.2764387\ttest: 6.2748721\tbest: 6.2748721 (305)\ttotal: 3m 25s\tremaining: 7m 45s\n",
      "306:\tlearn: 6.2763727\ttest: 6.2747948\tbest: 6.2747948 (306)\ttotal: 3m 26s\tremaining: 7m 45s\n",
      "307:\tlearn: 6.2763252\ttest: 6.2747562\tbest: 6.2747562 (307)\ttotal: 3m 26s\tremaining: 7m 44s\n",
      "308:\tlearn: 6.2762731\ttest: 6.2747390\tbest: 6.2747390 (308)\ttotal: 3m 27s\tremaining: 7m 43s\n",
      "309:\tlearn: 6.2762329\ttest: 6.2747060\tbest: 6.2747060 (309)\ttotal: 3m 28s\tremaining: 7m 43s\n",
      "310:\tlearn: 6.2761828\ttest: 6.2746691\tbest: 6.2746691 (310)\ttotal: 3m 28s\tremaining: 7m 42s\n",
      "311:\tlearn: 6.2761108\ttest: 6.2746115\tbest: 6.2746115 (311)\ttotal: 3m 29s\tremaining: 7m 41s\n",
      "312:\tlearn: 6.2760617\ttest: 6.2745761\tbest: 6.2745761 (312)\ttotal: 3m 29s\tremaining: 7m 40s\n",
      "313:\tlearn: 6.2760148\ttest: 6.2745620\tbest: 6.2745620 (313)\ttotal: 3m 30s\tremaining: 7m 40s\n",
      "314:\tlearn: 6.2759521\ttest: 6.2745031\tbest: 6.2745031 (314)\ttotal: 3m 31s\tremaining: 7m 39s\n",
      "315:\tlearn: 6.2758237\ttest: 6.2743880\tbest: 6.2743880 (315)\ttotal: 3m 31s\tremaining: 7m 38s\n",
      "316:\tlearn: 6.2757761\ttest: 6.2743567\tbest: 6.2743567 (316)\ttotal: 3m 32s\tremaining: 7m 37s\n",
      "317:\tlearn: 6.2757340\ttest: 6.2742925\tbest: 6.2742925 (317)\ttotal: 3m 33s\tremaining: 7m 37s\n",
      "318:\tlearn: 6.2756716\ttest: 6.2742387\tbest: 6.2742387 (318)\ttotal: 3m 33s\tremaining: 7m 36s\n",
      "319:\tlearn: 6.2756011\ttest: 6.2741984\tbest: 6.2741984 (319)\ttotal: 3m 34s\tremaining: 7m 35s\n",
      "320:\tlearn: 6.2755693\ttest: 6.2741663\tbest: 6.2741663 (320)\ttotal: 3m 35s\tremaining: 7m 34s\n",
      "321:\tlearn: 6.2755152\ttest: 6.2740981\tbest: 6.2740981 (321)\ttotal: 3m 35s\tremaining: 7m 34s\n",
      "322:\tlearn: 6.2754891\ttest: 6.2740780\tbest: 6.2740780 (322)\ttotal: 3m 36s\tremaining: 7m 33s\n",
      "323:\tlearn: 6.2754176\ttest: 6.2740198\tbest: 6.2740198 (323)\ttotal: 3m 36s\tremaining: 7m 32s\n",
      "324:\tlearn: 6.2753347\ttest: 6.2739271\tbest: 6.2739271 (324)\ttotal: 3m 37s\tremaining: 7m 32s\n",
      "325:\tlearn: 6.2752657\ttest: 6.2738520\tbest: 6.2738520 (325)\ttotal: 3m 38s\tremaining: 7m 31s\n",
      "326:\tlearn: 6.2752423\ttest: 6.2738269\tbest: 6.2738269 (326)\ttotal: 3m 38s\tremaining: 7m 30s\n",
      "327:\tlearn: 6.2751753\ttest: 6.2737730\tbest: 6.2737730 (327)\ttotal: 3m 39s\tremaining: 7m 30s\n",
      "328:\tlearn: 6.2751227\ttest: 6.2737275\tbest: 6.2737275 (328)\ttotal: 3m 40s\tremaining: 7m 29s\n",
      "329:\tlearn: 6.2750482\ttest: 6.2736648\tbest: 6.2736648 (329)\ttotal: 3m 40s\tremaining: 7m 28s\n",
      "330:\tlearn: 6.2750163\ttest: 6.2736257\tbest: 6.2736257 (330)\ttotal: 3m 41s\tremaining: 7m 27s\n",
      "331:\tlearn: 6.2749783\ttest: 6.2735915\tbest: 6.2735915 (331)\ttotal: 3m 42s\tremaining: 7m 27s\n",
      "332:\tlearn: 6.2749257\ttest: 6.2735326\tbest: 6.2735326 (332)\ttotal: 3m 42s\tremaining: 7m 26s\n",
      "333:\tlearn: 6.2748733\ttest: 6.2734945\tbest: 6.2734945 (333)\ttotal: 3m 43s\tremaining: 7m 25s\n",
      "334:\tlearn: 6.2748213\ttest: 6.2734408\tbest: 6.2734408 (334)\ttotal: 3m 44s\tremaining: 7m 25s\n",
      "335:\tlearn: 6.2747293\ttest: 6.2733683\tbest: 6.2733683 (335)\ttotal: 3m 44s\tremaining: 7m 24s\n",
      "336:\tlearn: 6.2746857\ttest: 6.2733402\tbest: 6.2733402 (336)\ttotal: 3m 45s\tremaining: 7m 23s\n",
      "337:\tlearn: 6.2746549\ttest: 6.2733234\tbest: 6.2733234 (337)\ttotal: 3m 46s\tremaining: 7m 23s\n",
      "338:\tlearn: 6.2746193\ttest: 6.2732888\tbest: 6.2732888 (338)\ttotal: 3m 46s\tremaining: 7m 22s\n",
      "339:\tlearn: 6.2745711\ttest: 6.2732592\tbest: 6.2732592 (339)\ttotal: 3m 47s\tremaining: 7m 21s\n",
      "340:\tlearn: 6.2745219\ttest: 6.2732065\tbest: 6.2732065 (340)\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "341:\tlearn: 6.2744810\ttest: 6.2731538\tbest: 6.2731538 (341)\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "342:\tlearn: 6.2744464\ttest: 6.2731295\tbest: 6.2731295 (342)\ttotal: 3m 49s\tremaining: 7m 19s\n",
      "343:\tlearn: 6.2744186\ttest: 6.2731036\tbest: 6.2731036 (343)\ttotal: 3m 49s\tremaining: 7m 18s\n",
      "344:\tlearn: 6.2743397\ttest: 6.2730364\tbest: 6.2730364 (344)\ttotal: 3m 50s\tremaining: 7m 17s\n",
      "345:\tlearn: 6.2742092\ttest: 6.2728906\tbest: 6.2728906 (345)\ttotal: 3m 51s\tremaining: 7m 17s\n",
      "346:\tlearn: 6.2741780\ttest: 6.2728585\tbest: 6.2728585 (346)\ttotal: 3m 51s\tremaining: 7m 16s\n",
      "347:\tlearn: 6.2741230\ttest: 6.2728194\tbest: 6.2728194 (347)\ttotal: 3m 52s\tremaining: 7m 16s\n",
      "348:\tlearn: 6.2740749\ttest: 6.2727955\tbest: 6.2727955 (348)\ttotal: 3m 53s\tremaining: 7m 15s\n",
      "349:\tlearn: 6.2740436\ttest: 6.2727774\tbest: 6.2727774 (349)\ttotal: 3m 54s\tremaining: 7m 14s\n",
      "350:\tlearn: 6.2739992\ttest: 6.2727506\tbest: 6.2727506 (350)\ttotal: 3m 54s\tremaining: 7m 14s\n",
      "351:\tlearn: 6.2739496\ttest: 6.2727064\tbest: 6.2727064 (351)\ttotal: 3m 55s\tremaining: 7m 13s\n",
      "352:\tlearn: 6.2739108\ttest: 6.2726703\tbest: 6.2726703 (352)\ttotal: 3m 56s\tremaining: 7m 12s\n",
      "353:\tlearn: 6.2738685\ttest: 6.2726465\tbest: 6.2726465 (353)\ttotal: 3m 56s\tremaining: 7m 12s\n",
      "354:\tlearn: 6.2737905\ttest: 6.2725777\tbest: 6.2725777 (354)\ttotal: 3m 57s\tremaining: 7m 11s\n",
      "355:\tlearn: 6.2737426\ttest: 6.2725411\tbest: 6.2725411 (355)\ttotal: 3m 58s\tremaining: 7m 10s\n",
      "356:\tlearn: 6.2736909\ttest: 6.2724994\tbest: 6.2724994 (356)\ttotal: 3m 58s\tremaining: 7m 10s\n",
      "357:\tlearn: 6.2736390\ttest: 6.2724526\tbest: 6.2724526 (357)\ttotal: 3m 59s\tremaining: 7m 9s\n",
      "358:\tlearn: 6.2736054\ttest: 6.2724329\tbest: 6.2724329 (358)\ttotal: 4m\tremaining: 7m 8s\n",
      "359:\tlearn: 6.2735700\ttest: 6.2724019\tbest: 6.2724019 (359)\ttotal: 4m\tremaining: 7m 8s\n",
      "360:\tlearn: 6.2735451\ttest: 6.2723839\tbest: 6.2723839 (360)\ttotal: 4m 1s\tremaining: 7m 7s\n",
      "361:\tlearn: 6.2735129\ttest: 6.2723760\tbest: 6.2723760 (361)\ttotal: 4m 1s\tremaining: 7m 6s\n",
      "362:\tlearn: 6.2734750\ttest: 6.2723489\tbest: 6.2723489 (362)\ttotal: 4m 2s\tremaining: 7m 5s\n",
      "363:\tlearn: 6.2734058\ttest: 6.2722850\tbest: 6.2722850 (363)\ttotal: 4m 3s\tremaining: 7m 5s\n",
      "364:\tlearn: 6.2733406\ttest: 6.2722146\tbest: 6.2722146 (364)\ttotal: 4m 4s\tremaining: 7m 4s\n",
      "365:\tlearn: 6.2732498\ttest: 6.2721184\tbest: 6.2721184 (365)\ttotal: 4m 4s\tremaining: 7m 3s\n",
      "366:\tlearn: 6.2732243\ttest: 6.2721029\tbest: 6.2721029 (366)\ttotal: 4m 5s\tremaining: 7m 3s\n",
      "367:\tlearn: 6.2730718\ttest: 6.2719271\tbest: 6.2719271 (367)\ttotal: 4m 6s\tremaining: 7m 2s\n",
      "368:\tlearn: 6.2730149\ttest: 6.2718879\tbest: 6.2718879 (368)\ttotal: 4m 6s\tremaining: 7m 2s\n",
      "369:\tlearn: 6.2729904\ttest: 6.2718627\tbest: 6.2718627 (369)\ttotal: 4m 7s\tremaining: 7m 1s\n",
      "370:\tlearn: 6.2729377\ttest: 6.2718235\tbest: 6.2718235 (370)\ttotal: 4m 8s\tremaining: 7m\n",
      "371:\tlearn: 6.2728970\ttest: 6.2717733\tbest: 6.2717733 (371)\ttotal: 4m 8s\tremaining: 7m\n",
      "372:\tlearn: 6.2728542\ttest: 6.2717567\tbest: 6.2717567 (372)\ttotal: 4m 9s\tremaining: 6m 59s\n",
      "373:\tlearn: 6.2728365\ttest: 6.2717353\tbest: 6.2717353 (373)\ttotal: 4m 10s\tremaining: 6m 58s\n",
      "374:\tlearn: 6.2727933\ttest: 6.2716932\tbest: 6.2716932 (374)\ttotal: 4m 10s\tremaining: 6m 58s\n",
      "375:\tlearn: 6.2727210\ttest: 6.2715942\tbest: 6.2715942 (375)\ttotal: 4m 11s\tremaining: 6m 57s\n",
      "376:\tlearn: 6.2726623\ttest: 6.2715394\tbest: 6.2715394 (376)\ttotal: 4m 12s\tremaining: 6m 56s\n",
      "377:\tlearn: 6.2726383\ttest: 6.2715334\tbest: 6.2715334 (377)\ttotal: 4m 12s\tremaining: 6m 55s\n",
      "378:\tlearn: 6.2725691\ttest: 6.2714853\tbest: 6.2714853 (378)\ttotal: 4m 13s\tremaining: 6m 55s\n",
      "379:\tlearn: 6.2725450\ttest: 6.2714602\tbest: 6.2714602 (379)\ttotal: 4m 14s\tremaining: 6m 54s\n",
      "380:\tlearn: 6.2725059\ttest: 6.2714363\tbest: 6.2714363 (380)\ttotal: 4m 14s\tremaining: 6m 53s\n",
      "381:\tlearn: 6.2724515\ttest: 6.2714079\tbest: 6.2714079 (381)\ttotal: 4m 15s\tremaining: 6m 53s\n",
      "382:\tlearn: 6.2724155\ttest: 6.2713873\tbest: 6.2713873 (382)\ttotal: 4m 15s\tremaining: 6m 52s\n",
      "383:\tlearn: 6.2723220\ttest: 6.2713066\tbest: 6.2713066 (383)\ttotal: 4m 16s\tremaining: 6m 51s\n",
      "384:\tlearn: 6.2722777\ttest: 6.2712566\tbest: 6.2712566 (384)\ttotal: 4m 17s\tremaining: 6m 50s\n",
      "385:\tlearn: 6.2721733\ttest: 6.2711389\tbest: 6.2711389 (385)\ttotal: 4m 18s\tremaining: 6m 50s\n",
      "386:\tlearn: 6.2721341\ttest: 6.2711105\tbest: 6.2711105 (386)\ttotal: 4m 18s\tremaining: 6m 49s\n",
      "387:\tlearn: 6.2721012\ttest: 6.2710943\tbest: 6.2710943 (387)\ttotal: 4m 19s\tremaining: 6m 49s\n",
      "388:\tlearn: 6.2720522\ttest: 6.2710497\tbest: 6.2710497 (388)\ttotal: 4m 20s\tremaining: 6m 48s\n",
      "389:\tlearn: 6.2720220\ttest: 6.2710149\tbest: 6.2710149 (389)\ttotal: 4m 20s\tremaining: 6m 47s\n",
      "390:\tlearn: 6.2719856\ttest: 6.2709864\tbest: 6.2709864 (390)\ttotal: 4m 21s\tremaining: 6m 47s\n",
      "391:\tlearn: 6.2719135\ttest: 6.2709096\tbest: 6.2709096 (391)\ttotal: 4m 22s\tremaining: 6m 46s\n",
      "392:\tlearn: 6.2718665\ttest: 6.2708648\tbest: 6.2708648 (392)\ttotal: 4m 22s\tremaining: 6m 45s\n",
      "393:\tlearn: 6.2718410\ttest: 6.2708449\tbest: 6.2708449 (393)\ttotal: 4m 23s\tremaining: 6m 45s\n",
      "394:\tlearn: 6.2717859\ttest: 6.2707806\tbest: 6.2707806 (394)\ttotal: 4m 24s\tremaining: 6m 44s\n",
      "395:\tlearn: 6.2717182\ttest: 6.2707370\tbest: 6.2707370 (395)\ttotal: 4m 24s\tremaining: 6m 43s\n",
      "396:\tlearn: 6.2716609\ttest: 6.2706784\tbest: 6.2706784 (396)\ttotal: 4m 25s\tremaining: 6m 43s\n",
      "397:\tlearn: 6.2716112\ttest: 6.2706318\tbest: 6.2706318 (397)\ttotal: 4m 26s\tremaining: 6m 42s\n",
      "398:\tlearn: 6.2715782\ttest: 6.2706144\tbest: 6.2706144 (398)\ttotal: 4m 26s\tremaining: 6m 41s\n",
      "399:\tlearn: 6.2715208\ttest: 6.2705539\tbest: 6.2705539 (399)\ttotal: 4m 27s\tremaining: 6m 41s\n",
      "400:\tlearn: 6.2714920\ttest: 6.2705427\tbest: 6.2705427 (400)\ttotal: 4m 28s\tremaining: 6m 40s\n",
      "401:\tlearn: 6.2714433\ttest: 6.2704923\tbest: 6.2704923 (401)\ttotal: 4m 28s\tremaining: 6m 39s\n",
      "402:\tlearn: 6.2714104\ttest: 6.2704677\tbest: 6.2704677 (402)\ttotal: 4m 29s\tremaining: 6m 39s\n",
      "403:\tlearn: 6.2713040\ttest: 6.2703290\tbest: 6.2703290 (403)\ttotal: 4m 30s\tremaining: 6m 38s\n",
      "404:\tlearn: 6.2712479\ttest: 6.2702892\tbest: 6.2702892 (404)\ttotal: 4m 30s\tremaining: 6m 37s\n",
      "405:\tlearn: 6.2712212\ttest: 6.2702620\tbest: 6.2702620 (405)\ttotal: 4m 31s\tremaining: 6m 37s\n",
      "406:\tlearn: 6.2711879\ttest: 6.2702403\tbest: 6.2702403 (406)\ttotal: 4m 31s\tremaining: 6m 36s\n",
      "407:\tlearn: 6.2711601\ttest: 6.2702054\tbest: 6.2702054 (407)\ttotal: 4m 32s\tremaining: 6m 35s\n",
      "408:\tlearn: 6.2710896\ttest: 6.2701162\tbest: 6.2701162 (408)\ttotal: 4m 33s\tremaining: 6m 34s\n",
      "409:\tlearn: 6.2709995\ttest: 6.2700473\tbest: 6.2700473 (409)\ttotal: 4m 33s\tremaining: 6m 34s\n",
      "410:\tlearn: 6.2709663\ttest: 6.2700268\tbest: 6.2700268 (410)\ttotal: 4m 34s\tremaining: 6m 33s\n",
      "411:\tlearn: 6.2708750\ttest: 6.2699356\tbest: 6.2699356 (411)\ttotal: 4m 35s\tremaining: 6m 32s\n",
      "412:\tlearn: 6.2708365\ttest: 6.2699032\tbest: 6.2699032 (412)\ttotal: 4m 35s\tremaining: 6m 32s\n",
      "413:\tlearn: 6.2707835\ttest: 6.2698371\tbest: 6.2698371 (413)\ttotal: 4m 36s\tremaining: 6m 31s\n",
      "414:\tlearn: 6.2707445\ttest: 6.2697742\tbest: 6.2697742 (414)\ttotal: 4m 37s\tremaining: 6m 30s\n",
      "415:\tlearn: 6.2706362\ttest: 6.2696656\tbest: 6.2696656 (415)\ttotal: 4m 38s\tremaining: 6m 30s\n",
      "416:\tlearn: 6.2705897\ttest: 6.2696457\tbest: 6.2696457 (416)\ttotal: 4m 38s\tremaining: 6m 29s\n",
      "417:\tlearn: 6.2705624\ttest: 6.2696163\tbest: 6.2696163 (417)\ttotal: 4m 39s\tremaining: 6m 28s\n",
      "418:\tlearn: 6.2705324\ttest: 6.2695907\tbest: 6.2695907 (418)\ttotal: 4m 39s\tremaining: 6m 28s\n",
      "419:\tlearn: 6.2704784\ttest: 6.2695665\tbest: 6.2695665 (419)\ttotal: 4m 40s\tremaining: 6m 27s\n",
      "420:\tlearn: 6.2704572\ttest: 6.2695593\tbest: 6.2695593 (420)\ttotal: 4m 41s\tremaining: 6m 26s\n",
      "421:\tlearn: 6.2704176\ttest: 6.2695315\tbest: 6.2695315 (421)\ttotal: 4m 41s\tremaining: 6m 26s\n",
      "422:\tlearn: 6.2703984\ttest: 6.2695067\tbest: 6.2695067 (422)\ttotal: 4m 42s\tremaining: 6m 25s\n",
      "423:\tlearn: 6.2703489\ttest: 6.2694797\tbest: 6.2694797 (423)\ttotal: 4m 43s\tremaining: 6m 24s\n",
      "424:\tlearn: 6.2702957\ttest: 6.2694274\tbest: 6.2694274 (424)\ttotal: 4m 43s\tremaining: 6m 24s\n",
      "425:\tlearn: 6.2702597\ttest: 6.2693906\tbest: 6.2693906 (425)\ttotal: 4m 44s\tremaining: 6m 23s\n",
      "426:\tlearn: 6.2702290\ttest: 6.2693792\tbest: 6.2693792 (426)\ttotal: 4m 45s\tremaining: 6m 22s\n",
      "427:\tlearn: 6.2701245\ttest: 6.2692642\tbest: 6.2692642 (427)\ttotal: 4m 45s\tremaining: 6m 22s\n",
      "428:\tlearn: 6.2700937\ttest: 6.2692295\tbest: 6.2692295 (428)\ttotal: 4m 46s\tremaining: 6m 21s\n",
      "429:\tlearn: 6.2700590\ttest: 6.2692288\tbest: 6.2692288 (429)\ttotal: 4m 47s\tremaining: 6m 20s\n",
      "430:\tlearn: 6.2700077\ttest: 6.2692106\tbest: 6.2692106 (430)\ttotal: 4m 47s\tremaining: 6m 19s\n",
      "431:\tlearn: 6.2699383\ttest: 6.2691479\tbest: 6.2691479 (431)\ttotal: 4m 48s\tremaining: 6m 19s\n",
      "432:\tlearn: 6.2699092\ttest: 6.2691402\tbest: 6.2691402 (432)\ttotal: 4m 49s\tremaining: 6m 18s\n",
      "433:\tlearn: 6.2698844\ttest: 6.2691225\tbest: 6.2691225 (433)\ttotal: 4m 49s\tremaining: 6m 17s\n",
      "434:\tlearn: 6.2698393\ttest: 6.2690880\tbest: 6.2690880 (434)\ttotal: 4m 50s\tremaining: 6m 17s\n",
      "435:\tlearn: 6.2698119\ttest: 6.2690607\tbest: 6.2690607 (435)\ttotal: 4m 51s\tremaining: 6m 16s\n",
      "436:\tlearn: 6.2697838\ttest: 6.2690256\tbest: 6.2690256 (436)\ttotal: 4m 51s\tremaining: 6m 15s\n",
      "437:\tlearn: 6.2697515\ttest: 6.2689825\tbest: 6.2689825 (437)\ttotal: 4m 52s\tremaining: 6m 15s\n",
      "438:\tlearn: 6.2697226\ttest: 6.2689462\tbest: 6.2689462 (438)\ttotal: 4m 53s\tremaining: 6m 14s\n",
      "439:\tlearn: 6.2696574\ttest: 6.2688694\tbest: 6.2688694 (439)\ttotal: 4m 53s\tremaining: 6m 13s\n",
      "440:\tlearn: 6.2696039\ttest: 6.2688108\tbest: 6.2688108 (440)\ttotal: 4m 54s\tremaining: 6m 13s\n",
      "441:\tlearn: 6.2695487\ttest: 6.2687862\tbest: 6.2687862 (441)\ttotal: 4m 55s\tremaining: 6m 12s\n",
      "442:\tlearn: 6.2695192\ttest: 6.2687652\tbest: 6.2687652 (442)\ttotal: 4m 55s\tremaining: 6m 11s\n",
      "443:\tlearn: 6.2694948\ttest: 6.2687543\tbest: 6.2687543 (443)\ttotal: 4m 56s\tremaining: 6m 11s\n",
      "444:\tlearn: 6.2694183\ttest: 6.2686638\tbest: 6.2686638 (444)\ttotal: 4m 56s\tremaining: 6m 10s\n",
      "445:\tlearn: 6.2693712\ttest: 6.2686249\tbest: 6.2686249 (445)\ttotal: 4m 57s\tremaining: 6m 9s\n",
      "446:\tlearn: 6.2693244\ttest: 6.2686117\tbest: 6.2686117 (446)\ttotal: 4m 58s\tremaining: 6m 9s\n",
      "447:\tlearn: 6.2692774\ttest: 6.2685690\tbest: 6.2685690 (447)\ttotal: 4m 58s\tremaining: 6m 8s\n",
      "448:\tlearn: 6.2692305\ttest: 6.2685070\tbest: 6.2685070 (448)\ttotal: 4m 59s\tremaining: 6m 7s\n",
      "449:\tlearn: 6.2691581\ttest: 6.2684317\tbest: 6.2684317 (449)\ttotal: 5m\tremaining: 6m 6s\n",
      "450:\tlearn: 6.2691301\ttest: 6.2683895\tbest: 6.2683895 (450)\ttotal: 5m\tremaining: 6m 6s\n",
      "451:\tlearn: 6.2691024\ttest: 6.2683749\tbest: 6.2683749 (451)\ttotal: 5m 1s\tremaining: 6m 5s\n",
      "452:\tlearn: 6.2690586\ttest: 6.2683193\tbest: 6.2683193 (452)\ttotal: 5m 2s\tremaining: 6m 4s\n",
      "453:\tlearn: 6.2690143\ttest: 6.2682705\tbest: 6.2682705 (453)\ttotal: 5m 2s\tremaining: 6m 4s\n",
      "454:\tlearn: 6.2689905\ttest: 6.2682529\tbest: 6.2682529 (454)\ttotal: 5m 3s\tremaining: 6m 3s\n",
      "455:\tlearn: 6.2689571\ttest: 6.2682202\tbest: 6.2682202 (455)\ttotal: 5m 4s\tremaining: 6m 2s\n",
      "456:\tlearn: 6.2689174\ttest: 6.2681942\tbest: 6.2681942 (456)\ttotal: 5m 4s\tremaining: 6m 2s\n",
      "457:\tlearn: 6.2688274\ttest: 6.2680974\tbest: 6.2680974 (457)\ttotal: 5m 5s\tremaining: 6m 1s\n",
      "458:\tlearn: 6.2687884\ttest: 6.2680612\tbest: 6.2680612 (458)\ttotal: 5m 6s\tremaining: 6m\n",
      "459:\tlearn: 6.2687523\ttest: 6.2680441\tbest: 6.2680441 (459)\ttotal: 5m 6s\tremaining: 6m\n",
      "460:\tlearn: 6.2687253\ttest: 6.2680196\tbest: 6.2680196 (460)\ttotal: 5m 7s\tremaining: 5m 59s\n",
      "461:\tlearn: 6.2686413\ttest: 6.2679253\tbest: 6.2679253 (461)\ttotal: 5m 8s\tremaining: 5m 58s\n",
      "462:\tlearn: 6.2686066\ttest: 6.2679004\tbest: 6.2679004 (462)\ttotal: 5m 8s\tremaining: 5m 58s\n",
      "463:\tlearn: 6.2685650\ttest: 6.2678734\tbest: 6.2678734 (463)\ttotal: 5m 9s\tremaining: 5m 57s\n",
      "464:\tlearn: 6.2685407\ttest: 6.2678551\tbest: 6.2678551 (464)\ttotal: 5m 10s\tremaining: 5m 56s\n",
      "465:\tlearn: 6.2684941\ttest: 6.2678308\tbest: 6.2678308 (465)\ttotal: 5m 10s\tremaining: 5m 56s\n",
      "466:\tlearn: 6.2684698\ttest: 6.2678093\tbest: 6.2678093 (466)\ttotal: 5m 11s\tremaining: 5m 55s\n",
      "467:\tlearn: 6.2684431\ttest: 6.2677911\tbest: 6.2677911 (467)\ttotal: 5m 11s\tremaining: 5m 54s\n",
      "468:\tlearn: 6.2684191\ttest: 6.2677721\tbest: 6.2677721 (468)\ttotal: 5m 12s\tremaining: 5m 53s\n",
      "469:\tlearn: 6.2683760\ttest: 6.2677514\tbest: 6.2677514 (469)\ttotal: 5m 13s\tremaining: 5m 53s\n",
      "470:\tlearn: 6.2683396\ttest: 6.2677306\tbest: 6.2677306 (470)\ttotal: 5m 13s\tremaining: 5m 52s\n",
      "471:\tlearn: 6.2682969\ttest: 6.2676773\tbest: 6.2676773 (471)\ttotal: 5m 14s\tremaining: 5m 51s\n",
      "472:\tlearn: 6.2682059\ttest: 6.2676051\tbest: 6.2676051 (472)\ttotal: 5m 15s\tremaining: 5m 51s\n",
      "473:\tlearn: 6.2681223\ttest: 6.2675013\tbest: 6.2675013 (473)\ttotal: 5m 15s\tremaining: 5m 50s\n",
      "474:\tlearn: 6.2680898\ttest: 6.2674614\tbest: 6.2674614 (474)\ttotal: 5m 16s\tremaining: 5m 49s\n",
      "475:\tlearn: 6.2680438\ttest: 6.2674362\tbest: 6.2674362 (475)\ttotal: 5m 17s\tremaining: 5m 49s\n",
      "476:\tlearn: 6.2680036\ttest: 6.2674213\tbest: 6.2674213 (476)\ttotal: 5m 17s\tremaining: 5m 48s\n",
      "477:\tlearn: 6.2679184\ttest: 6.2673333\tbest: 6.2673333 (477)\ttotal: 5m 18s\tremaining: 5m 47s\n",
      "478:\tlearn: 6.2678908\ttest: 6.2673248\tbest: 6.2673248 (478)\ttotal: 5m 18s\tremaining: 5m 46s\n",
      "479:\tlearn: 6.2678510\ttest: 6.2673112\tbest: 6.2673112 (479)\ttotal: 5m 19s\tremaining: 5m 46s\n",
      "480:\tlearn: 6.2678128\ttest: 6.2672776\tbest: 6.2672776 (480)\ttotal: 5m 20s\tremaining: 5m 45s\n",
      "481:\tlearn: 6.2677814\ttest: 6.2672585\tbest: 6.2672585 (481)\ttotal: 5m 20s\tremaining: 5m 44s\n",
      "482:\tlearn: 6.2677336\ttest: 6.2672133\tbest: 6.2672133 (482)\ttotal: 5m 21s\tremaining: 5m 44s\n",
      "483:\tlearn: 6.2677057\ttest: 6.2671895\tbest: 6.2671895 (483)\ttotal: 5m 22s\tremaining: 5m 43s\n",
      "484:\tlearn: 6.2676746\ttest: 6.2671585\tbest: 6.2671585 (484)\ttotal: 5m 22s\tremaining: 5m 42s\n",
      "485:\tlearn: 6.2675848\ttest: 6.2670920\tbest: 6.2670920 (485)\ttotal: 5m 23s\tremaining: 5m 42s\n",
      "486:\tlearn: 6.2675544\ttest: 6.2670677\tbest: 6.2670677 (486)\ttotal: 5m 24s\tremaining: 5m 41s\n",
      "487:\tlearn: 6.2675112\ttest: 6.2670217\tbest: 6.2670217 (487)\ttotal: 5m 24s\tremaining: 5m 40s\n",
      "488:\tlearn: 6.2674586\ttest: 6.2669961\tbest: 6.2669961 (488)\ttotal: 5m 25s\tremaining: 5m 40s\n",
      "489:\tlearn: 6.2674294\ttest: 6.2669828\tbest: 6.2669828 (489)\ttotal: 5m 26s\tremaining: 5m 39s\n",
      "490:\tlearn: 6.2673446\ttest: 6.2668990\tbest: 6.2668990 (490)\ttotal: 5m 26s\tremaining: 5m 38s\n",
      "491:\tlearn: 6.2673099\ttest: 6.2668518\tbest: 6.2668518 (491)\ttotal: 5m 27s\tremaining: 5m 38s\n",
      "492:\tlearn: 6.2672475\ttest: 6.2667749\tbest: 6.2667749 (492)\ttotal: 5m 28s\tremaining: 5m 37s\n",
      "493:\tlearn: 6.2672192\ttest: 6.2667530\tbest: 6.2667530 (493)\ttotal: 5m 28s\tremaining: 5m 36s\n",
      "494:\tlearn: 6.2671844\ttest: 6.2667221\tbest: 6.2667221 (494)\ttotal: 5m 29s\tremaining: 5m 36s\n",
      "495:\tlearn: 6.2671290\ttest: 6.2666626\tbest: 6.2666626 (495)\ttotal: 5m 30s\tremaining: 5m 35s\n",
      "496:\tlearn: 6.2670643\ttest: 6.2666040\tbest: 6.2666040 (496)\ttotal: 5m 30s\tremaining: 5m 34s\n",
      "497:\tlearn: 6.2670294\ttest: 6.2665950\tbest: 6.2665950 (497)\ttotal: 5m 31s\tremaining: 5m 34s\n",
      "498:\tlearn: 6.2669968\ttest: 6.2665776\tbest: 6.2665776 (498)\ttotal: 5m 32s\tremaining: 5m 33s\n",
      "499:\tlearn: 6.2669424\ttest: 6.2665302\tbest: 6.2665302 (499)\ttotal: 5m 32s\tremaining: 5m 32s\n",
      "500:\tlearn: 6.2669149\ttest: 6.2665027\tbest: 6.2665027 (500)\ttotal: 5m 33s\tremaining: 5m 32s\n",
      "501:\tlearn: 6.2668637\ttest: 6.2664643\tbest: 6.2664643 (501)\ttotal: 5m 34s\tremaining: 5m 31s\n",
      "502:\tlearn: 6.2668321\ttest: 6.2664436\tbest: 6.2664436 (502)\ttotal: 5m 34s\tremaining: 5m 30s\n",
      "503:\tlearn: 6.2667906\ttest: 6.2664032\tbest: 6.2664032 (503)\ttotal: 5m 35s\tremaining: 5m 30s\n",
      "504:\tlearn: 6.2667436\ttest: 6.2663782\tbest: 6.2663782 (504)\ttotal: 5m 36s\tremaining: 5m 29s\n",
      "505:\tlearn: 6.2666986\ttest: 6.2663448\tbest: 6.2663448 (505)\ttotal: 5m 36s\tremaining: 5m 28s\n",
      "506:\tlearn: 6.2666645\ttest: 6.2663244\tbest: 6.2663244 (506)\ttotal: 5m 37s\tremaining: 5m 27s\n",
      "507:\tlearn: 6.2666211\ttest: 6.2662956\tbest: 6.2662956 (507)\ttotal: 5m 37s\tremaining: 5m 27s\n",
      "508:\tlearn: 6.2665761\ttest: 6.2662544\tbest: 6.2662544 (508)\ttotal: 5m 38s\tremaining: 5m 26s\n",
      "509:\tlearn: 6.2665471\ttest: 6.2662451\tbest: 6.2662451 (509)\ttotal: 5m 39s\tremaining: 5m 26s\n",
      "510:\tlearn: 6.2665168\ttest: 6.2662310\tbest: 6.2662310 (510)\ttotal: 5m 39s\tremaining: 5m 25s\n",
      "511:\tlearn: 6.2664755\ttest: 6.2661921\tbest: 6.2661921 (511)\ttotal: 5m 40s\tremaining: 5m 24s\n",
      "512:\tlearn: 6.2664511\ttest: 6.2661735\tbest: 6.2661735 (512)\ttotal: 5m 41s\tremaining: 5m 23s\n",
      "513:\tlearn: 6.2664236\ttest: 6.2661604\tbest: 6.2661604 (513)\ttotal: 5m 41s\tremaining: 5m 23s\n",
      "514:\tlearn: 6.2663920\ttest: 6.2661273\tbest: 6.2661273 (514)\ttotal: 5m 42s\tremaining: 5m 22s\n",
      "515:\tlearn: 6.2663307\ttest: 6.2660639\tbest: 6.2660639 (515)\ttotal: 5m 43s\tremaining: 5m 22s\n",
      "516:\tlearn: 6.2662937\ttest: 6.2660408\tbest: 6.2660408 (516)\ttotal: 5m 43s\tremaining: 5m 21s\n",
      "517:\tlearn: 6.2662643\ttest: 6.2660124\tbest: 6.2660124 (517)\ttotal: 5m 44s\tremaining: 5m 20s\n",
      "518:\tlearn: 6.2662300\ttest: 6.2659731\tbest: 6.2659731 (518)\ttotal: 5m 45s\tremaining: 5m 19s\n",
      "519:\tlearn: 6.2661688\ttest: 6.2659146\tbest: 6.2659146 (519)\ttotal: 5m 45s\tremaining: 5m 19s\n",
      "520:\tlearn: 6.2661204\ttest: 6.2658944\tbest: 6.2658944 (520)\ttotal: 5m 46s\tremaining: 5m 18s\n",
      "521:\tlearn: 6.2660875\ttest: 6.2658612\tbest: 6.2658612 (521)\ttotal: 5m 47s\tremaining: 5m 17s\n",
      "522:\tlearn: 6.2660450\ttest: 6.2658070\tbest: 6.2658070 (522)\ttotal: 5m 47s\tremaining: 5m 17s\n",
      "523:\tlearn: 6.2660172\ttest: 6.2657899\tbest: 6.2657899 (523)\ttotal: 5m 48s\tremaining: 5m 16s\n",
      "524:\tlearn: 6.2659924\ttest: 6.2657817\tbest: 6.2657817 (524)\ttotal: 5m 49s\tremaining: 5m 15s\n",
      "525:\tlearn: 6.2659533\ttest: 6.2657299\tbest: 6.2657299 (525)\ttotal: 5m 49s\tremaining: 5m 15s\n",
      "526:\tlearn: 6.2659117\ttest: 6.2656958\tbest: 6.2656958 (526)\ttotal: 5m 50s\tremaining: 5m 14s\n",
      "527:\tlearn: 6.2658557\ttest: 6.2656335\tbest: 6.2656335 (527)\ttotal: 5m 51s\tremaining: 5m 13s\n",
      "528:\tlearn: 6.2658167\ttest: 6.2655885\tbest: 6.2655885 (528)\ttotal: 5m 51s\tremaining: 5m 13s\n",
      "529:\tlearn: 6.2657787\ttest: 6.2655632\tbest: 6.2655632 (529)\ttotal: 5m 52s\tremaining: 5m 12s\n",
      "530:\tlearn: 6.2657479\ttest: 6.2655474\tbest: 6.2655474 (530)\ttotal: 5m 53s\tremaining: 5m 11s\n",
      "531:\tlearn: 6.2656837\ttest: 6.2654892\tbest: 6.2654892 (531)\ttotal: 5m 53s\tremaining: 5m 11s\n",
      "532:\tlearn: 6.2656419\ttest: 6.2654520\tbest: 6.2654520 (532)\ttotal: 5m 54s\tremaining: 5m 10s\n",
      "533:\tlearn: 6.2656133\ttest: 6.2654220\tbest: 6.2654220 (533)\ttotal: 5m 54s\tremaining: 5m 9s\n",
      "534:\tlearn: 6.2655708\ttest: 6.2653753\tbest: 6.2653753 (534)\ttotal: 5m 55s\tremaining: 5m 9s\n",
      "535:\tlearn: 6.2655486\ttest: 6.2653495\tbest: 6.2653495 (535)\ttotal: 5m 56s\tremaining: 5m 8s\n",
      "536:\tlearn: 6.2655239\ttest: 6.2653357\tbest: 6.2653357 (536)\ttotal: 5m 56s\tremaining: 5m 7s\n",
      "537:\tlearn: 6.2654900\ttest: 6.2653147\tbest: 6.2653147 (537)\ttotal: 5m 57s\tremaining: 5m 7s\n",
      "538:\tlearn: 6.2654493\ttest: 6.2652787\tbest: 6.2652787 (538)\ttotal: 5m 58s\tremaining: 5m 6s\n",
      "539:\tlearn: 6.2654203\ttest: 6.2652487\tbest: 6.2652487 (539)\ttotal: 5m 58s\tremaining: 5m 5s\n",
      "540:\tlearn: 6.2653801\ttest: 6.2652142\tbest: 6.2652142 (540)\ttotal: 5m 59s\tremaining: 5m 5s\n",
      "541:\tlearn: 6.2653396\ttest: 6.2652025\tbest: 6.2652025 (541)\ttotal: 6m\tremaining: 5m 4s\n",
      "542:\tlearn: 6.2653154\ttest: 6.2651895\tbest: 6.2651895 (542)\ttotal: 6m\tremaining: 5m 3s\n",
      "543:\tlearn: 6.2652898\ttest: 6.2651757\tbest: 6.2651757 (543)\ttotal: 6m 1s\tremaining: 5m 2s\n",
      "544:\tlearn: 6.2652601\ttest: 6.2651494\tbest: 6.2651494 (544)\ttotal: 6m 2s\tremaining: 5m 2s\n",
      "545:\tlearn: 6.2652144\ttest: 6.2651006\tbest: 6.2651006 (545)\ttotal: 6m 2s\tremaining: 5m 1s\n",
      "546:\tlearn: 6.2651778\ttest: 6.2650646\tbest: 6.2650646 (546)\ttotal: 6m 3s\tremaining: 5m\n",
      "547:\tlearn: 6.2651229\ttest: 6.2650487\tbest: 6.2650487 (547)\ttotal: 6m 4s\tremaining: 5m\n",
      "548:\tlearn: 6.2650891\ttest: 6.2650101\tbest: 6.2650101 (548)\ttotal: 6m 4s\tremaining: 4m 59s\n",
      "549:\tlearn: 6.2650559\ttest: 6.2649887\tbest: 6.2649887 (549)\ttotal: 6m 5s\tremaining: 4m 58s\n",
      "550:\tlearn: 6.2650232\ttest: 6.2649757\tbest: 6.2649757 (550)\ttotal: 6m 5s\tremaining: 4m 58s\n",
      "551:\tlearn: 6.2649892\ttest: 6.2649744\tbest: 6.2649744 (551)\ttotal: 6m 6s\tremaining: 4m 57s\n",
      "552:\tlearn: 6.2649461\ttest: 6.2649575\tbest: 6.2649575 (552)\ttotal: 6m 7s\tremaining: 4m 56s\n",
      "553:\tlearn: 6.2648554\ttest: 6.2648780\tbest: 6.2648780 (553)\ttotal: 6m 7s\tremaining: 4m 56s\n",
      "554:\tlearn: 6.2647901\ttest: 6.2648232\tbest: 6.2648232 (554)\ttotal: 6m 8s\tremaining: 4m 55s\n",
      "555:\tlearn: 6.2647534\ttest: 6.2647847\tbest: 6.2647847 (555)\ttotal: 6m 9s\tremaining: 4m 54s\n",
      "556:\tlearn: 6.2646994\ttest: 6.2647341\tbest: 6.2647341 (556)\ttotal: 6m 9s\tremaining: 4m 54s\n",
      "557:\tlearn: 6.2646635\ttest: 6.2647149\tbest: 6.2647149 (557)\ttotal: 6m 10s\tremaining: 4m 53s\n",
      "558:\tlearn: 6.2646341\ttest: 6.2646704\tbest: 6.2646704 (558)\ttotal: 6m 11s\tremaining: 4m 52s\n",
      "559:\tlearn: 6.2646085\ttest: 6.2646655\tbest: 6.2646655 (559)\ttotal: 6m 11s\tremaining: 4m 52s\n",
      "560:\tlearn: 6.2645707\ttest: 6.2646475\tbest: 6.2646475 (560)\ttotal: 6m 12s\tremaining: 4m 51s\n",
      "561:\tlearn: 6.2645430\ttest: 6.2646351\tbest: 6.2646351 (561)\ttotal: 6m 12s\tremaining: 4m 50s\n",
      "562:\tlearn: 6.2644804\ttest: 6.2645840\tbest: 6.2645840 (562)\ttotal: 6m 13s\tremaining: 4m 50s\n",
      "563:\tlearn: 6.2643830\ttest: 6.2644965\tbest: 6.2644965 (563)\ttotal: 6m 14s\tremaining: 4m 49s\n",
      "564:\tlearn: 6.2643430\ttest: 6.2644566\tbest: 6.2644566 (564)\ttotal: 6m 14s\tremaining: 4m 48s\n",
      "565:\tlearn: 6.2642881\ttest: 6.2643831\tbest: 6.2643831 (565)\ttotal: 6m 15s\tremaining: 4m 47s\n",
      "566:\tlearn: 6.2642389\ttest: 6.2643401\tbest: 6.2643401 (566)\ttotal: 6m 16s\tremaining: 4m 47s\n",
      "567:\tlearn: 6.2641678\ttest: 6.2642769\tbest: 6.2642769 (567)\ttotal: 6m 16s\tremaining: 4m 46s\n",
      "568:\tlearn: 6.2640902\ttest: 6.2642245\tbest: 6.2642245 (568)\ttotal: 6m 17s\tremaining: 4m 45s\n",
      "569:\tlearn: 6.2640662\ttest: 6.2642058\tbest: 6.2642058 (569)\ttotal: 6m 18s\tremaining: 4m 45s\n",
      "570:\tlearn: 6.2640305\ttest: 6.2641709\tbest: 6.2641709 (570)\ttotal: 6m 18s\tremaining: 4m 44s\n",
      "571:\tlearn: 6.2639883\ttest: 6.2641318\tbest: 6.2641318 (571)\ttotal: 6m 19s\tremaining: 4m 43s\n",
      "572:\tlearn: 6.2639680\ttest: 6.2641152\tbest: 6.2641152 (572)\ttotal: 6m 20s\tremaining: 4m 43s\n",
      "573:\tlearn: 6.2639037\ttest: 6.2640494\tbest: 6.2640494 (573)\ttotal: 6m 20s\tremaining: 4m 42s\n",
      "574:\tlearn: 6.2638509\ttest: 6.2639979\tbest: 6.2639979 (574)\ttotal: 6m 21s\tremaining: 4m 42s\n",
      "575:\tlearn: 6.2638207\ttest: 6.2639931\tbest: 6.2639931 (575)\ttotal: 6m 22s\tremaining: 4m 41s\n",
      "576:\tlearn: 6.2637944\ttest: 6.2639568\tbest: 6.2639568 (576)\ttotal: 6m 22s\tremaining: 4m 40s\n",
      "577:\tlearn: 6.2637184\ttest: 6.2638828\tbest: 6.2638828 (577)\ttotal: 6m 23s\tremaining: 4m 40s\n",
      "578:\tlearn: 6.2636930\ttest: 6.2638574\tbest: 6.2638574 (578)\ttotal: 6m 24s\tremaining: 4m 39s\n",
      "579:\tlearn: 6.2636636\ttest: 6.2638266\tbest: 6.2638266 (579)\ttotal: 6m 24s\tremaining: 4m 38s\n",
      "580:\tlearn: 6.2636090\ttest: 6.2637684\tbest: 6.2637684 (580)\ttotal: 6m 25s\tremaining: 4m 37s\n",
      "581:\tlearn: 6.2635709\ttest: 6.2637465\tbest: 6.2637465 (581)\ttotal: 6m 26s\tremaining: 4m 37s\n",
      "582:\tlearn: 6.2635483\ttest: 6.2637366\tbest: 6.2637366 (582)\ttotal: 6m 26s\tremaining: 4m 36s\n",
      "583:\tlearn: 6.2635152\ttest: 6.2637078\tbest: 6.2637078 (583)\ttotal: 6m 27s\tremaining: 4m 35s\n",
      "584:\tlearn: 6.2634725\ttest: 6.2636951\tbest: 6.2636951 (584)\ttotal: 6m 28s\tremaining: 4m 35s\n",
      "585:\tlearn: 6.2634381\ttest: 6.2636773\tbest: 6.2636773 (585)\ttotal: 6m 28s\tremaining: 4m 34s\n",
      "586:\tlearn: 6.2634042\ttest: 6.2636449\tbest: 6.2636449 (586)\ttotal: 6m 29s\tremaining: 4m 33s\n",
      "587:\tlearn: 6.2633701\ttest: 6.2636365\tbest: 6.2636365 (587)\ttotal: 6m 29s\tremaining: 4m 33s\n",
      "588:\tlearn: 6.2633324\ttest: 6.2635997\tbest: 6.2635997 (588)\ttotal: 6m 30s\tremaining: 4m 32s\n",
      "589:\tlearn: 6.2632924\ttest: 6.2635793\tbest: 6.2635793 (589)\ttotal: 6m 31s\tremaining: 4m 31s\n",
      "590:\tlearn: 6.2632592\ttest: 6.2635531\tbest: 6.2635531 (590)\ttotal: 6m 31s\tremaining: 4m 31s\n",
      "591:\tlearn: 6.2632327\ttest: 6.2635409\tbest: 6.2635409 (591)\ttotal: 6m 32s\tremaining: 4m 30s\n",
      "592:\tlearn: 6.2632086\ttest: 6.2635256\tbest: 6.2635256 (592)\ttotal: 6m 33s\tremaining: 4m 29s\n",
      "593:\tlearn: 6.2631765\ttest: 6.2635187\tbest: 6.2635187 (593)\ttotal: 6m 33s\tremaining: 4m 29s\n",
      "594:\tlearn: 6.2631399\ttest: 6.2634911\tbest: 6.2634911 (594)\ttotal: 6m 34s\tremaining: 4m 28s\n",
      "595:\tlearn: 6.2631020\ttest: 6.2634573\tbest: 6.2634573 (595)\ttotal: 6m 35s\tremaining: 4m 27s\n",
      "596:\tlearn: 6.2630724\ttest: 6.2634301\tbest: 6.2634301 (596)\ttotal: 6m 35s\tremaining: 4m 27s\n",
      "597:\tlearn: 6.2630437\ttest: 6.2634170\tbest: 6.2634170 (597)\ttotal: 6m 36s\tremaining: 4m 26s\n",
      "598:\tlearn: 6.2630218\ttest: 6.2633949\tbest: 6.2633949 (598)\ttotal: 6m 37s\tremaining: 4m 25s\n",
      "599:\tlearn: 6.2629820\ttest: 6.2633474\tbest: 6.2633474 (599)\ttotal: 6m 37s\tremaining: 4m 25s\n",
      "600:\tlearn: 6.2629422\ttest: 6.2633328\tbest: 6.2633328 (600)\ttotal: 6m 38s\tremaining: 4m 24s\n",
      "601:\tlearn: 6.2629013\ttest: 6.2632923\tbest: 6.2632923 (601)\ttotal: 6m 39s\tremaining: 4m 23s\n",
      "602:\tlearn: 6.2628620\ttest: 6.2632842\tbest: 6.2632842 (602)\ttotal: 6m 39s\tremaining: 4m 23s\n",
      "603:\tlearn: 6.2628385\ttest: 6.2632555\tbest: 6.2632555 (603)\ttotal: 6m 40s\tremaining: 4m 22s\n",
      "604:\tlearn: 6.2628109\ttest: 6.2632292\tbest: 6.2632292 (604)\ttotal: 6m 41s\tremaining: 4m 21s\n",
      "605:\tlearn: 6.2627748\ttest: 6.2631779\tbest: 6.2631779 (605)\ttotal: 6m 41s\tremaining: 4m 21s\n",
      "606:\tlearn: 6.2627297\ttest: 6.2631305\tbest: 6.2631305 (606)\ttotal: 6m 42s\tremaining: 4m 20s\n",
      "607:\tlearn: 6.2626930\ttest: 6.2631077\tbest: 6.2631077 (607)\ttotal: 6m 43s\tremaining: 4m 19s\n",
      "608:\tlearn: 6.2626365\ttest: 6.2630575\tbest: 6.2630575 (608)\ttotal: 6m 43s\tremaining: 4m 19s\n",
      "609:\tlearn: 6.2626071\ttest: 6.2630415\tbest: 6.2630415 (609)\ttotal: 6m 44s\tremaining: 4m 18s\n",
      "610:\tlearn: 6.2625591\ttest: 6.2630168\tbest: 6.2630168 (610)\ttotal: 6m 45s\tremaining: 4m 17s\n",
      "611:\tlearn: 6.2625280\ttest: 6.2629785\tbest: 6.2629785 (611)\ttotal: 6m 45s\tremaining: 4m 17s\n",
      "612:\tlearn: 6.2624963\ttest: 6.2629671\tbest: 6.2629671 (612)\ttotal: 6m 46s\tremaining: 4m 16s\n",
      "613:\tlearn: 6.2624576\ttest: 6.2629207\tbest: 6.2629207 (613)\ttotal: 6m 47s\tremaining: 4m 15s\n",
      "614:\tlearn: 6.2624300\ttest: 6.2629078\tbest: 6.2629078 (614)\ttotal: 6m 47s\tremaining: 4m 15s\n",
      "615:\tlearn: 6.2623891\ttest: 6.2628875\tbest: 6.2628875 (615)\ttotal: 6m 48s\tremaining: 4m 14s\n",
      "616:\tlearn: 6.2623686\ttest: 6.2628615\tbest: 6.2628615 (616)\ttotal: 6m 49s\tremaining: 4m 13s\n",
      "617:\tlearn: 6.2623169\ttest: 6.2628467\tbest: 6.2628467 (617)\ttotal: 6m 49s\tremaining: 4m 13s\n",
      "618:\tlearn: 6.2622920\ttest: 6.2628269\tbest: 6.2628269 (618)\ttotal: 6m 50s\tremaining: 4m 12s\n",
      "619:\tlearn: 6.2622431\ttest: 6.2627632\tbest: 6.2627632 (619)\ttotal: 6m 51s\tremaining: 4m 11s\n",
      "620:\tlearn: 6.2622026\ttest: 6.2627352\tbest: 6.2627352 (620)\ttotal: 6m 51s\tremaining: 4m 11s\n",
      "621:\tlearn: 6.2621729\ttest: 6.2627170\tbest: 6.2627170 (621)\ttotal: 6m 52s\tremaining: 4m 10s\n",
      "622:\tlearn: 6.2621380\ttest: 6.2626987\tbest: 6.2626987 (622)\ttotal: 6m 53s\tremaining: 4m 9s\n",
      "623:\tlearn: 6.2621153\ttest: 6.2626791\tbest: 6.2626791 (623)\ttotal: 6m 53s\tremaining: 4m 9s\n",
      "624:\tlearn: 6.2620798\ttest: 6.2626685\tbest: 6.2626685 (624)\ttotal: 6m 54s\tremaining: 4m 8s\n",
      "625:\tlearn: 6.2620504\ttest: 6.2626358\tbest: 6.2626358 (625)\ttotal: 6m 54s\tremaining: 4m 7s\n",
      "626:\tlearn: 6.2620106\ttest: 6.2626202\tbest: 6.2626202 (626)\ttotal: 6m 55s\tremaining: 4m 7s\n",
      "627:\tlearn: 6.2619916\ttest: 6.2626031\tbest: 6.2626031 (627)\ttotal: 6m 56s\tremaining: 4m 6s\n",
      "628:\tlearn: 6.2619670\ttest: 6.2625989\tbest: 6.2625989 (628)\ttotal: 6m 56s\tremaining: 4m 5s\n",
      "629:\tlearn: 6.2619426\ttest: 6.2625883\tbest: 6.2625883 (629)\ttotal: 6m 57s\tremaining: 4m 5s\n",
      "630:\tlearn: 6.2619091\ttest: 6.2625555\tbest: 6.2625555 (630)\ttotal: 6m 58s\tremaining: 4m 4s\n",
      "631:\tlearn: 6.2618746\ttest: 6.2625266\tbest: 6.2625266 (631)\ttotal: 6m 58s\tremaining: 4m 3s\n",
      "632:\tlearn: 6.2618267\ttest: 6.2624867\tbest: 6.2624867 (632)\ttotal: 6m 59s\tremaining: 4m 3s\n",
      "633:\tlearn: 6.2617942\ttest: 6.2624644\tbest: 6.2624644 (633)\ttotal: 7m\tremaining: 4m 2s\n",
      "634:\tlearn: 6.2617666\ttest: 6.2624571\tbest: 6.2624571 (634)\ttotal: 7m\tremaining: 4m 1s\n",
      "635:\tlearn: 6.2617305\ttest: 6.2624408\tbest: 6.2624408 (635)\ttotal: 7m 1s\tremaining: 4m 1s\n",
      "636:\tlearn: 6.2616892\ttest: 6.2624158\tbest: 6.2624158 (636)\ttotal: 7m 2s\tremaining: 4m\n",
      "637:\tlearn: 6.2616639\ttest: 6.2624154\tbest: 6.2624154 (637)\ttotal: 7m 2s\tremaining: 3m 59s\n",
      "638:\tlearn: 6.2616253\ttest: 6.2624016\tbest: 6.2624016 (638)\ttotal: 7m 3s\tremaining: 3m 59s\n",
      "639:\tlearn: 6.2615928\ttest: 6.2623957\tbest: 6.2623957 (639)\ttotal: 7m 4s\tremaining: 3m 58s\n",
      "640:\tlearn: 6.2615461\ttest: 6.2623771\tbest: 6.2623771 (640)\ttotal: 7m 4s\tremaining: 3m 57s\n",
      "641:\tlearn: 6.2615125\ttest: 6.2623437\tbest: 6.2623437 (641)\ttotal: 7m 5s\tremaining: 3m 57s\n",
      "642:\tlearn: 6.2614899\ttest: 6.2623294\tbest: 6.2623294 (642)\ttotal: 7m 6s\tremaining: 3m 56s\n",
      "643:\tlearn: 6.2614593\ttest: 6.2623018\tbest: 6.2623018 (643)\ttotal: 7m 6s\tremaining: 3m 56s\n",
      "644:\tlearn: 6.2614188\ttest: 6.2622724\tbest: 6.2622724 (644)\ttotal: 7m 7s\tremaining: 3m 55s\n",
      "645:\tlearn: 6.2613741\ttest: 6.2622505\tbest: 6.2622505 (645)\ttotal: 7m 8s\tremaining: 3m 54s\n",
      "646:\tlearn: 6.2613344\ttest: 6.2622029\tbest: 6.2622029 (646)\ttotal: 7m 8s\tremaining: 3m 53s\n",
      "647:\tlearn: 6.2613050\ttest: 6.2621844\tbest: 6.2621844 (647)\ttotal: 7m 9s\tremaining: 3m 53s\n",
      "648:\tlearn: 6.2612681\ttest: 6.2621702\tbest: 6.2621702 (648)\ttotal: 7m 10s\tremaining: 3m 52s\n",
      "649:\tlearn: 6.2612281\ttest: 6.2621449\tbest: 6.2621449 (649)\ttotal: 7m 10s\tremaining: 3m 52s\n",
      "650:\tlearn: 6.2611984\ttest: 6.2621269\tbest: 6.2621269 (650)\ttotal: 7m 11s\tremaining: 3m 51s\n",
      "651:\tlearn: 6.2611629\ttest: 6.2621056\tbest: 6.2621056 (651)\ttotal: 7m 12s\tremaining: 3m 50s\n",
      "652:\tlearn: 6.2611434\ttest: 6.2621010\tbest: 6.2621010 (652)\ttotal: 7m 12s\tremaining: 3m 50s\n",
      "653:\tlearn: 6.2611044\ttest: 6.2620910\tbest: 6.2620910 (653)\ttotal: 7m 13s\tremaining: 3m 49s\n",
      "654:\tlearn: 6.2610686\ttest: 6.2620561\tbest: 6.2620561 (654)\ttotal: 7m 14s\tremaining: 3m 48s\n",
      "655:\tlearn: 6.2610476\ttest: 6.2620475\tbest: 6.2620475 (655)\ttotal: 7m 14s\tremaining: 3m 47s\n",
      "656:\tlearn: 6.2610254\ttest: 6.2620420\tbest: 6.2620420 (656)\ttotal: 7m 15s\tremaining: 3m 47s\n",
      "657:\tlearn: 6.2610029\ttest: 6.2620316\tbest: 6.2620316 (657)\ttotal: 7m 16s\tremaining: 3m 46s\n",
      "658:\tlearn: 6.2609786\ttest: 6.2620101\tbest: 6.2620101 (658)\ttotal: 7m 16s\tremaining: 3m 45s\n",
      "659:\tlearn: 6.2609454\ttest: 6.2619877\tbest: 6.2619877 (659)\ttotal: 7m 17s\tremaining: 3m 45s\n",
      "660:\tlearn: 6.2608950\ttest: 6.2619441\tbest: 6.2619441 (660)\ttotal: 7m 18s\tremaining: 3m 44s\n",
      "661:\tlearn: 6.2608537\ttest: 6.2619058\tbest: 6.2619058 (661)\ttotal: 7m 18s\tremaining: 3m 43s\n",
      "662:\tlearn: 6.2608177\ttest: 6.2618829\tbest: 6.2618829 (662)\ttotal: 7m 19s\tremaining: 3m 43s\n",
      "663:\tlearn: 6.2607900\ttest: 6.2618827\tbest: 6.2618827 (663)\ttotal: 7m 19s\tremaining: 3m 42s\n",
      "664:\tlearn: 6.2607639\ttest: 6.2618756\tbest: 6.2618756 (664)\ttotal: 7m 20s\tremaining: 3m 41s\n",
      "665:\tlearn: 6.2607486\ttest: 6.2618872\tbest: 6.2618756 (664)\ttotal: 7m 21s\tremaining: 3m 41s\n",
      "666:\tlearn: 6.2607032\ttest: 6.2618356\tbest: 6.2618356 (666)\ttotal: 7m 21s\tremaining: 3m 40s\n",
      "667:\tlearn: 6.2606614\ttest: 6.2618263\tbest: 6.2618263 (667)\ttotal: 7m 22s\tremaining: 3m 39s\n",
      "668:\tlearn: 6.2606332\ttest: 6.2618058\tbest: 6.2618058 (668)\ttotal: 7m 23s\tremaining: 3m 39s\n",
      "669:\tlearn: 6.2605649\ttest: 6.2617506\tbest: 6.2617506 (669)\ttotal: 7m 23s\tremaining: 3m 38s\n",
      "670:\tlearn: 6.2605466\ttest: 6.2617433\tbest: 6.2617433 (670)\ttotal: 7m 24s\tremaining: 3m 37s\n",
      "671:\tlearn: 6.2605264\ttest: 6.2617202\tbest: 6.2617202 (671)\ttotal: 7m 24s\tremaining: 3m 37s\n",
      "672:\tlearn: 6.2604955\ttest: 6.2617013\tbest: 6.2617013 (672)\ttotal: 7m 25s\tremaining: 3m 36s\n",
      "673:\tlearn: 6.2604344\ttest: 6.2616284\tbest: 6.2616284 (673)\ttotal: 7m 26s\tremaining: 3m 35s\n",
      "674:\tlearn: 6.2604055\ttest: 6.2616210\tbest: 6.2616210 (674)\ttotal: 7m 26s\tremaining: 3m 35s\n",
      "675:\tlearn: 6.2603774\ttest: 6.2616144\tbest: 6.2616144 (675)\ttotal: 7m 27s\tremaining: 3m 34s\n",
      "676:\tlearn: 6.2603491\ttest: 6.2616028\tbest: 6.2616028 (676)\ttotal: 7m 28s\tremaining: 3m 33s\n",
      "677:\tlearn: 6.2603216\ttest: 6.2615966\tbest: 6.2615966 (677)\ttotal: 7m 28s\tremaining: 3m 33s\n",
      "678:\tlearn: 6.2602853\ttest: 6.2615807\tbest: 6.2615807 (678)\ttotal: 7m 29s\tremaining: 3m 32s\n",
      "679:\tlearn: 6.2602622\ttest: 6.2615641\tbest: 6.2615641 (679)\ttotal: 7m 30s\tremaining: 3m 31s\n",
      "680:\tlearn: 6.2602362\ttest: 6.2615383\tbest: 6.2615383 (680)\ttotal: 7m 30s\tremaining: 3m 31s\n",
      "681:\tlearn: 6.2601988\ttest: 6.2614975\tbest: 6.2614975 (681)\ttotal: 7m 31s\tremaining: 3m 30s\n",
      "682:\tlearn: 6.2601669\ttest: 6.2614860\tbest: 6.2614860 (682)\ttotal: 7m 32s\tremaining: 3m 29s\n",
      "683:\tlearn: 6.2601380\ttest: 6.2614589\tbest: 6.2614589 (683)\ttotal: 7m 32s\tremaining: 3m 29s\n",
      "684:\tlearn: 6.2601137\ttest: 6.2614497\tbest: 6.2614497 (684)\ttotal: 7m 33s\tremaining: 3m 28s\n",
      "685:\tlearn: 6.2600712\ttest: 6.2614122\tbest: 6.2614122 (685)\ttotal: 7m 34s\tremaining: 3m 27s\n",
      "686:\tlearn: 6.2600443\ttest: 6.2614100\tbest: 6.2614100 (686)\ttotal: 7m 34s\tremaining: 3m 27s\n",
      "687:\tlearn: 6.2600124\ttest: 6.2613857\tbest: 6.2613857 (687)\ttotal: 7m 35s\tremaining: 3m 26s\n",
      "688:\tlearn: 6.2599720\ttest: 6.2613619\tbest: 6.2613619 (688)\ttotal: 7m 36s\tremaining: 3m 25s\n",
      "689:\tlearn: 6.2599359\ttest: 6.2613496\tbest: 6.2613496 (689)\ttotal: 7m 36s\tremaining: 3m 25s\n",
      "690:\tlearn: 6.2598941\ttest: 6.2613155\tbest: 6.2613155 (690)\ttotal: 7m 37s\tremaining: 3m 24s\n",
      "691:\tlearn: 6.2598607\ttest: 6.2612696\tbest: 6.2612696 (691)\ttotal: 7m 38s\tremaining: 3m 23s\n",
      "692:\tlearn: 6.2598242\ttest: 6.2612447\tbest: 6.2612447 (692)\ttotal: 7m 38s\tremaining: 3m 23s\n",
      "693:\tlearn: 6.2598002\ttest: 6.2612330\tbest: 6.2612330 (693)\ttotal: 7m 39s\tremaining: 3m 22s\n",
      "694:\tlearn: 6.2597656\ttest: 6.2612057\tbest: 6.2612057 (694)\ttotal: 7m 40s\tremaining: 3m 21s\n",
      "695:\tlearn: 6.2597338\ttest: 6.2611804\tbest: 6.2611804 (695)\ttotal: 7m 40s\tremaining: 3m 21s\n",
      "696:\tlearn: 6.2596942\ttest: 6.2611633\tbest: 6.2611633 (696)\ttotal: 7m 41s\tremaining: 3m 20s\n",
      "697:\tlearn: 6.2596640\ttest: 6.2611334\tbest: 6.2611334 (697)\ttotal: 7m 42s\tremaining: 3m 19s\n",
      "698:\tlearn: 6.2596311\ttest: 6.2611208\tbest: 6.2611208 (698)\ttotal: 7m 42s\tremaining: 3m 19s\n",
      "699:\tlearn: 6.2596031\ttest: 6.2610953\tbest: 6.2610953 (699)\ttotal: 7m 43s\tremaining: 3m 18s\n",
      "700:\tlearn: 6.2595517\ttest: 6.2610417\tbest: 6.2610417 (700)\ttotal: 7m 44s\tremaining: 3m 17s\n",
      "701:\tlearn: 6.2595161\ttest: 6.2610234\tbest: 6.2610234 (701)\ttotal: 7m 44s\tremaining: 3m 17s\n",
      "702:\tlearn: 6.2594919\ttest: 6.2610177\tbest: 6.2610177 (702)\ttotal: 7m 45s\tremaining: 3m 16s\n",
      "703:\tlearn: 6.2594520\ttest: 6.2609888\tbest: 6.2609888 (703)\ttotal: 7m 46s\tremaining: 3m 15s\n",
      "704:\tlearn: 6.2594246\ttest: 6.2609701\tbest: 6.2609701 (704)\ttotal: 7m 46s\tremaining: 3m 15s\n",
      "705:\tlearn: 6.2593802\ttest: 6.2609417\tbest: 6.2609417 (705)\ttotal: 7m 47s\tremaining: 3m 14s\n",
      "706:\tlearn: 6.2593437\ttest: 6.2609034\tbest: 6.2609034 (706)\ttotal: 7m 48s\tremaining: 3m 14s\n",
      "707:\tlearn: 6.2593206\ttest: 6.2608917\tbest: 6.2608917 (707)\ttotal: 7m 48s\tremaining: 3m 13s\n",
      "708:\tlearn: 6.2592931\ttest: 6.2608640\tbest: 6.2608640 (708)\ttotal: 7m 49s\tremaining: 3m 12s\n",
      "709:\tlearn: 6.2592693\ttest: 6.2608505\tbest: 6.2608505 (709)\ttotal: 7m 50s\tremaining: 3m 12s\n",
      "710:\tlearn: 6.2592434\ttest: 6.2608360\tbest: 6.2608360 (710)\ttotal: 7m 50s\tremaining: 3m 11s\n",
      "711:\tlearn: 6.2592269\ttest: 6.2608332\tbest: 6.2608332 (711)\ttotal: 7m 51s\tremaining: 3m 10s\n",
      "712:\tlearn: 6.2591872\ttest: 6.2607959\tbest: 6.2607959 (712)\ttotal: 7m 52s\tremaining: 3m 10s\n",
      "713:\tlearn: 6.2591169\ttest: 6.2607505\tbest: 6.2607505 (713)\ttotal: 7m 52s\tremaining: 3m 9s\n",
      "714:\tlearn: 6.2590922\ttest: 6.2607350\tbest: 6.2607350 (714)\ttotal: 7m 53s\tremaining: 3m 8s\n",
      "715:\tlearn: 6.2590216\ttest: 6.2606687\tbest: 6.2606687 (715)\ttotal: 7m 54s\tremaining: 3m 8s\n",
      "716:\tlearn: 6.2589915\ttest: 6.2606429\tbest: 6.2606429 (716)\ttotal: 7m 54s\tremaining: 3m 7s\n",
      "717:\tlearn: 6.2589515\ttest: 6.2606026\tbest: 6.2606026 (717)\ttotal: 7m 55s\tremaining: 3m 6s\n",
      "718:\tlearn: 6.2589175\ttest: 6.2605922\tbest: 6.2605922 (718)\ttotal: 7m 56s\tremaining: 3m 6s\n",
      "719:\tlearn: 6.2588980\ttest: 6.2605810\tbest: 6.2605810 (719)\ttotal: 7m 56s\tremaining: 3m 5s\n",
      "720:\tlearn: 6.2588748\ttest: 6.2605720\tbest: 6.2605720 (720)\ttotal: 7m 57s\tremaining: 3m 4s\n",
      "721:\tlearn: 6.2588270\ttest: 6.2605101\tbest: 6.2605101 (721)\ttotal: 7m 58s\tremaining: 3m 4s\n",
      "722:\tlearn: 6.2587946\ttest: 6.2604832\tbest: 6.2604832 (722)\ttotal: 7m 58s\tremaining: 3m 3s\n",
      "723:\tlearn: 6.2587661\ttest: 6.2604717\tbest: 6.2604717 (723)\ttotal: 7m 59s\tremaining: 3m 2s\n",
      "724:\tlearn: 6.2587407\ttest: 6.2604553\tbest: 6.2604553 (724)\ttotal: 8m\tremaining: 3m 2s\n",
      "725:\tlearn: 6.2587095\ttest: 6.2604356\tbest: 6.2604356 (725)\ttotal: 8m\tremaining: 3m 1s\n",
      "726:\tlearn: 6.2586758\ttest: 6.2604203\tbest: 6.2604203 (726)\ttotal: 8m 1s\tremaining: 3m\n",
      "727:\tlearn: 6.2586468\ttest: 6.2604097\tbest: 6.2604097 (727)\ttotal: 8m 2s\tremaining: 3m\n",
      "728:\tlearn: 6.2586239\ttest: 6.2603831\tbest: 6.2603831 (728)\ttotal: 8m 2s\tremaining: 2m 59s\n",
      "729:\tlearn: 6.2586001\ttest: 6.2603714\tbest: 6.2603714 (729)\ttotal: 8m 3s\tremaining: 2m 58s\n",
      "730:\tlearn: 6.2585412\ttest: 6.2603229\tbest: 6.2603229 (730)\ttotal: 8m 4s\tremaining: 2m 58s\n",
      "731:\tlearn: 6.2585138\ttest: 6.2603135\tbest: 6.2603135 (731)\ttotal: 8m 4s\tremaining: 2m 57s\n",
      "732:\tlearn: 6.2584837\ttest: 6.2602973\tbest: 6.2602973 (732)\ttotal: 8m 5s\tremaining: 2m 56s\n",
      "733:\tlearn: 6.2584235\ttest: 6.2602432\tbest: 6.2602432 (733)\ttotal: 8m 6s\tremaining: 2m 56s\n",
      "734:\tlearn: 6.2583992\ttest: 6.2602346\tbest: 6.2602346 (734)\ttotal: 8m 6s\tremaining: 2m 55s\n",
      "735:\tlearn: 6.2583715\ttest: 6.2602080\tbest: 6.2602080 (735)\ttotal: 8m 7s\tremaining: 2m 54s\n",
      "736:\tlearn: 6.2583477\ttest: 6.2601954\tbest: 6.2601954 (736)\ttotal: 8m 8s\tremaining: 2m 54s\n",
      "737:\tlearn: 6.2583122\ttest: 6.2601636\tbest: 6.2601636 (737)\ttotal: 8m 8s\tremaining: 2m 53s\n",
      "738:\tlearn: 6.2582845\ttest: 6.2601428\tbest: 6.2601428 (738)\ttotal: 8m 9s\tremaining: 2m 52s\n",
      "739:\tlearn: 6.2582594\ttest: 6.2601219\tbest: 6.2601219 (739)\ttotal: 8m 10s\tremaining: 2m 52s\n",
      "740:\tlearn: 6.2582336\ttest: 6.2601030\tbest: 6.2601030 (740)\ttotal: 8m 10s\tremaining: 2m 51s\n",
      "741:\tlearn: 6.2582014\ttest: 6.2601052\tbest: 6.2601030 (740)\ttotal: 8m 11s\tremaining: 2m 50s\n",
      "742:\tlearn: 6.2581783\ttest: 6.2600987\tbest: 6.2600987 (742)\ttotal: 8m 12s\tremaining: 2m 50s\n",
      "743:\tlearn: 6.2581586\ttest: 6.2600817\tbest: 6.2600817 (743)\ttotal: 8m 12s\tremaining: 2m 49s\n",
      "744:\tlearn: 6.2581270\ttest: 6.2600834\tbest: 6.2600817 (743)\ttotal: 8m 13s\tremaining: 2m 48s\n",
      "745:\tlearn: 6.2580967\ttest: 6.2600825\tbest: 6.2600817 (743)\ttotal: 8m 13s\tremaining: 2m 48s\n",
      "746:\tlearn: 6.2580689\ttest: 6.2600728\tbest: 6.2600728 (746)\ttotal: 8m 14s\tremaining: 2m 47s\n",
      "747:\tlearn: 6.2580392\ttest: 6.2600493\tbest: 6.2600493 (747)\ttotal: 8m 15s\tremaining: 2m 46s\n",
      "748:\tlearn: 6.2580209\ttest: 6.2600304\tbest: 6.2600304 (748)\ttotal: 8m 15s\tremaining: 2m 46s\n",
      "749:\tlearn: 6.2580008\ttest: 6.2600242\tbest: 6.2600242 (749)\ttotal: 8m 16s\tremaining: 2m 45s\n",
      "750:\tlearn: 6.2579817\ttest: 6.2600132\tbest: 6.2600132 (750)\ttotal: 8m 17s\tremaining: 2m 44s\n",
      "751:\tlearn: 6.2579624\ttest: 6.2600036\tbest: 6.2600036 (751)\ttotal: 8m 17s\tremaining: 2m 44s\n",
      "752:\tlearn: 6.2579330\ttest: 6.2599892\tbest: 6.2599892 (752)\ttotal: 8m 18s\tremaining: 2m 43s\n",
      "753:\tlearn: 6.2579051\ttest: 6.2599810\tbest: 6.2599810 (753)\ttotal: 8m 19s\tremaining: 2m 42s\n",
      "754:\tlearn: 6.2578798\ttest: 6.2599810\tbest: 6.2599810 (754)\ttotal: 8m 19s\tremaining: 2m 42s\n",
      "755:\tlearn: 6.2578616\ttest: 6.2599634\tbest: 6.2599634 (755)\ttotal: 8m 20s\tremaining: 2m 41s\n",
      "756:\tlearn: 6.2578301\ttest: 6.2599587\tbest: 6.2599587 (756)\ttotal: 8m 21s\tremaining: 2m 40s\n",
      "757:\tlearn: 6.2577993\ttest: 6.2599378\tbest: 6.2599378 (757)\ttotal: 8m 21s\tremaining: 2m 40s\n",
      "758:\tlearn: 6.2577784\ttest: 6.2599285\tbest: 6.2599285 (758)\ttotal: 8m 22s\tremaining: 2m 39s\n",
      "759:\tlearn: 6.2577502\ttest: 6.2598977\tbest: 6.2598977 (759)\ttotal: 8m 22s\tremaining: 2m 38s\n",
      "760:\tlearn: 6.2577233\ttest: 6.2598884\tbest: 6.2598884 (760)\ttotal: 8m 23s\tremaining: 2m 38s\n",
      "761:\tlearn: 6.2576895\ttest: 6.2598578\tbest: 6.2598578 (761)\ttotal: 8m 24s\tremaining: 2m 37s\n",
      "762:\tlearn: 6.2576662\ttest: 6.2598408\tbest: 6.2598408 (762)\ttotal: 8m 24s\tremaining: 2m 36s\n",
      "763:\tlearn: 6.2576391\ttest: 6.2598314\tbest: 6.2598314 (763)\ttotal: 8m 25s\tremaining: 2m 36s\n",
      "764:\tlearn: 6.2575695\ttest: 6.2597744\tbest: 6.2597744 (764)\ttotal: 8m 26s\tremaining: 2m 35s\n",
      "765:\tlearn: 6.2575558\ttest: 6.2597707\tbest: 6.2597707 (765)\ttotal: 8m 26s\tremaining: 2m 34s\n",
      "766:\tlearn: 6.2575320\ttest: 6.2597555\tbest: 6.2597555 (766)\ttotal: 8m 27s\tremaining: 2m 34s\n",
      "767:\tlearn: 6.2575119\ttest: 6.2597424\tbest: 6.2597424 (767)\ttotal: 8m 28s\tremaining: 2m 33s\n",
      "768:\tlearn: 6.2574841\ttest: 6.2597347\tbest: 6.2597347 (768)\ttotal: 8m 28s\tremaining: 2m 32s\n",
      "769:\tlearn: 6.2574428\ttest: 6.2597217\tbest: 6.2597217 (769)\ttotal: 8m 29s\tremaining: 2m 32s\n",
      "770:\tlearn: 6.2574203\ttest: 6.2596916\tbest: 6.2596916 (770)\ttotal: 8m 30s\tremaining: 2m 31s\n",
      "771:\tlearn: 6.2573982\ttest: 6.2596677\tbest: 6.2596677 (771)\ttotal: 8m 30s\tremaining: 2m 30s\n",
      "772:\tlearn: 6.2573756\ttest: 6.2596566\tbest: 6.2596566 (772)\ttotal: 8m 31s\tremaining: 2m 30s\n",
      "773:\tlearn: 6.2573515\ttest: 6.2596335\tbest: 6.2596335 (773)\ttotal: 8m 32s\tremaining: 2m 29s\n",
      "774:\tlearn: 6.2573128\ttest: 6.2595922\tbest: 6.2595922 (774)\ttotal: 8m 32s\tremaining: 2m 28s\n",
      "775:\tlearn: 6.2572747\ttest: 6.2595681\tbest: 6.2595681 (775)\ttotal: 8m 33s\tremaining: 2m 28s\n",
      "776:\tlearn: 6.2572512\ttest: 6.2595537\tbest: 6.2595537 (776)\ttotal: 8m 34s\tremaining: 2m 27s\n",
      "777:\tlearn: 6.2572359\ttest: 6.2595439\tbest: 6.2595439 (777)\ttotal: 8m 34s\tremaining: 2m 26s\n",
      "778:\tlearn: 6.2572127\ttest: 6.2595382\tbest: 6.2595382 (778)\ttotal: 8m 35s\tremaining: 2m 26s\n",
      "779:\tlearn: 6.2571767\ttest: 6.2595156\tbest: 6.2595156 (779)\ttotal: 8m 35s\tremaining: 2m 25s\n",
      "780:\tlearn: 6.2571568\ttest: 6.2594950\tbest: 6.2594950 (780)\ttotal: 8m 36s\tremaining: 2m 24s\n",
      "781:\tlearn: 6.2571344\ttest: 6.2594892\tbest: 6.2594892 (781)\ttotal: 8m 37s\tremaining: 2m 24s\n",
      "782:\tlearn: 6.2571139\ttest: 6.2594765\tbest: 6.2594765 (782)\ttotal: 8m 37s\tremaining: 2m 23s\n",
      "783:\tlearn: 6.2570853\ttest: 6.2594543\tbest: 6.2594543 (783)\ttotal: 8m 38s\tremaining: 2m 22s\n",
      "784:\tlearn: 6.2570271\ttest: 6.2594015\tbest: 6.2594015 (784)\ttotal: 8m 39s\tremaining: 2m 22s\n",
      "785:\tlearn: 6.2570056\ttest: 6.2593769\tbest: 6.2593769 (785)\ttotal: 8m 39s\tremaining: 2m 21s\n",
      "786:\tlearn: 6.2569786\ttest: 6.2593555\tbest: 6.2593555 (786)\ttotal: 8m 40s\tremaining: 2m 20s\n",
      "787:\tlearn: 6.2569526\ttest: 6.2593493\tbest: 6.2593493 (787)\ttotal: 8m 41s\tremaining: 2m 20s\n",
      "788:\tlearn: 6.2569012\ttest: 6.2593214\tbest: 6.2593214 (788)\ttotal: 8m 41s\tremaining: 2m 19s\n",
      "789:\tlearn: 6.2568695\ttest: 6.2593079\tbest: 6.2593079 (789)\ttotal: 8m 42s\tremaining: 2m 18s\n",
      "790:\tlearn: 6.2568557\ttest: 6.2593033\tbest: 6.2593033 (790)\ttotal: 8m 43s\tremaining: 2m 18s\n",
      "791:\tlearn: 6.2568316\ttest: 6.2592963\tbest: 6.2592963 (791)\ttotal: 8m 43s\tremaining: 2m 17s\n",
      "792:\tlearn: 6.2568105\ttest: 6.2592861\tbest: 6.2592861 (792)\ttotal: 8m 44s\tremaining: 2m 16s\n",
      "793:\tlearn: 6.2567976\ttest: 6.2592809\tbest: 6.2592809 (793)\ttotal: 8m 44s\tremaining: 2m 16s\n",
      "794:\tlearn: 6.2567671\ttest: 6.2592573\tbest: 6.2592573 (794)\ttotal: 8m 45s\tremaining: 2m 15s\n",
      "795:\tlearn: 6.2567324\ttest: 6.2592152\tbest: 6.2592152 (795)\ttotal: 8m 46s\tremaining: 2m 14s\n",
      "796:\tlearn: 6.2567152\ttest: 6.2592090\tbest: 6.2592090 (796)\ttotal: 8m 47s\tremaining: 2m 14s\n",
      "797:\tlearn: 6.2566920\ttest: 6.2591782\tbest: 6.2591782 (797)\ttotal: 8m 47s\tremaining: 2m 13s\n",
      "798:\tlearn: 6.2566704\ttest: 6.2591716\tbest: 6.2591716 (798)\ttotal: 8m 48s\tremaining: 2m 12s\n",
      "799:\tlearn: 6.2566523\ttest: 6.2591765\tbest: 6.2591716 (798)\ttotal: 8m 48s\tremaining: 2m 12s\n",
      "800:\tlearn: 6.2566196\ttest: 6.2591465\tbest: 6.2591465 (800)\ttotal: 8m 49s\tremaining: 2m 11s\n",
      "801:\tlearn: 6.2566018\ttest: 6.2591278\tbest: 6.2591278 (801)\ttotal: 8m 50s\tremaining: 2m 10s\n",
      "802:\tlearn: 6.2565700\ttest: 6.2591057\tbest: 6.2591057 (802)\ttotal: 8m 50s\tremaining: 2m 10s\n",
      "803:\tlearn: 6.2564971\ttest: 6.2590348\tbest: 6.2590348 (803)\ttotal: 8m 51s\tremaining: 2m 9s\n",
      "804:\tlearn: 6.2564698\ttest: 6.2590213\tbest: 6.2590213 (804)\ttotal: 8m 52s\tremaining: 2m 8s\n",
      "805:\tlearn: 6.2564394\ttest: 6.2590083\tbest: 6.2590083 (805)\ttotal: 8m 52s\tremaining: 2m 8s\n",
      "806:\tlearn: 6.2564198\ttest: 6.2590038\tbest: 6.2590038 (806)\ttotal: 8m 53s\tremaining: 2m 7s\n",
      "807:\tlearn: 6.2563705\ttest: 6.2589604\tbest: 6.2589604 (807)\ttotal: 8m 54s\tremaining: 2m 6s\n",
      "808:\tlearn: 6.2563338\ttest: 6.2589220\tbest: 6.2589220 (808)\ttotal: 8m 55s\tremaining: 2m 6s\n",
      "809:\tlearn: 6.2563028\ttest: 6.2588994\tbest: 6.2588994 (809)\ttotal: 8m 55s\tremaining: 2m 5s\n",
      "810:\tlearn: 6.2562650\ttest: 6.2588776\tbest: 6.2588776 (810)\ttotal: 8m 56s\tremaining: 2m 4s\n",
      "811:\tlearn: 6.2562209\ttest: 6.2588536\tbest: 6.2588536 (811)\ttotal: 8m 57s\tremaining: 2m 4s\n",
      "812:\tlearn: 6.2562034\ttest: 6.2588497\tbest: 6.2588497 (812)\ttotal: 8m 57s\tremaining: 2m 3s\n",
      "813:\tlearn: 6.2561856\ttest: 6.2588422\tbest: 6.2588422 (813)\ttotal: 8m 58s\tremaining: 2m 2s\n",
      "814:\tlearn: 6.2561693\ttest: 6.2588449\tbest: 6.2588422 (813)\ttotal: 8m 58s\tremaining: 2m 2s\n",
      "815:\tlearn: 6.2561060\ttest: 6.2588001\tbest: 6.2588001 (815)\ttotal: 8m 59s\tremaining: 2m 1s\n",
      "816:\tlearn: 6.2560906\ttest: 6.2587866\tbest: 6.2587866 (816)\ttotal: 9m\tremaining: 2m\n",
      "817:\tlearn: 6.2560535\ttest: 6.2587637\tbest: 6.2587637 (817)\ttotal: 9m\tremaining: 2m\n",
      "818:\tlearn: 6.2559969\ttest: 6.2587146\tbest: 6.2587146 (818)\ttotal: 9m 1s\tremaining: 1m 59s\n",
      "819:\tlearn: 6.2559716\ttest: 6.2587002\tbest: 6.2587002 (819)\ttotal: 9m 2s\tremaining: 1m 58s\n",
      "820:\tlearn: 6.2559317\ttest: 6.2586762\tbest: 6.2586762 (820)\ttotal: 9m 2s\tremaining: 1m 58s\n",
      "821:\tlearn: 6.2558898\ttest: 6.2586384\tbest: 6.2586384 (821)\ttotal: 9m 3s\tremaining: 1m 57s\n",
      "822:\tlearn: 6.2558391\ttest: 6.2586098\tbest: 6.2586098 (822)\ttotal: 9m 4s\tremaining: 1m 57s\n",
      "823:\tlearn: 6.2558227\ttest: 6.2585963\tbest: 6.2585963 (823)\ttotal: 9m 4s\tremaining: 1m 56s\n",
      "824:\tlearn: 6.2557911\ttest: 6.2585842\tbest: 6.2585842 (824)\ttotal: 9m 5s\tremaining: 1m 55s\n",
      "825:\tlearn: 6.2557726\ttest: 6.2585687\tbest: 6.2585687 (825)\ttotal: 9m 6s\tremaining: 1m 55s\n",
      "826:\tlearn: 6.2557492\ttest: 6.2585510\tbest: 6.2585510 (826)\ttotal: 9m 6s\tremaining: 1m 54s\n",
      "827:\tlearn: 6.2557283\ttest: 6.2585326\tbest: 6.2585326 (827)\ttotal: 9m 7s\tremaining: 1m 53s\n",
      "828:\tlearn: 6.2557052\ttest: 6.2585074\tbest: 6.2585074 (828)\ttotal: 9m 8s\tremaining: 1m 53s\n",
      "829:\tlearn: 6.2556917\ttest: 6.2584937\tbest: 6.2584937 (829)\ttotal: 9m 8s\tremaining: 1m 52s\n",
      "830:\tlearn: 6.2556754\ttest: 6.2584823\tbest: 6.2584823 (830)\ttotal: 9m 9s\tremaining: 1m 51s\n",
      "831:\tlearn: 6.2556535\ttest: 6.2584746\tbest: 6.2584746 (831)\ttotal: 9m 10s\tremaining: 1m 51s\n",
      "832:\tlearn: 6.2556287\ttest: 6.2584493\tbest: 6.2584493 (832)\ttotal: 9m 10s\tremaining: 1m 50s\n",
      "833:\tlearn: 6.2556070\ttest: 6.2584457\tbest: 6.2584457 (833)\ttotal: 9m 11s\tremaining: 1m 49s\n",
      "834:\tlearn: 6.2555596\ttest: 6.2584132\tbest: 6.2584132 (834)\ttotal: 9m 12s\tremaining: 1m 49s\n",
      "835:\tlearn: 6.2555395\ttest: 6.2584003\tbest: 6.2584003 (835)\ttotal: 9m 12s\tremaining: 1m 48s\n",
      "836:\tlearn: 6.2555184\ttest: 6.2583885\tbest: 6.2583885 (836)\ttotal: 9m 13s\tremaining: 1m 47s\n",
      "837:\tlearn: 6.2554932\ttest: 6.2583751\tbest: 6.2583751 (837)\ttotal: 9m 13s\tremaining: 1m 47s\n",
      "838:\tlearn: 6.2554636\ttest: 6.2583632\tbest: 6.2583632 (838)\ttotal: 9m 14s\tremaining: 1m 46s\n",
      "839:\tlearn: 6.2554400\ttest: 6.2583357\tbest: 6.2583357 (839)\ttotal: 9m 15s\tremaining: 1m 45s\n",
      "840:\tlearn: 6.2554175\ttest: 6.2583208\tbest: 6.2583208 (840)\ttotal: 9m 15s\tremaining: 1m 45s\n",
      "841:\tlearn: 6.2553754\ttest: 6.2582855\tbest: 6.2582855 (841)\ttotal: 9m 16s\tremaining: 1m 44s\n",
      "842:\tlearn: 6.2553204\ttest: 6.2582403\tbest: 6.2582403 (842)\ttotal: 9m 17s\tremaining: 1m 43s\n",
      "843:\tlearn: 6.2552993\ttest: 6.2582296\tbest: 6.2582296 (843)\ttotal: 9m 17s\tremaining: 1m 43s\n",
      "844:\tlearn: 6.2552588\ttest: 6.2581958\tbest: 6.2581958 (844)\ttotal: 9m 18s\tremaining: 1m 42s\n",
      "845:\tlearn: 6.2552381\ttest: 6.2581933\tbest: 6.2581933 (845)\ttotal: 9m 19s\tremaining: 1m 41s\n",
      "846:\tlearn: 6.2552094\ttest: 6.2581749\tbest: 6.2581749 (846)\ttotal: 9m 19s\tremaining: 1m 41s\n",
      "847:\tlearn: 6.2551785\ttest: 6.2581709\tbest: 6.2581709 (847)\ttotal: 9m 20s\tremaining: 1m 40s\n",
      "848:\tlearn: 6.2551427\ttest: 6.2581443\tbest: 6.2581443 (848)\ttotal: 9m 21s\tremaining: 1m 39s\n",
      "849:\tlearn: 6.2551262\ttest: 6.2581261\tbest: 6.2581261 (849)\ttotal: 9m 21s\tremaining: 1m 39s\n",
      "850:\tlearn: 6.2550992\ttest: 6.2580984\tbest: 6.2580984 (850)\ttotal: 9m 22s\tremaining: 1m 38s\n",
      "851:\tlearn: 6.2550819\ttest: 6.2580902\tbest: 6.2580902 (851)\ttotal: 9m 23s\tremaining: 1m 37s\n",
      "852:\tlearn: 6.2550520\ttest: 6.2580875\tbest: 6.2580875 (852)\ttotal: 9m 23s\tremaining: 1m 37s\n",
      "853:\tlearn: 6.2550343\ttest: 6.2580811\tbest: 6.2580811 (853)\ttotal: 9m 24s\tremaining: 1m 36s\n",
      "854:\tlearn: 6.2550176\ttest: 6.2580738\tbest: 6.2580738 (854)\ttotal: 9m 24s\tremaining: 1m 35s\n",
      "855:\tlearn: 6.2549922\ttest: 6.2580554\tbest: 6.2580554 (855)\ttotal: 9m 25s\tremaining: 1m 35s\n",
      "856:\tlearn: 6.2549558\ttest: 6.2580357\tbest: 6.2580357 (856)\ttotal: 9m 26s\tremaining: 1m 34s\n",
      "857:\tlearn: 6.2549340\ttest: 6.2580145\tbest: 6.2580145 (857)\ttotal: 9m 26s\tremaining: 1m 33s\n",
      "858:\tlearn: 6.2548981\ttest: 6.2579993\tbest: 6.2579993 (858)\ttotal: 9m 27s\tremaining: 1m 33s\n",
      "859:\tlearn: 6.2548667\ttest: 6.2579656\tbest: 6.2579656 (859)\ttotal: 9m 28s\tremaining: 1m 32s\n",
      "860:\tlearn: 6.2548436\ttest: 6.2579391\tbest: 6.2579391 (860)\ttotal: 9m 28s\tremaining: 1m 31s\n",
      "861:\tlearn: 6.2548254\ttest: 6.2579319\tbest: 6.2579319 (861)\ttotal: 9m 29s\tremaining: 1m 31s\n",
      "862:\tlearn: 6.2548060\ttest: 6.2579197\tbest: 6.2579197 (862)\ttotal: 9m 30s\tremaining: 1m 30s\n",
      "863:\tlearn: 6.2547821\ttest: 6.2579089\tbest: 6.2579089 (863)\ttotal: 9m 30s\tremaining: 1m 29s\n",
      "864:\tlearn: 6.2547360\ttest: 6.2578733\tbest: 6.2578733 (864)\ttotal: 9m 31s\tremaining: 1m 29s\n",
      "865:\tlearn: 6.2547214\ttest: 6.2578595\tbest: 6.2578595 (865)\ttotal: 9m 32s\tremaining: 1m 28s\n",
      "866:\tlearn: 6.2546878\ttest: 6.2578224\tbest: 6.2578224 (866)\ttotal: 9m 32s\tremaining: 1m 27s\n",
      "867:\tlearn: 6.2546599\ttest: 6.2578151\tbest: 6.2578151 (867)\ttotal: 9m 33s\tremaining: 1m 27s\n",
      "868:\tlearn: 6.2546409\ttest: 6.2577989\tbest: 6.2577989 (868)\ttotal: 9m 33s\tremaining: 1m 26s\n",
      "869:\tlearn: 6.2546210\ttest: 6.2577789\tbest: 6.2577789 (869)\ttotal: 9m 34s\tremaining: 1m 25s\n",
      "870:\tlearn: 6.2545818\ttest: 6.2577621\tbest: 6.2577621 (870)\ttotal: 9m 35s\tremaining: 1m 25s\n",
      "871:\tlearn: 6.2545486\ttest: 6.2577383\tbest: 6.2577383 (871)\ttotal: 9m 35s\tremaining: 1m 24s\n",
      "872:\tlearn: 6.2545170\ttest: 6.2577084\tbest: 6.2577084 (872)\ttotal: 9m 36s\tremaining: 1m 23s\n",
      "873:\tlearn: 6.2544887\ttest: 6.2576796\tbest: 6.2576796 (873)\ttotal: 9m 37s\tremaining: 1m 23s\n",
      "874:\tlearn: 6.2544718\ttest: 6.2576818\tbest: 6.2576796 (873)\ttotal: 9m 37s\tremaining: 1m 22s\n",
      "875:\tlearn: 6.2544454\ttest: 6.2576538\tbest: 6.2576538 (875)\ttotal: 9m 38s\tremaining: 1m 21s\n",
      "876:\tlearn: 6.2544101\ttest: 6.2576220\tbest: 6.2576220 (876)\ttotal: 9m 39s\tremaining: 1m 21s\n",
      "877:\tlearn: 6.2543864\ttest: 6.2576071\tbest: 6.2576071 (877)\ttotal: 9m 39s\tremaining: 1m 20s\n",
      "878:\tlearn: 6.2543604\ttest: 6.2576097\tbest: 6.2576071 (877)\ttotal: 9m 40s\tremaining: 1m 19s\n",
      "879:\tlearn: 6.2543164\ttest: 6.2575822\tbest: 6.2575822 (879)\ttotal: 9m 41s\tremaining: 1m 19s\n",
      "880:\tlearn: 6.2542816\ttest: 6.2575374\tbest: 6.2575374 (880)\ttotal: 9m 41s\tremaining: 1m 18s\n",
      "881:\tlearn: 6.2542421\ttest: 6.2575181\tbest: 6.2575181 (881)\ttotal: 9m 42s\tremaining: 1m 17s\n",
      "882:\tlearn: 6.2542266\ttest: 6.2575076\tbest: 6.2575076 (882)\ttotal: 9m 42s\tremaining: 1m 17s\n",
      "883:\tlearn: 6.2542042\ttest: 6.2575023\tbest: 6.2575023 (883)\ttotal: 9m 43s\tremaining: 1m 16s\n",
      "884:\tlearn: 6.2541673\ttest: 6.2574779\tbest: 6.2574779 (884)\ttotal: 9m 44s\tremaining: 1m 15s\n",
      "885:\tlearn: 6.2541370\ttest: 6.2574620\tbest: 6.2574620 (885)\ttotal: 9m 44s\tremaining: 1m 15s\n",
      "886:\tlearn: 6.2541175\ttest: 6.2574712\tbest: 6.2574620 (885)\ttotal: 9m 45s\tremaining: 1m 14s\n",
      "887:\tlearn: 6.2540951\ttest: 6.2574639\tbest: 6.2574620 (885)\ttotal: 9m 46s\tremaining: 1m 13s\n",
      "888:\tlearn: 6.2540580\ttest: 6.2574353\tbest: 6.2574353 (888)\ttotal: 9m 46s\tremaining: 1m 13s\n",
      "889:\tlearn: 6.2540238\ttest: 6.2574084\tbest: 6.2574084 (889)\ttotal: 9m 47s\tremaining: 1m 12s\n",
      "890:\tlearn: 6.2540029\ttest: 6.2573992\tbest: 6.2573992 (890)\ttotal: 9m 47s\tremaining: 1m 11s\n",
      "891:\tlearn: 6.2539800\ttest: 6.2573830\tbest: 6.2573830 (891)\ttotal: 9m 48s\tremaining: 1m 11s\n",
      "892:\tlearn: 6.2539635\ttest: 6.2573759\tbest: 6.2573759 (892)\ttotal: 9m 49s\tremaining: 1m 10s\n",
      "893:\tlearn: 6.2539437\ttest: 6.2573633\tbest: 6.2573633 (893)\ttotal: 9m 49s\tremaining: 1m 9s\n",
      "894:\tlearn: 6.2539220\ttest: 6.2573587\tbest: 6.2573587 (894)\ttotal: 9m 50s\tremaining: 1m 9s\n",
      "895:\tlearn: 6.2538785\ttest: 6.2573246\tbest: 6.2573246 (895)\ttotal: 9m 51s\tremaining: 1m 8s\n",
      "896:\tlearn: 6.2538534\ttest: 6.2573096\tbest: 6.2573096 (896)\ttotal: 9m 52s\tremaining: 1m 7s\n",
      "897:\tlearn: 6.2538280\ttest: 6.2572977\tbest: 6.2572977 (897)\ttotal: 9m 52s\tremaining: 1m 7s\n",
      "898:\tlearn: 6.2537974\ttest: 6.2572744\tbest: 6.2572744 (898)\ttotal: 9m 53s\tremaining: 1m 6s\n",
      "899:\tlearn: 6.2537807\ttest: 6.2572581\tbest: 6.2572581 (899)\ttotal: 9m 54s\tremaining: 1m 6s\n",
      "900:\tlearn: 6.2537497\ttest: 6.2572373\tbest: 6.2572373 (900)\ttotal: 9m 54s\tremaining: 1m 5s\n",
      "901:\tlearn: 6.2537309\ttest: 6.2572259\tbest: 6.2572259 (901)\ttotal: 9m 55s\tremaining: 1m 4s\n",
      "902:\tlearn: 6.2536996\ttest: 6.2572005\tbest: 6.2572005 (902)\ttotal: 9m 55s\tremaining: 1m 4s\n",
      "903:\tlearn: 6.2536790\ttest: 6.2571996\tbest: 6.2571996 (903)\ttotal: 9m 56s\tremaining: 1m 3s\n",
      "904:\tlearn: 6.2536559\ttest: 6.2571668\tbest: 6.2571668 (904)\ttotal: 9m 57s\tremaining: 1m 2s\n",
      "905:\tlearn: 6.2536234\ttest: 6.2571481\tbest: 6.2571481 (905)\ttotal: 9m 57s\tremaining: 1m 2s\n",
      "906:\tlearn: 6.2536041\ttest: 6.2571383\tbest: 6.2571383 (906)\ttotal: 9m 58s\tremaining: 1m 1s\n",
      "907:\tlearn: 6.2535765\ttest: 6.2571234\tbest: 6.2571234 (907)\ttotal: 9m 59s\tremaining: 1m\n",
      "908:\tlearn: 6.2535577\ttest: 6.2571083\tbest: 6.2571083 (908)\ttotal: 9m 59s\tremaining: 1m\n",
      "909:\tlearn: 6.2535301\ttest: 6.2571023\tbest: 6.2571023 (909)\ttotal: 10m\tremaining: 59.4s\n",
      "910:\tlearn: 6.2534988\ttest: 6.2570873\tbest: 6.2570873 (910)\ttotal: 10m 1s\tremaining: 58.7s\n",
      "911:\tlearn: 6.2534679\ttest: 6.2570676\tbest: 6.2570676 (911)\ttotal: 10m 1s\tremaining: 58.1s\n",
      "912:\tlearn: 6.2534369\ttest: 6.2570393\tbest: 6.2570393 (912)\ttotal: 10m 2s\tremaining: 57.4s\n",
      "913:\tlearn: 6.2533897\ttest: 6.2569951\tbest: 6.2569951 (913)\ttotal: 10m 2s\tremaining: 56.7s\n",
      "914:\tlearn: 6.2533648\ttest: 6.2569890\tbest: 6.2569890 (914)\ttotal: 10m 3s\tremaining: 56.1s\n",
      "915:\tlearn: 6.2533381\ttest: 6.2569750\tbest: 6.2569750 (915)\ttotal: 10m 4s\tremaining: 55.4s\n",
      "916:\tlearn: 6.2533111\ttest: 6.2569433\tbest: 6.2569433 (916)\ttotal: 10m 4s\tremaining: 54.8s\n",
      "917:\tlearn: 6.2532937\ttest: 6.2569368\tbest: 6.2569368 (917)\ttotal: 10m 5s\tremaining: 54.1s\n",
      "918:\tlearn: 6.2532726\ttest: 6.2569276\tbest: 6.2569276 (918)\ttotal: 10m 6s\tremaining: 53.4s\n",
      "919:\tlearn: 6.2532494\ttest: 6.2569164\tbest: 6.2569164 (919)\ttotal: 10m 6s\tremaining: 52.8s\n",
      "920:\tlearn: 6.2532295\ttest: 6.2569051\tbest: 6.2569051 (920)\ttotal: 10m 7s\tremaining: 52.1s\n",
      "921:\tlearn: 6.2531862\ttest: 6.2568719\tbest: 6.2568719 (921)\ttotal: 10m 8s\tremaining: 51.4s\n",
      "922:\tlearn: 6.2531669\ttest: 6.2568536\tbest: 6.2568536 (922)\ttotal: 10m 8s\tremaining: 50.8s\n",
      "923:\tlearn: 6.2531388\ttest: 6.2568375\tbest: 6.2568375 (923)\ttotal: 10m 9s\tremaining: 50.1s\n",
      "924:\tlearn: 6.2531039\ttest: 6.2568429\tbest: 6.2568375 (923)\ttotal: 10m 10s\tremaining: 49.5s\n",
      "925:\tlearn: 6.2530849\ttest: 6.2568328\tbest: 6.2568328 (925)\ttotal: 10m 10s\tremaining: 48.8s\n",
      "926:\tlearn: 6.2530726\ttest: 6.2568296\tbest: 6.2568296 (926)\ttotal: 10m 11s\tremaining: 48.1s\n",
      "927:\tlearn: 6.2530365\ttest: 6.2568101\tbest: 6.2568101 (927)\ttotal: 10m 11s\tremaining: 47.5s\n",
      "928:\tlearn: 6.2530089\ttest: 6.2567969\tbest: 6.2567969 (928)\ttotal: 10m 12s\tremaining: 46.8s\n",
      "929:\tlearn: 6.2529807\ttest: 6.2567761\tbest: 6.2567761 (929)\ttotal: 10m 13s\tremaining: 46.2s\n",
      "930:\tlearn: 6.2529515\ttest: 6.2567722\tbest: 6.2567722 (930)\ttotal: 10m 13s\tremaining: 45.5s\n",
      "931:\tlearn: 6.2529288\ttest: 6.2567532\tbest: 6.2567532 (931)\ttotal: 10m 14s\tremaining: 44.8s\n",
      "932:\tlearn: 6.2528859\ttest: 6.2567070\tbest: 6.2567070 (932)\ttotal: 10m 15s\tremaining: 44.2s\n",
      "933:\tlearn: 6.2528667\ttest: 6.2567057\tbest: 6.2567057 (933)\ttotal: 10m 15s\tremaining: 43.5s\n",
      "934:\tlearn: 6.2528509\ttest: 6.2566871\tbest: 6.2566871 (934)\ttotal: 10m 16s\tremaining: 42.8s\n",
      "935:\tlearn: 6.2528183\ttest: 6.2566790\tbest: 6.2566790 (935)\ttotal: 10m 16s\tremaining: 42.2s\n",
      "936:\tlearn: 6.2527948\ttest: 6.2566599\tbest: 6.2566599 (936)\ttotal: 10m 17s\tremaining: 41.5s\n",
      "937:\tlearn: 6.2527675\ttest: 6.2566223\tbest: 6.2566223 (937)\ttotal: 10m 18s\tremaining: 40.9s\n",
      "938:\tlearn: 6.2527268\ttest: 6.2565791\tbest: 6.2565791 (938)\ttotal: 10m 18s\tremaining: 40.2s\n",
      "939:\tlearn: 6.2527129\ttest: 6.2565769\tbest: 6.2565769 (939)\ttotal: 10m 19s\tremaining: 39.5s\n",
      "940:\tlearn: 6.2526856\ttest: 6.2565700\tbest: 6.2565700 (940)\ttotal: 10m 20s\tremaining: 38.9s\n",
      "941:\tlearn: 6.2526626\ttest: 6.2565569\tbest: 6.2565569 (941)\ttotal: 10m 20s\tremaining: 38.2s\n",
      "942:\tlearn: 6.2526417\ttest: 6.2565495\tbest: 6.2565495 (942)\ttotal: 10m 21s\tremaining: 37.6s\n",
      "943:\tlearn: 6.2526160\ttest: 6.2565318\tbest: 6.2565318 (943)\ttotal: 10m 22s\tremaining: 36.9s\n",
      "944:\tlearn: 6.2525851\ttest: 6.2564950\tbest: 6.2564950 (944)\ttotal: 10m 22s\tremaining: 36.2s\n",
      "945:\tlearn: 6.2525594\ttest: 6.2564754\tbest: 6.2564754 (945)\ttotal: 10m 23s\tremaining: 35.6s\n",
      "946:\tlearn: 6.2525381\ttest: 6.2564685\tbest: 6.2564685 (946)\ttotal: 10m 24s\tremaining: 34.9s\n",
      "947:\tlearn: 6.2525136\ttest: 6.2564406\tbest: 6.2564406 (947)\ttotal: 10m 24s\tremaining: 34.3s\n",
      "948:\tlearn: 6.2524979\ttest: 6.2564405\tbest: 6.2564405 (948)\ttotal: 10m 25s\tremaining: 33.6s\n",
      "949:\tlearn: 6.2524791\ttest: 6.2564382\tbest: 6.2564382 (949)\ttotal: 10m 26s\tremaining: 32.9s\n",
      "950:\tlearn: 6.2524569\ttest: 6.2564278\tbest: 6.2564278 (950)\ttotal: 10m 26s\tremaining: 32.3s\n",
      "951:\tlearn: 6.2524313\ttest: 6.2564126\tbest: 6.2564126 (951)\ttotal: 10m 27s\tremaining: 31.6s\n",
      "952:\tlearn: 6.2524152\ttest: 6.2564000\tbest: 6.2564000 (952)\ttotal: 10m 27s\tremaining: 31s\n",
      "953:\tlearn: 6.2523792\ttest: 6.2563862\tbest: 6.2563862 (953)\ttotal: 10m 28s\tremaining: 30.3s\n",
      "954:\tlearn: 6.2523557\ttest: 6.2563681\tbest: 6.2563681 (954)\ttotal: 10m 29s\tremaining: 29.7s\n",
      "955:\tlearn: 6.2523316\ttest: 6.2563481\tbest: 6.2563481 (955)\ttotal: 10m 30s\tremaining: 29s\n",
      "956:\tlearn: 6.2522981\ttest: 6.2563025\tbest: 6.2563025 (956)\ttotal: 10m 30s\tremaining: 28.3s\n",
      "957:\tlearn: 6.2522826\ttest: 6.2562909\tbest: 6.2562909 (957)\ttotal: 10m 31s\tremaining: 27.7s\n",
      "958:\tlearn: 6.2522561\ttest: 6.2562895\tbest: 6.2562895 (958)\ttotal: 10m 32s\tremaining: 27s\n",
      "959:\tlearn: 6.2522221\ttest: 6.2562581\tbest: 6.2562581 (959)\ttotal: 10m 32s\tremaining: 26.4s\n",
      "960:\tlearn: 6.2522019\ttest: 6.2562386\tbest: 6.2562386 (960)\ttotal: 10m 33s\tremaining: 25.7s\n",
      "961:\tlearn: 6.2521722\ttest: 6.2562193\tbest: 6.2562193 (961)\ttotal: 10m 34s\tremaining: 25s\n",
      "962:\tlearn: 6.2521497\ttest: 6.2561975\tbest: 6.2561975 (962)\ttotal: 10m 34s\tremaining: 24.4s\n",
      "963:\tlearn: 6.2521275\ttest: 6.2561797\tbest: 6.2561797 (963)\ttotal: 10m 35s\tremaining: 23.7s\n",
      "964:\tlearn: 6.2521034\ttest: 6.2561666\tbest: 6.2561666 (964)\ttotal: 10m 35s\tremaining: 23.1s\n",
      "965:\tlearn: 6.2520780\ttest: 6.2561698\tbest: 6.2561666 (964)\ttotal: 10m 36s\tremaining: 22.4s\n",
      "966:\tlearn: 6.2520614\ttest: 6.2561613\tbest: 6.2561613 (966)\ttotal: 10m 37s\tremaining: 21.7s\n",
      "967:\tlearn: 6.2520372\ttest: 6.2561475\tbest: 6.2561475 (967)\ttotal: 10m 37s\tremaining: 21.1s\n",
      "968:\tlearn: 6.2520176\ttest: 6.2561328\tbest: 6.2561328 (968)\ttotal: 10m 38s\tremaining: 20.4s\n",
      "969:\tlearn: 6.2520030\ttest: 6.2561224\tbest: 6.2561224 (969)\ttotal: 10m 39s\tremaining: 19.8s\n",
      "970:\tlearn: 6.2519743\ttest: 6.2561068\tbest: 6.2561068 (970)\ttotal: 10m 39s\tremaining: 19.1s\n",
      "971:\tlearn: 6.2519454\ttest: 6.2560968\tbest: 6.2560968 (971)\ttotal: 10m 40s\tremaining: 18.4s\n",
      "972:\tlearn: 6.2519234\ttest: 6.2560817\tbest: 6.2560817 (972)\ttotal: 10m 41s\tremaining: 17.8s\n",
      "973:\tlearn: 6.2518932\ttest: 6.2560733\tbest: 6.2560733 (973)\ttotal: 10m 41s\tremaining: 17.1s\n",
      "974:\tlearn: 6.2518675\ttest: 6.2560568\tbest: 6.2560568 (974)\ttotal: 10m 42s\tremaining: 16.5s\n",
      "975:\tlearn: 6.2518532\ttest: 6.2560527\tbest: 6.2560527 (975)\ttotal: 10m 43s\tremaining: 15.8s\n",
      "976:\tlearn: 6.2518289\ttest: 6.2560371\tbest: 6.2560371 (976)\ttotal: 10m 43s\tremaining: 15.2s\n",
      "977:\tlearn: 6.2518042\ttest: 6.2560114\tbest: 6.2560114 (977)\ttotal: 10m 44s\tremaining: 14.5s\n",
      "978:\tlearn: 6.2517832\ttest: 6.2559971\tbest: 6.2559971 (978)\ttotal: 10m 45s\tremaining: 13.8s\n",
      "979:\tlearn: 6.2517558\ttest: 6.2559660\tbest: 6.2559660 (979)\ttotal: 10m 45s\tremaining: 13.2s\n",
      "980:\tlearn: 6.2517342\ttest: 6.2559496\tbest: 6.2559496 (980)\ttotal: 10m 46s\tremaining: 12.5s\n",
      "981:\tlearn: 6.2517087\ttest: 6.2559335\tbest: 6.2559335 (981)\ttotal: 10m 47s\tremaining: 11.9s\n",
      "982:\tlearn: 6.2516844\ttest: 6.2559062\tbest: 6.2559062 (982)\ttotal: 10m 47s\tremaining: 11.2s\n",
      "983:\tlearn: 6.2516622\ttest: 6.2558846\tbest: 6.2558846 (983)\ttotal: 10m 48s\tremaining: 10.5s\n",
      "984:\tlearn: 6.2516238\ttest: 6.2558815\tbest: 6.2558815 (984)\ttotal: 10m 49s\tremaining: 9.89s\n",
      "985:\tlearn: 6.2516104\ttest: 6.2558696\tbest: 6.2558696 (985)\ttotal: 10m 49s\tremaining: 9.23s\n",
      "986:\tlearn: 6.2515905\ttest: 6.2558616\tbest: 6.2558616 (986)\ttotal: 10m 50s\tremaining: 8.57s\n",
      "987:\tlearn: 6.2515752\ttest: 6.2558541\tbest: 6.2558541 (987)\ttotal: 10m 51s\tremaining: 7.91s\n",
      "988:\tlearn: 6.2515582\ttest: 6.2558520\tbest: 6.2558520 (988)\ttotal: 10m 51s\tremaining: 7.25s\n",
      "989:\tlearn: 6.2515370\ttest: 6.2558482\tbest: 6.2558482 (989)\ttotal: 10m 52s\tremaining: 6.59s\n",
      "990:\tlearn: 6.2515133\ttest: 6.2558352\tbest: 6.2558352 (990)\ttotal: 10m 53s\tremaining: 5.93s\n",
      "991:\tlearn: 6.2514757\ttest: 6.2557970\tbest: 6.2557970 (991)\ttotal: 10m 53s\tremaining: 5.27s\n",
      "992:\tlearn: 6.2514620\ttest: 6.2557969\tbest: 6.2557969 (992)\ttotal: 10m 54s\tremaining: 4.61s\n",
      "993:\tlearn: 6.2514435\ttest: 6.2557798\tbest: 6.2557798 (993)\ttotal: 10m 55s\tremaining: 3.95s\n",
      "994:\tlearn: 6.2514256\ttest: 6.2557650\tbest: 6.2557650 (994)\ttotal: 10m 55s\tremaining: 3.29s\n",
      "995:\tlearn: 6.2514089\ttest: 6.2557632\tbest: 6.2557632 (995)\ttotal: 10m 56s\tremaining: 2.64s\n",
      "996:\tlearn: 6.2513885\ttest: 6.2557594\tbest: 6.2557594 (996)\ttotal: 10m 57s\tremaining: 1.98s\n",
      "997:\tlearn: 6.2513543\ttest: 6.2557481\tbest: 6.2557481 (997)\ttotal: 10m 57s\tremaining: 1.32s\n",
      "998:\tlearn: 6.2513261\ttest: 6.2557421\tbest: 6.2557421 (998)\ttotal: 10m 58s\tremaining: 659ms\n",
      "999:\tlearn: 6.2513049\ttest: 6.2557309\tbest: 6.2557309 (999)\ttotal: 10m 58s\tremaining: 0us\n",
      "\n",
      "bestTest = 6.25573092\n",
      "bestIteration = 999\n",
      "\n",
      "Begin Training of Models\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.074728\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000027 seconds, init for row-wise cost 0.605148 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.779967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 16969\n",
      "[LightGBM] [Info] Number of data points in the train set: 3142735, number of used features: 70\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 440 and depth = 9\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 432 and depth = 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#train/test triggers\n",
    "is_train = True\n",
    "is_infer = True\n",
    "\n",
    "# Remove rows with missing target values\n",
    "valid_indices = np.isfinite(y)\n",
    "X = X[valid_indices]\n",
    "y = y[valid_indices]\n",
    "\n",
    "# Split the data into training and test\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Save indices\n",
    "train_index = np.arange(len(X_train))\n",
    "val_index = np.arange(len(X_val))\n",
    "\n",
    "#Save the bounds of the target\n",
    "y_min = np.min(y)\n",
    "y_max = np.max(y)\n",
    "\n",
    "# Set parameters for XGBoost (These were ours think about cvgrid search on individual model)\n",
    "params_xgb = {\n",
    "    'tree_method': 'hist',\n",
    "    'objective': 'reg:absoluteerror',\n",
    "    'n_estimators': 1000,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Set parameters for CatBoost (These were ours think about cvgrid search on individual model)\n",
    "#Cant use gpu because mean absolute error is not built for that\n",
    "params_cbt = {\n",
    "    'objective': 'MAE',\n",
    "    'iterations': 1000,\n",
    "    'use_best_model': True,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Set params for LGBM (these were by the author besides my callback)\n",
    "params_lgb = {\n",
    "    'learning_rate': 0.018,\n",
    "    'max_depth': 9,\n",
    "    'n_estimators': 600,\n",
    "    'num_leaves': 440,\n",
    "    'objective': 'mae',\n",
    "    'random_state': 42,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 100,\n",
    "    'verbose': 2\n",
    "}\n",
    "\n",
    "#Had to change names for full so i can analyze on test set its weird its for the model.__name__ part\n",
    "# Create a dictionary of models (from Jatindeeps idea)\n",
    "model_dict = {\n",
    "    'XGBRegressor': xgb.XGBRegressor(**params_xgb),\n",
    "    'CatBoostRegressor': cbt.CatBoostRegressor(**params_cbt),\n",
    "    'LGBMRegressor': lgb.LGBMRegressor(**params_lgb)\n",
    "}\n",
    "\n",
    "\n",
    "#Specify Number of Folds\n",
    "n_folds = 4\n",
    "\n",
    "\n",
    "# List to store models\n",
    "models = []\n",
    "\n",
    "# Path to store models\n",
    "model_path = \"C:/Users/User/Desktop/Kaggle_Models_Optiver\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "#My training method (NEED SOMEBODY TO VERIFY THE CROSS VALIDATION)\n",
    "# Add the train model with cross-validation\n",
    "#Somebody make sure the best model saves for each of these\n",
    "def train_models_with_cv(model_dict, modelname='lgb'):\n",
    "    if is_train:\n",
    "        X_train_fold = X_train[train_index%n_folds!=i]\n",
    "        Y_train_fold = Y_train[train_index%n_folds!=i]\n",
    "        X_val_fold = X_val[val_index%n_folds==i]\n",
    "        Y_val_fold = Y_val[val_index%n_folds==i]\n",
    "        \n",
    "        model = model_dict[modelname]\n",
    "\n",
    "        if modelname == 'LGBMRegressor':\n",
    "            callbacks = [lgb.callback.early_stopping(100, first_metric_only=True, verbose=True, min_delta=.0001)]\n",
    "            model.fit(X_train_fold, Y_train_fold, eval_set=[(X_val_fold, Y_val_fold)], eval_metric='mae', callbacks=callbacks) \n",
    "\n",
    "        if modelname == 'XGBRegressor':\n",
    "            callbacks = xgb.callback.EarlyStopping(rounds=5, metric_name=\"mae\", save_best=True, min_delta=.0001)\n",
    "            model.fit(X_train_fold, Y_train_fold, eval_set=[(X_val_fold, Y_val_fold)], callbacks=[callbacks], verbose=True)\n",
    "\n",
    "        if modelname == 'CatBoostRegressor':\n",
    "            model.fit(X_train_fold, Y_train_fold, eval_set=[(X_val_fold, Y_val_fold)], verbose=1, early_stopping_rounds=100)\n",
    "\n",
    "        models.append(model)\n",
    "        joblib.dump(model, f'{model_path}/{modelname}_{i}.model')\n",
    "    else:\n",
    "        models.append(joblib.load(f'{model_path}/{modelname}_{i}.model'))\n",
    "        print(f'{modelname}_{i} loaded')\n",
    "#--------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# Train the models\n",
    "for i in range(n_folds):\n",
    "    print('Begin Training of Models')\n",
    "    train_models_with_cv(model_dict, 'LGBMRegressor')\n",
    "    train_models_with_cv(model_dict, 'XGBRegressor') \n",
    "    train_models_with_cv(model_dict, 'CatBoostRegressor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a380b839-b2b2-443d-8547-e9bf8b12b831",
   "metadata": {},
   "source": [
    "### Performance Results from Upgraded Model\n",
    "- I will now test on the test set and calculate the average MAE amongst folds for each model separately, and then make an averaged prediction, add final transformations, and calculate MAE for our final model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b44a90b9-2c42-4f55-95f8-5d76b82e1345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor MAE Calculated for fold 1\n",
      "LGBMRegressor MAE Calculated for fold 1\n",
      "LGBMRegressor MAE Calculated for fold 1\n",
      "LGBMRegressor MAE Calculated for fold 1\n",
      "LGBMRegressor MAE Calculated for fold 2\n",
      "LGBMRegressor MAE Calculated for fold 2\n",
      "LGBMRegressor MAE Calculated for fold 2\n",
      "LGBMRegressor MAE Calculated for fold 2\n",
      "LGBMRegressor MAE Calculated for fold 3\n",
      "LGBMRegressor MAE Calculated for fold 3\n",
      "LGBMRegressor MAE Calculated for fold 3\n",
      "LGBMRegressor MAE Calculated for fold 3\n",
      "LGBMRegressor MAE Calculated for fold 4\n",
      "LGBMRegressor MAE Calculated for fold 4\n",
      "LGBMRegressor MAE Calculated for fold 4\n",
      "LGBMRegressor MAE Calculated for fold 4\n",
      "XGBRegressor MAE Calculated for fold 1\n",
      "XGBRegressor MAE Calculated for fold 1\n",
      "XGBRegressor MAE Calculated for fold 1\n",
      "XGBRegressor MAE Calculated for fold 1\n",
      "XGBRegressor MAE Calculated for fold 2\n",
      "XGBRegressor MAE Calculated for fold 2\n",
      "XGBRegressor MAE Calculated for fold 2\n",
      "XGBRegressor MAE Calculated for fold 2\n",
      "XGBRegressor MAE Calculated for fold 3\n",
      "XGBRegressor MAE Calculated for fold 3\n",
      "XGBRegressor MAE Calculated for fold 3\n",
      "XGBRegressor MAE Calculated for fold 3\n",
      "XGBRegressor MAE Calculated for fold 4\n",
      "XGBRegressor MAE Calculated for fold 4\n",
      "XGBRegressor MAE Calculated for fold 4\n",
      "XGBRegressor MAE Calculated for fold 4\n",
      "CatBoostRegressor MAE Calculated for fold 1\n",
      "CatBoostRegressor MAE Calculated for fold 1\n",
      "CatBoostRegressor MAE Calculated for fold 1\n",
      "CatBoostRegressor MAE Calculated for fold 1\n",
      "CatBoostRegressor MAE Calculated for fold 2\n",
      "CatBoostRegressor MAE Calculated for fold 2\n",
      "CatBoostRegressor MAE Calculated for fold 2\n",
      "CatBoostRegressor MAE Calculated for fold 2\n",
      "CatBoostRegressor MAE Calculated for fold 3\n",
      "CatBoostRegressor MAE Calculated for fold 3\n",
      "CatBoostRegressor MAE Calculated for fold 3\n",
      "CatBoostRegressor MAE Calculated for fold 3\n",
      "CatBoostRegressor MAE Calculated for fold 4\n",
      "CatBoostRegressor MAE Calculated for fold 4\n",
      "CatBoostRegressor MAE Calculated for fold 4\n",
      "CatBoostRegressor MAE Calculated for fold 4\n",
      "LGBMRegressor - 4 fold MAE: 6.2369437275446105\n",
      "XGBRegressor - 4 fold MAE: 6.243424444090414\n",
      "CatBoostRegressor - 4 fold MAE: 6.259998049803945\n",
      "Averaged and Final Transformed Prediction MAE: 6.241370745263414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "#Transformation function from author \n",
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices)/np.sum(std_error)\n",
    "    out = prices-std_error*step\n",
    "    return out\n",
    "    \n",
    "# Initialize lists to store MAE for each model and predictions\n",
    "mae_scores = {model_name: [] for model_name in model_dict}\n",
    "all_predictions = []\n",
    "\n",
    "# Save the indices of the test set\n",
    "test_index = np.arange(len(X_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#technically since theres folds and 12 models (10/17/23) you have 48 predictions\n",
    "for model_name in model_dict: # Iterate through the three models\n",
    "    for fold in range(n_folds): #Iterate through all the folds\n",
    "        # Initialize lists to store predictions for each model\n",
    "        model_predictions = {model_name: [] for model_name in model_dict}\n",
    "        #Calculate the test folds\n",
    "        X_test_fold = X_test[test_index%n_folds!=fold]\n",
    "        Y_test_fold = Y_test[test_index%n_folds!=fold]\n",
    "        for model in models: # Idea is to iterate through the models and for each fold and predict on it and save it\n",
    "            if model_name == model.__class__.__name__:\n",
    "                y_pred_test = model.predict(X_test_fold)  # Predict using the test data for this fold\n",
    "                mae = mean_absolute_error(Y_test_fold, y_pred_test)  # Calculate MAE for this fold\n",
    "                mae_scores[model_name].append(mae)\n",
    "                model_predictions[model_name] = y_pred_test\n",
    "                print(f'{model_name} MAE Calculated for fold {fold + 1}')\n",
    "            \n",
    "    \n",
    "\n",
    "# Calculate the average MAE for each model\n",
    "average_mae_scores = {model_name: np.mean(scores) for model_name, scores in mae_scores.items()}\n",
    "\n",
    "# Calculate averaged predictions for all models\n",
    "all_model_prediction = np.mean([model.predict(X_test) for model in models], 0)\n",
    "\n",
    "# Perform zero sum transformation\n",
    "zero_summed_prediction = zero_sum(all_model_prediction, X_test['bid_size'] + X_test['ask_size'])\n",
    "\n",
    "#Get the final prediction by clipping THIS IS LIKE THE LAST ONE THEN WE WILL CHECK HOW CLOSE IT IS TO TARGET\n",
    "final_transformed_prediction = np.clip(zero_summed_prediction, y_min, y_max)\n",
    "\n",
    "#Calculate the MAE for this averaged prediction\n",
    "final_transformed_prediction_mae = mean_absolute_error(Y_test, final_transformed_prediction)\n",
    "\n",
    "# Print the results\n",
    "for model_name, score in average_mae_scores.items():\n",
    "    print(f\"{model_name} - {n_folds} fold MAE: {score}\")\n",
    "\n",
    "print(f\"Averaged and Final Transformed Prediction MAE: {final_transformed_prediction_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc941774-6f1b-492e-8a9e-e0fae7f27b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a dictionary to store the predictions for each model\n",
    "predictions_by_model = {}\n",
    "\n",
    "# Get predictions for each model\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    predictions_by_model[model_name] = y_pred_test\n",
    "\n",
    "# Create a scatter plot for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for model_name, y_pred_test in predictions_by_model.items():\n",
    "    plt.scatter(Y_test, y_pred_test, alpha=0.5, label=model_name)\n",
    "\n",
    "plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], linestyle='--', color='red', label='y=x line')\n",
    "\n",
    "plt.title(\"Combined Scatter Plot: Predicted vs. Actual by Model\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7e8eb-de63-4da2-9f60-fa37708588a2",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "- CV Grid search on all three models. Analyze their optimized score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
